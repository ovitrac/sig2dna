<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>signomics API documentation</title>
<meta name="description" content="Module: sig2dna_core.signomics.py (from the Generative Simulation Initiative)
…" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>signomics</code></h1>
</header>
<section id="section-intro">
<h1 id="module-sig2dna_coresignomicspy-from-the-generative-simulation-initiative">Module: sig2dna_core.signomics.py (from the Generative Simulation Initiative)</h1>
<p>This is the core module of the sig2dna framework, dedicated to transforming numerical chemical signals into DNA-like symbolic representations. The module enables symbolic analysis, fingerprinting, alignment, and classification of complex analytical signals, such as:</p>
<ul>
<li>GC-MS / GC-FID</li>
<li>HPLC-MS</li>
<li>NMR / FTIR / Raman</li>
<li>RX and other spectroscopy data</li>
</ul>
<p>It is designed to facilitate high-throughput pattern recognition, compression, clustering, and AI/ML-based classification. Symbolic transformation is based on <strong>wavelet decomposition (Mexican Hat/Ricker)</strong> and segment encoding into letters (e.g., A, B, C, X, Y, Z). The representation preserves key structural patterns (e.g., peak transitions) across multiple scales and supports entropy-based distances.</p>
<h2 id="main-components">Main Components</h2>
<ul>
<li>DNAsignal — core class to transform a signal into DNA-like symbolic representation</li>
<li>DNAstr — string subclass enabling alignment, entropy analysis, visualization, and reconstruction</li>
<li>DNApairwiseAnalysis — distance and clustering toolbox for aligned DNA codes (PCoA, dendrogram, 2D/3D plots)</li>
</ul>
<h2 id="key-features">Key Features</h2>
<ul>
<li>Multi-scale wavelet transform with symbolic encoding</li>
<li>Symbolic entropy and mutual information measures</li>
<li>Fast symbolic alignment using <code>difflib</code> or <code>biopython</code></li>
<li>Pairwise symbolic distances (Shannon, excess entropy, Jaccard, Jensen-Shannon)</li>
<li>Interactive plotting: segments, alignment masks, triangle patches</li>
<li>Motif search, alignment visualization, HTML and terminal rendering</li>
<li>Dimensionality reduction (MDS), clustering, dendrogram and heatmaps</li>
</ul>
<h2 id="core-concept">Core Concept</h2>
<p>Input Signal
- 1D NumPy array S of shape (m,)
- Data type: np.float64 (default) or np.float32
- Typically sparse and non-negative, such as GC-MS total ion chromatograms</p>
<p>Wavelet Transform
- CWT with Ricker (Mexican hat) wavelet
- Scales: $s = 2^0, 2^1,&hellip;, 2^n
- Downsampling by scale (to reduce data volume and capture features at relevant resolutions)</p>
<p>Symbolic Encoding and compressed representation</p>
<p>The transformed signal Ts at scale s is converted to a sequence of symbolic letters using the rules:
| Symbol | Description
|
| ------ | ------------------------------------------------- |
| A
| Monotonic increase crossing from − to +
|
| B
| Monotonic increase from − to − (no zero crossing) |
| C
| Monotonic increase from + to +
|
| X
| Monotonic decrease from + to + (no zero crossing) |
| Y
| Monotonic decrease from − to −
|
| Z
| Monotonic decrease crossing from + to −
|
| _
| Zero or noise (after filtering)
|</p>
<p>Each encoded segment is associated with:
- width: number of points
- height: amplitude difference</p>
<p>These form the compressed representation</p>
<h2 id="installation">Installation</h2>
<p>Install all dependencies with:</p>
<p>conda install pywavelets seaborn scikit-learn
conda install -c conda-forge python-Levenshtein biopython</p>
<h2 id="examples">Examples</h2>
<p>from signomics import DNAsignal
from signal import signal</p>
<h1 id="load-a-sampled-signal-eg-from-gc-ms-raman">Load a sampled signal (e.g., from GC-MS, Raman)</h1>
<p>S = signal.from_peaks(&hellip;)
# or any constructor for sampled signals</p>
<h1 id="encode-into-dna-like-format">Encode into DNA-like format</h1>
<p>D = DNAsignal(S, encode=True)
D.encode_dna()
D.plot_codes(scale=4)</p>
<h1 id="compare-samples-and-cluster">Compare samples and cluster</h1>
<p>Dlist = [DNAsignal(S1, encode=True), DNAsignal(S2, encode=True), &hellip;]
analysis = DNAsignal._pairwiseEntropyDistance(Dlist, scale=4)
analysis.plot_dendrogram()
analysis.scatter(n_clusters=3)</p>
<h2 id="notes">Notes</h2>
<p>The methodology implemented in this module covers and extends the approaches initially tested during the PhD of Julien Kermorvant.
"Concept of chemical fingerprints applied to the management of chemical risk of materials, recycled deposits and food packaging". PhD thesis AgroParisTech. December 2023. <a href="https://theses.hal.science/tel-04194172">https://theses.hal.science/tel-04194172</a></p>
<h2 id="maintenance-forking">Maintenance &amp; forking</h2>
<h1 id="git-init-b-main">git init -b main</h1>
<h1 id="gh-repo-create-sig2dna-public-source-remoteorigin-push">gh repo create sig2dna &ndash;public &ndash;source=. &ndash;remote=origin &ndash;push</h1>
<h1 id="alternatively">alternatively</h1>
<h1 id="git-remote-add-origin-gitgithubcomovitracsig2dnagit">git remote add origin git@github.com:ovitrac/sig2dna.git</h1>
<h1 id="git-branch-m-main-ensure-current-branch-is-named-main">git branch -M main
# Ensure current branch is named 'main'</h1>
<h1 id="git-push-u-origin-main-push-and-set-upstream-tracking">git push -u origin main
# Push and set upstream tracking</h1>
<p>tree -P '<em>.py' -P '</em>.md' -P 'LICENSE' -I '<strong>pycache</strong>|.*' &ndash;prune
pdoc ./sig2dna-core/signomics.py -f &ndash;html -o ./docs</p>
<p>Author: Olivier Vitrac — olivier.vitrac@gmail.com
Revision: 2025-05-21</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python3
# -*- coding: utf-8 -*-

&#34;&#34;&#34;
Module: sig2dna_core.signomics.py (from the Generative Simulation Initiative)
==================================

This is the core module of the sig2dna framework, dedicated to transforming numerical chemical signals into DNA-like symbolic representations. The module enables symbolic analysis, fingerprinting, alignment, and classification of complex analytical signals, such as:

- GC-MS / GC-FID
- HPLC-MS
- NMR / FTIR / Raman
- RX and other spectroscopy data

It is designed to facilitate high-throughput pattern recognition, compression, clustering, and AI/ML-based classification. Symbolic transformation is based on **wavelet decomposition (Mexican Hat/Ricker)** and segment encoding into letters (e.g., A, B, C, X, Y, Z). The representation preserves key structural patterns (e.g., peak transitions) across multiple scales and supports entropy-based distances.

Main Components
---------------
- DNAsignal — core class to transform a signal into DNA-like symbolic representation
- DNAstr — string subclass enabling alignment, entropy analysis, visualization, and reconstruction
- DNApairwiseAnalysis — distance and clustering toolbox for aligned DNA codes (PCoA, dendrogram, 2D/3D plots)

Key Features
------------
- Multi-scale wavelet transform with symbolic encoding
- Symbolic entropy and mutual information measures
- Fast symbolic alignment using `difflib` or `biopython`
- Pairwise symbolic distances (Shannon, excess entropy, Jaccard, Jensen-Shannon)
- Interactive plotting: segments, alignment masks, triangle patches
- Motif search, alignment visualization, HTML and terminal rendering
- Dimensionality reduction (MDS), clustering, dendrogram and heatmaps

Core Concept
------------

Input Signal
- 1D NumPy array S of shape (m,)
- Data type: np.float64 (default) or np.float32
- Typically sparse and non-negative, such as GC-MS total ion chromatograms

Wavelet Transform
- CWT with Ricker (Mexican hat) wavelet
- Scales: $s = 2^0, 2^1,..., 2^n
- Downsampling by scale (to reduce data volume and capture features at relevant resolutions)

Symbolic Encoding and compressed representation

The transformed signal Ts at scale s is converted to a sequence of symbolic letters using the rules:
| Symbol | Description                                       |
| ------ | ------------------------------------------------- |
| A      | Monotonic increase crossing from − to +           |
| B      | Monotonic increase from − to − (no zero crossing) |
| C      | Monotonic increase from + to +                    |
| X      | Monotonic decrease from + to + (no zero crossing) |
| Y      | Monotonic decrease from − to −                    |
| Z      | Monotonic decrease crossing from + to −           |
| _      | Zero or noise (after filtering)                   |

Each encoded segment is associated with:
- width: number of points
- height: amplitude difference

These form the compressed representation

Installation
------------
Install all dependencies with:

conda install pywavelets seaborn scikit-learn
conda install -c conda-forge python-Levenshtein biopython

Examples
--------
from signomics import DNAsignal
from signal import signal

# Load a sampled signal (e.g., from GC-MS, Raman)
S = signal.from_peaks(...)  # or any constructor for sampled signals

# Encode into DNA-like format
D = DNAsignal(S, encode=True)
D.encode_dna()
D.plot_codes(scale=4)

# Compare samples and cluster
Dlist = [DNAsignal(S1, encode=True), DNAsignal(S2, encode=True), ...]
analysis = DNAsignal._pairwiseEntropyDistance(Dlist, scale=4)
analysis.plot_dendrogram()
analysis.scatter(n_clusters=3)

Notes
-----
The methodology implemented in this module covers and extends the approaches initially tested during the PhD of Julien Kermorvant.
&#34;Concept of chemical fingerprints applied to the management of chemical risk of materials, recycled deposits and food packaging&#34;. PhD thesis AgroParisTech. December 2023. https://theses.hal.science/tel-04194172


Maintenance &amp; forking
---------------------
# git init -b main
# gh repo create sig2dna --public --source=. --remote=origin --push
# alternatively
#   git remote add origin git@github.com:ovitrac/sig2dna.git
#   git branch -M main        # Ensure current branch is named &#39;main&#39;
#   git push -u origin main   # Push and set upstream tracking
tree -P &#39;*.py&#39; -P &#39;*.md&#39; -P &#39;LICENSE&#39; -I &#39;__pycache__|.*&#39; --prune
pdoc ./sig2dna-core/signomics.py -f --html -o ./docs


Author: Olivier Vitrac — olivier.vitrac@gmail.com
Revision: 2025-05-21
&#34;&#34;&#34;

# %% Indentication
__project__ = &#34;Signomics&#34;
__author__ = &#34;Olivier Vitrac&#34;
__copyright__ = &#34;Copyright 2025&#34;
__credits__ = [&#34;Olivier Vitrac&#34;]
__license__ = &#34;MIT&#34;
__maintainer__ = &#34;Olivier Vitrac&#34;
__email__ = &#34;olivier.vitrac@gmail.com&#34;
__version__ = &#34;0.34&#34;

# %% Dependencies
# note:
# cwt and ricker are depreciated since scipy v1.12, pwywalets is used instead. See: https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.signal.cwt.html

# Generic libs
import os, sys, socket, getpass, datetime, uuid, operator, json, gzip, hashlib, re
import inspect, importlib.util, warnings
from pathlib import Path
from collections import OrderedDict, Counter
from types import SimpleNamespace
#from itertools import islice
from copy import deepcopy
from time import time
from tqdm import tqdm

# Math, machine-learning and visualization libs
import random
import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from numpy.lib.stride_tricks import sliding_window_view
from scipy.interpolate import interp1d
from scipy.signal import  medfilt
from scipy.ndimage import uniform_filter1d
from scipy.stats import entropy
from scipy.spatial.distance import jensenshannon
from difflib import SequenceMatcher
from matplotlib.patches import Polygon, Rectangle
from mpl_toolkits.mplot3d import Axes3D
from IPython.display import HTML, display

# Non-default libs
# Check availability of optional packages
optional_dependencies = {
    &#34;pywt&#34;: {&#34;package&#34;: &#34;pywavelets&#34;, &#34;optional&#34;: False, &#34;source&#34;:&#34;&#34;},
    &#34;Levenshtein&#34;: {&#34;package&#34;: &#34;python-Levenshtein&#34;, &#34;optional&#34;: False, &#34;source&#34;:&#34;-c conda-forge&#34;},
    &#34;Bio.Align&#34;: {&#34;package&#34;: &#34;biopython&#34;, &#34;optional&#34;: True, &#34;source&#34;: &#34;-c conda-forge&#34;},
    &#34;seaborn&#34;: {&#34;package&#34;: &#34;seaborn&#34;, &#34;optional&#34;: False, &#34;source&#34;:&#34;&#34;},
    &#34;sklearn&#34;: {&#34;package&#34;: &#34;scikit-learn&#34;, &#34;optional&#34;:False, &#34;source&#34;:&#34;&#34;}
}
dependency_status = []
for module, meta in optional_dependencies.items():
    module_name = module.split(&#39;.&#39;)[0]
    available = importlib.util.find_spec(module_name) is not None
    status = {
        &#34;Module&#34;: module,
        &#34;Available&#34;: available,
        &#34;Install Instruction&#34;: f&#34;conda install {meta[&#39;source&#39;]} {meta[&#39;package&#39;]}&#34;
    }
    dependency_status.append(status)
    if not available:
        msg = (
            f&#34;Required module &#39;{module}&#39; not found.\n&#34;
            f&#34;To install: {status[&#39;Install Instruction&#39;]}&#34;
        )
        if meta.get(&#34;optional&#34;, False):
            warnings.warn(msg)
        else:
            raise ImportError(msg)

import pywt
import Levenshtein
from Bio.Align import PairwiseAligner
from sklearn.decomposition import PCA
from sklearn.manifold import MDS
from sklearn.metrics import pairwise_distances, silhouette_score
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from scipy.spatial.distance import squareform
import seaborn as sns


__all__ = [&#34;DNAsignal&#34;, &#34;DNAstr&#34;, &#34;DNApairwiseAnalysis&#34;, &#34;signal&#34;, &#34;signal_collection&#34;, &#34;peaks&#34;, &#34;generator&#34;]

# %% load dynamically figprint without pythonpath modification or installation
def import_local_module(name: str, relative_path: str):
    &#34;&#34;&#34;
    Import a module by name from a file path relative to the calling module.

    Usage here:
    -----------
    import_local_module(&#34;figprint&#34;, &#34;figprint.py&#34;) replaces import figprint (zero-installation)

    Parameters:
    ----------
    name : str
        Name to assign to the module (used internally).
    relative_path : str
        Path relative to the calling module&#39;s location.

    Returns:
    -------
    module
        Imported module object.

    Example:
    --------
    &gt;&gt;&gt; figprint = import_local_module(&#34;figprint&#34;, &#34;figprint.py&#34;)
    &gt;&gt;&gt; figprint.print_pdf(...)
    &#34;&#34;&#34;
    # Get the caller&#39;s file path
    caller_frame = inspect.stack()[1]
    caller_path = os.path.abspath(os.path.dirname(caller_frame.filename))
    # Resolve full path to the module
    full_path = os.path.abspath(os.path.join(caller_path, relative_path))
    # Import as custom name
    spec = importlib.util.spec_from_file_location(name, full_path)
    if spec is None or spec.loader is None:
        raise ImportError(f&#34;Cannot load module {name} from {full_path}&#34;)
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)
    return mod

# use figprint = import_local_module if you want to access directly print_pdf, print_png...
import_local_module(&#34;figprint&#34;, &#34;figprint.py&#34;)

# %% Main classes DNAsignal, DNAstr, DNApairwiseAnalysis

# ------------------------
# DNAsignal
# ------------------------
class DNAsignal:
    &#34;&#34;&#34;
    DNAsignal(signal):
    ==================
    A class to encode a numerical signal (typically a 1D GC-MS trace, NMR/FTIR/Raman spectra
    or time series) into a DNA-like symbolic representation using wavelet analysis.
    This symbolic coding enables fast comparison, search, and alignment of signal features
    using abstracted patterns (e.g., &#39;YAZB&#39;).

    The class supports:
    - Continuous Wavelet Transform (CWT) using Ricker wavelets
    - Symbolic conversion of wavelet features to DNA-like letters (A, B, C, X, Y, Z)
    - Visualization of CWTs, symbolic encodings, and signal overlays
    - Reversible decoding of symbolic segments back into approximate signals
    - Substring extraction and matching
    - Storage of multi-scale representations (multi-resolution DNA encoding)

    This class is part of the symbolic signal transformation pipeline (`sig2dna`), compatible with `signal`, `peaks`, and `signal_collection`.

    Parameters
    ----------
    signal : signal
        An instance of the `signal` class representing a sampled waveform. It must
        have `x`, `y`, and a valid name or identifier.
    encode : bool (default = False)
        Launch encoders = [&#34;compute_cwt&#34;,&#34;encode_dna&#34;,&#34;encode_dna_full&#34;] if True
    plot : bool (default = False)
        Plot with plotter = [&#34;plot_signals&#34;,&#34;plot_transforms&#34;,&#34;plot_codes&#34;]

    Attributes
    ----------
    signal : signal
        The raw signal object being encoded.
    dx : float
        The nominal x-resolution of the signal (automatically derived).
    n : int
        Number of points in the signal (length of x/y arrays).
    scales : array-like
        Set of scales used in the Continuous Wavelet Transform (powers of 2 by default).
    transforms : signal_collection
        Stores the CWT-transformed signals, each as a `signal` object, indexed by scale.
    codes : dict[int, DNAstr]
        Symbolic codes by scale level. Each is a `DNAstr` object representing
        the symbolic sequence at that scale.
    codesfull : dict[int, DNAstr]
        Same as `codes`, but uses full resolution symbolic representation.
    peaks : peaks
        Optional `peaks` object used to index real peak positions from the signal.
    codebook : dict
        Mapping between symbolic characters (A, B, C, X, Y, Z, _) and wavelet features.
    generator : str
        Name of the wavelet basis used (default: &#39;ricker&#39;).

    Methods
    -------
    compute_cwt(scales=None, normalize=False)
        Computes the Continuous Wavelet Transform using the Ricker wavelet
        and stores the transformed signals in `transforms`.
    encode_dna()
        Encodes each scale&#39;s transformed signal into a symbolic `DNAstr` sequence
        using local maximum coding (ABCXYZ).
    encode_dna_full()
        Encodes signals at each scale using the full encoding scheme, preserving
        the flat regions (_) and finer symbolic transitions.
    plot_codes(scale)
        Plots both the wavelet transform and the symbolic code for the given scale.
    decode_dna(scale)
        Reconstructs the approximate signal for a given scale from its DNA encoding.
    __getitem__(scale)
        Shortcut to access the `DNAstr` object for a specific scale.
    summary()
        Returns a dictionary summarizing encoded scales and metadata.
    has(scale)
        Checks whether a DNAstr encoding exists at the given scale.

    Static pairwise distance methods
    --------------------------------
    _pairwiseEntropyDistance(list of DNAstr objects, scale)
        Return a DNApairwiseAnalysis instance based on the mutually exclusive information
        after DNA/code alignment.
    _pairwiseJaccardMotifDistance(list of DNAstr objects, scale)
        Return a DNApairwisedistance based on the presence/absence of a pattern (default=YAZB)
    _pairwiseJensenShannonDistance(list of DNAstr objects, scale)
        Return a DNApairwisedistance based on the Jensen-Shannon distance of a pattern
    _pairwiseLevenshteinDistance(list of DNAstr objects, scale)
        Return a DNApairwisedistance based on the Levenshtein Distance

    Examples
    --------
    &gt;&gt;&gt; S = signal.from_peaks(...)  # define a signal
    &gt;&gt;&gt; dna = DNAsignal(S)
    &gt;&gt;&gt; dna.compute_cwt()
    &gt;&gt;&gt; dna.encode_dna()
    &gt;&gt;&gt; dna.codes[4]
    DNAstr(&#34;AAAZZZYY...&#34;)
    &gt;&gt;&gt; dna.plot_codes(4)
    &gt;&gt;&gt; dna.codes[4].find(&#34;YAZB&#34;)
    &#34;&#34;&#34;

    def __init__(self, signal_obj, sampling_dt=1.0, dtype=np.float64,
                 encode=False,
                 encoder=[&#34;compute_cwt&#34;,&#34;encode_dna&#34;,&#34;encode_dna_full&#34;],
                 scales=[1,2,4,8,16,32],
                 x_label=&#34;index&#34;, x_unit = &#34;-&#34;, y_label=&#34;Intensity&#34;, y_unit = &#34;&#34;,
                 plot=False,
                 plotter=[&#34;plot_signals&#34;,&#34;plot_transforms&#34;,&#34;plot_codes&#34;]):
        &#34;&#34;&#34;
        Initialize DNAsignal with a signal object or 1D array.

        Parameters
        ----------
        signal_obj : signal or np.ndarray
            The input signal (preferably a signal object).
        sampling_dt : float
            Sampling interval (used for filtering).
        dtype : data-type
            Data type to cast the signal (default: np.float64).
        &#34;&#34;&#34;
        if isinstance(signal_obj, signal):
            self.signal_obj = signal_obj.copy()
            self.signal = np.asarray(signal_obj.y, dtype=dtype)
            self.x = signal_obj.x
            self.x_label = signal_obj.x_label or x_label
            self.x_unit = signal_obj.x_unit or x_unit
            self.y_label = signal_obj.y_label or y_label
            self.y_unit = signal_obj.y_unit or y_unit
            self.name = signal_obj.name
            self.sampling_dt = signal_obj.x[1] - signal_obj.x[0]
        else:
            self.signal_obj = None
            self.signal = np.asarray(signal_obj, dtype=dtype)
            self.x = np.arange(len(self.signal)) * sampling_dt
            self.x_label = x_label
            self.x_unit =  x_unit
            self.y_label = y_label
            self.y_unit = y_unit
            self.name = &#34;array&#34;
            self.sampling_dt = sampling_dt
        self.dtype = dtype
        self.filtered_signal = None
        self.scales = []
        self.cwt_coeffs = {}  # scale -&gt; array
        self.codes = {}       # scale -&gt; {letters, widths, heights}

        # encode and plots on request
        if plot and &#34;plot_signals&#34; in plotter:
            self.plot_signals()
        if encode:
            self.compute_cwt(scales=scales) # minimum encoder
            if plot and &#34;plot_transforms&#34; in plotter:
                self.plot_transforms()
            if (&#34;encode_dna&#34; in encoder) or (&#34;encode_dna_full&#34; in encoder):
                self.encode_dna(scales=scales)
                if plot and &#34;plot_codes&#34; in plotter:
                    self.plot_codes(scales=scales)
            if (&#34;encode_dna_full&#34; in encoder):
                self.encode_dna_full()


    def has(self, scale):
        &#34;&#34;&#34;
        Check if a DNA encoding exists for the specified scale.

        Parameters
        ----------
        scale : int
            The wavelet scale to check.

        Returns
        -------
        bool
            True if a symbolic DNAstr encoding exists at the given scale, False otherwise.

        Examples
        --------
        &gt;&gt;&gt; dna.has(4)
        True
        &gt;&gt;&gt; dna.has(16)
        False
        &#34;&#34;&#34;
        return scale in self.codes

    @staticmethod
    def apply_baseline_filter(signal, w=None, k=2, delta_t=1.0):
        &#34;&#34;&#34;
        Apply baseline filtering using moving median and local Poisson-based thresholding.

        Parameters
        ----------
        signal : np.ndarray
            Input signal (expected to be non-negative or baseline-dominated).
        w : int or None
            Window size for baseline and statistics (must be odd).
            Defaults to max(11, 2% of signal length).
        k : float
            Bienaymé-Tchebychev multiplier.
        delta_t : float
            Sampling time step.

        Returns
        -------
        filtered : np.ndarray
            Signal with baseline removed and low-intensity noise suppressed.

        Note
        ----
        This method is static, use signal.apply_baseline_filter() whenever appropriate instead.

        &#34;&#34;&#34;
        signal = np.asarray(signal)
        m = len(signal)

        # Determine appropriate window width
        if w is None:
            w = max(11, int(0.01 * m))
        if w % 2 == 0:
            w += 1
        if w &gt;= m:
            raise ValueError(f&#34;Window width w={w} must be smaller than signal length {m}.&#34;)

        # Step 1: remove baseline via moving median
        baseline = medfilt(signal, kernel_size=w)
        s = signal - baseline
        s[s &lt; 0] = 0  # force non-negativity

        # Step 2: moving mean and std (uniform filter = moving average)
        # signal.apply_baseline_filter() uses np.sliding_window_view() instead.
        mean = uniform_filter1d(s, size=w, mode=&#39;nearest&#39;)
        sq = uniform_filter1d(s**2, size=w, mode=&#39;nearest&#39;)
        std = np.sqrt(np.maximum(sq - mean**2, 0))

        # Step 3: Poisson λ from cv = std / mean
        with np.errstate(divide=&#39;ignore&#39;, invalid=&#39;ignore&#39;):
            cv = np.where(mean &gt; 0, std / mean, 0)
            lam = np.where(cv &gt; 0, 1 / (cv**2), 0)

        # Step 4: BT thresholding
        threshold = k * np.sqrt(10 * lam * delta_t)
        s[s &lt; threshold] = 0
        return s

    def compute_cwt(self, scales=None, apply_filter=False):
        &#34;&#34;&#34;
        Compute Continuous Wavelet Transform (CWT) using the Mexican Hat wavelet.

        Parameters
        ----------
        scales : list, int, or None
            List of scales (or a single scale) to compute. If None, default to [1, 2, 4, 8, 16].
        apply_filter : bool
            Whether to apply a baseline filter to the input signal before transforming.

        Sets
        ----
        self.scales : list
            The list of actual scales used.
        self.filtered_signal : ndarray
            Filtered or raw signal used for CWT.
        self.cwt_coeffs : dict
            Dictionary mapping each scale to its 1D coefficient array.
        self.transforms : signal_collection
            Collection of `signal` objects storing the transformed signals for each scale.
        &#34;&#34;&#34;
        if scales is None:
            scales = [2 ** i for i in range(5)]
        if not isinstance(scales,(list,tuple)):
            scales = [scales]
        self.scales = scales
        if apply_filter:
            self.filtered_signal = self.apply_baseline_filter(self.signal,delta_t=self.sampling_dt)
        else:
            self.filtered_signal = self.signal
        self.transforms = signal_collection()
        for scale in self.scales:
            coef, _ = pywt.cwt(self.filtered_signal, [scale], &#39;mexh&#39;)
            self.cwt_coeffs[scale] = coef[0]  # Access directly via scale
            sig = signal(
                x=self.x.copy(),
                y=coef[0],
                name=f&#34;CWT_scale_{scale}&#34;,
                x_label=&#34;x&#34;,
                y_label=&#34;CWT amplitude&#34;,
                y_unit=&#34;a.u.&#34;,
                source=&#34;CWT&#34;)
            self.transforms.append(sig)

    def encode_dna(self, scales=None):
        &#34;&#34;&#34;
        Encode each transformed signal into a symbolic DNA-like sequence of monotonic segments.

        Parameters
        ----------
        scales : list, int, or None
            List of scales (or a single scale) to encode. If None, use self.scales.

        The encoding detects strictly monotonic (or flat) segments and labels them with symbolic letters:
        - A: crosses 0 upward (neg → pos)
        - Z: crosses 0 downward (pos → neg)
        - B: strictly increasing negative segment
        - Y: strictly decreasing negative segment
        - C: strictly increasing positive segment
        - X: strictly decreasing positive segment
        - _: flat or ambiguous segment

        Sets
        ----
        self.codes : dict
            Dictionary mapping each scale to a struct with:
                - letters : str (symbolic encoding)
                - widths  : list of float (x-span of each segment)
                - heights : list of float (y-delta of each segment)
                - iloc    : list of index-pair tuples (start, end+1)
                - xloc    : list of x-span tuples (x_start, x_end)
                - dx      : segment step (dx)
        &#34;&#34;&#34;
        if scales is None:
            scales = self.scales
        if not isinstance(scales,(list,tuple)):
            scales = [scales]
        if not hasattr(self, &#39;cwt_coeffs&#39;) or not self.cwt_coeffs:
            self.compute_cwt(scales)
        dx = self.x[1]-self.x[0]
        for scale in scales:
            coef = self.cwt_coeffs[scale]
            letters, widths, heights, iloc, xloc = [], [], [], [], []
            monotonic = np.diff(coef)
            mono_sign = np.sign(monotonic)
            sign_changes = np.where(np.diff(mono_sign) != 0)[0] + 1  # +1 because diff shortens by 1
            start_idx = 0
            segment_ends = np.append(sign_changes, len(coef) - 1)
            for count, idx in enumerate(segment_ends):
                xsegment = self.x[start_idx:idx + 1]
                segment = coef[start_idx:idx + 1]
                if len(segment) &lt; 2:
                    letters.append(&#39;_&#39;)
                else:
                    start, end = segment[0], segment[-1]
                    letter = self._get_letter(start, end)
                    letters.append(letter)
                widths.append(xsegment[-1] - xsegment[0])
                heights.append(segment[-1] - segment[0])
                xloc.append((xsegment[0],xsegment[-1]))
                is_last = count == len(segment_ends) - 1
                iloc.append((start_idx, idx + 1 if is_last else idx))
                start_idx = idx #idx + 1 (segments are continguous)
            # update codes
            self.codes[scale] = {&#39;letters&#39;: &#39;&#39;.join(letters),
                                 &#39;widths&#39;: widths,
                                 &#39;heights&#39;: heights,
                                 &#39;xloc&#39;:xloc,
                                 &#39;iloc&#39;:iloc,
                                 &#39;dx&#39;:dx}

    def encode_dna_full(self, scales=None, resolution=&#39;index&#39;, repeat=True, n_points=None):
        &#34;&#34;&#34;
        Convert symbolic codes into DNA-like strings by repeating letters proportionally to their span.

        Parameters
        ----------
        scales : list, int, or None
            List of scales (or a single scale) to convert. If None, use self.scales.
        resolution : {&#39;index&#39;, &#39;x&#39;}
            Repetition mode:
                - &#39;index&#39;: repeat letters by number of indices (j - i from iloc)
                - &#39;x&#39;    : interpolate letter values over physical x-axis distance (xloc)
        repeat : bool
            If True, repeat or interpolate letters to form a string of desired resolution.
            If False, return the symbolic sequence without repetition.
        n_points : int or None
            Used only for resolution=&#39;x&#39; to control the number of interpolation points.
            If None, defaults to ~10 points per x-unit.

        Returns
        -------
        dict
            Dictionary mapping each scale to its DNA-like string.

        Sets
        ----
        self.codesfull : dict
            Dictionary storing the resulting full DNA-like string per scale.
        &#34;&#34;&#34;
        if scales is None:
            scales = self.scales
        elif isinstance(scales, (int, float)):
            scales = [scales]
        elif not isinstance(scales, (list, tuple)):
            raise TypeError(&#34;scales must be a list, int, or None&#34;)

        if not hasattr(self, &#39;codes&#39;) or not self.codes:
            self.encode_dna(scales)

        result = {}
        for scale in scales:
            if scale not in self.codes:
                self.encode_dna([scale])
            code = self.codes[scale]
            if not repeat:
                result[scale] = code[&#39;letters&#39;]
                continue
            if resolution == &#39;index&#39;:
                sequence = &#39;&#39;.join(
                    letter * max(1, (j - i)) for letter, (i, j) in zip(code[&#39;letters&#39;], code[&#39;iloc&#39;])
                )
            elif resolution == &#39;x&#39;:
                if n_points is None:
                    total_span = sum(x2 - x1 for x1, x2 in code[&#39;xloc&#39;])
                    n_points = int(np.ceil(total_span * 10))  # adjustable density
                x_start = code[&#39;xloc&#39;][0][0]
                x_end = code[&#39;xloc&#39;][-1][1]
                grid = np.linspace(x_start, x_end, n_points, endpoint=True)
                centers = [(x1 + x2) / 2 for x1, x2 in code[&#39;xloc&#39;]]
                # Encode letters as integers
                unique_letters = list(OrderedDict.fromkeys(code[&#39;letters&#39;]))
                letter_to_int = {ch: i for i, ch in enumerate(unique_letters)}
                int_to_letter = {i: ch for ch, i in letter_to_int.items()}

                int_vals = [letter_to_int[ch] for ch in code[&#39;letters&#39;]]
                interp_func = interp1d(centers, int_vals, kind=&#39;nearest&#39;,
                                       bounds_error=False, fill_value=int_vals[-1])
                interpolated = np.round(interp_func(grid)).astype(int)
                sequence = &#39;&#39;.join(int_to_letter[i] for i in interpolated)
            else:
                raise ValueError(&#34;resolution must be either &#39;index&#39; or &#39;x&#39;&#34;)
            result[scale] = DNAstr(sequence,
                                   dx=code[&#34;dx&#34;],
                                   iloc=(code[&#34;iloc&#34;][0][0],code[&#34;iloc&#34;][-1][-1]),
                                   xloc=(code[&#34;xloc&#34;][0][0],code[&#34;xloc&#34;][-1][-1]),
                                   x_label=self.x_label, x_unit=self.x_unit)
        self.codesfull = result

    @staticmethod
    def _get_letter(start, end, tol=1e-12):
        &#34;&#34;&#34;
        Determine letter based on monotonicity and signal range.

        Returns one of:
            - &#39;A&#39;: Negative to Positive (crosses zero upward)
            - &#39;Z&#39;: Positive to Negative (crosses zero downward)
            - &#39;B&#39;: Increasing Negative (concave up)
            - &#39;Y&#39;: Decreasing Negative (concave down)
            - &#39;C&#39;: Increasing Positive (concave up)
            - &#39;X&#39;: Decreasing Positive (concave down)
            - &#39;_&#39;: Flat or undefined
        &#34;&#34;&#34;
        # Optional tolerance for numerical 0
        s = start if abs(start) &gt; tol else 0.0
        e = end   if abs(end)   &gt; tol else 0.0
        if s == e:
            return &#39;_&#39;
        # Zero-crossings
        if s &lt; 0 and e &gt; 0:
            return &#39;A&#39;
        if s &gt; 0 and e &lt; 0:
            return &#39;Z&#39;
        # Entirely negative (possibly with 0 at one end)
        if s &lt;= 0 and e &lt;= 0:
            return &#39;B&#39; if e &gt; s else &#39;Y&#39;
        # Entirely positive (possibly with 0 at one end)
        if s &gt;= 0 and e &gt;= 0:
            return &#39;C&#39; if e &gt; s else &#39;X&#39;
        return &#39;_&#39;

    @staticmethod
    def _get_triangle_from_letter(letter,x0,y0,w,h):
        &#34;&#34;&#34;returns the triangle (counter-clockwise, x are incr) &#34;&#34;&#34;
        if letter == &#34;A&#34;:
            x = (x0,x0+w,x0+w)
            y = (y0,y0,y0+h)
        elif letter == &#34;B&#34;:
            x = (x0,x0+w,x0)
            y = (y0,y0+h,y0+h)
        elif letter == &#34;C&#34;:
            x = (x0,x0+w,x0+w)
            y = (y0,y0,y0+h)
        elif letter ==&#34;X&#34;:
            x = (x0,x0,x0+w)
            y = (y0,y0+h,y0+h)
        elif letter == &#34;Y&#34;:
            x = (x0,x0+w,x0+w)
            y = (y0,y0,y0+h)
        elif letter == &#34;Z&#34;:
            x = (x0,x0,x0+w)
            y = (y0,y0+h,y0+h)
        elif letter == &#34;_&#34;:
            x = (x0,x0+w,x0+w)
            y = (y0,y0,y0)
        else:
            raise ValueError(f&#34;the letter {letter} is unknown/undocumented&#34;)
        return x,y


    @property
    def _is_letter_crossing(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment crossing y=0&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_crossing_from_positive(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment crossing y=0 from y&gt;0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_crossing_from_negative(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment crossing y=0 from y&lt;0&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_increasing(self):
        &#34;&#34;&#34;Return True if the letter codes for an increasing segment&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:True,&#34;C&#34;:True,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_decreasing(self):
        &#34;&#34;&#34;Return True if the letter codes for an decreasing segment&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:True,&#34;Y&#34;:True,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_constant(self):
        &#34;&#34;&#34;Return True if the letter codes for a constant segment, y=0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:True}
    @property
    def _is_letter_starting_positive(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment starting with y&gt;0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:True,&#34;X&#34;:True,&#34;Y&#34;:False,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_starting_negative(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment crossing y=0&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:True,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:True,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_ending_positive(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment ending with y&gt;0&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:False,&#34;C&#34;:True,&#34;X&#34;:True,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_ending_negative(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment ending with y&lt;0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:True,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:True,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_starting_from_zero(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment staring from 0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:True,&#34;X&#34;:False,&#34;Y&#34;:True,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_ending_at_zero(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment ending at 0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:True,&#34;C&#34;:False,&#34;X&#34;:True,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:False}


    def get_entropy(self, scale):
        &#34;&#34;&#34;Calculate Shannon entropy for encoded signal.&#34;&#34;&#34;
        letters = self.codes[scale][&#39;letters&#39;]
        _, counts = np.unique(list(letters), return_counts=True)
        return entropy(counts, base=2)

    def get_code(self, scale):
        &#34;&#34;&#34;Retrieve encoded data for a specific scale.&#34;&#34;&#34;
        return self.codes[scale]

    def find_sequence(self, pattern, scale):
        &#34;&#34;&#34;Find occurrences of a specific letter pattern in encoded sequence.&#34;&#34;&#34;
        sequence = self.codes[scale][&#39;letters&#39;]
        positions = []
        idx = sequence.find(pattern)
        while idx != -1:
            positions.append(idx)
            idx = sequence.find(pattern, idx + 1)
        return positions

    def reconstruct_signal(self, scale, return_signal=True):
        &#34;&#34;&#34;
        Reconstruct the signal from symbolic features (e.g., YAZB).

        Parameters
        ----------
        scale : int
            Scale to use for reconstruction.
        return_signal : bool
            If True, return a `signal` object. Else return y array.

        Returns
        -------
        signal or np.ndarray
            Reconstructed signal.
        &#34;&#34;&#34;
        coef = self.cwt_coeffs[scale]
        peaks = self.find_sequence(&#39;YAZB&#39;, scale)
        y = np.zeros_like(self.signal)

        for peak in peaks:
            pos = peak * scale
            width = scale
            height = coef[peak]
            y += height * np.exp(-((np.arange(len(y)) - pos) / (0.6006 * width)) ** 2)

        if return_signal:
            from signal import signal as Signal
            return Signal(x=self.x.copy(), y=y, name=f&#34;reconstructed_{self.name}&#34;,
                          x_label=&#34;x&#34;, y_label=&#34;reconstructed&#34;, y_unit=&#34;a.u.&#34;)
        return y

    def align_with(self, other, scale=1):
        &#34;&#34;&#34;
        Align symbolic sequences and compute mutual entropy.

        Returns:
            SimpleNamespace: with fields
                - seq1_aligned (str)
                - seq2_aligned (str)
                - aligned_signal (list of tuples)
                - mutual_entropy (float)
        &#34;&#34;&#34;
        seq1 = self.codes[scale][&#39;letters&#39;]
        seq2 = other.codes[scale][&#39;letters&#39;]
        aligner = PairwiseAligner()
        aligner.mode = &#39;global&#39;
        alignment = aligner.align(seq1, seq2)[0]
        a1 = self.reconstruct_aligned_string(seq1, alignment.aligned[0])
        a2 = self.reconstruct_aligned_string(seq2, alignment.aligned[1])
        pairs = list(zip(a1, a2))
        shared = &#39;&#39;.join(a if a == b else &#39;_&#39; for a, b in pairs)
        H = self.entropy_from_string
        return SimpleNamespace(
            seq1_aligned=a1,
            seq2_aligned=a2,
            aligned_signal=pairs,
            mutual_entropy=H(a1) + H(a2) - 2 * H(shared)
        )

    @staticmethod
    def reconstruct_aligned_string(seq, aligned):
        &#34;&#34;&#34;Fast reconstruction of aligned signals&#34;&#34;&#34;
        result, last = [], 0
        for start, end in aligned:
            result.extend([&#39;-&#39;] * (start - last))
            result.extend(seq[start:end])
            last = end
        return &#39;&#39;.join(result)

    @staticmethod
    def entropy_from_string(s):
        &#34;&#34;&#34;return the entropy of a string&#34;&#34;&#34;
        _, counts = np.unique(list(s), return_counts=True)
        return entropy(counts, base=2)

    @staticmethod
    def print_alignment(seq1, seq2, width=80):
        &#34;&#34;&#34;print aligned sequences&#34;&#34;&#34;
        for i in range(0, len(seq1), width):
            s1 = seq1[i:i+width]
            s2 = seq2[i:i+width]
            match = &#39;&#39;.join(&#39;|&#39; if a == b else &#39; &#39; for a, b in zip(s1, s2))
            print(s1)
            print(match)
            print(s2)
            print()

    def __repr__(self):
        total = sum(len(c[&#39;letters&#39;]) for c in self.codes.values()) or 1
        ratio = len(self.signal) / total
        print(f&#34;&lt;DNAsignal(length={len(self.signal)}, scales={self.scales}, &#34;
                f&#34;transforms={len(self.cwt_coeffs)}, compression_ratio={ratio:.2f}, dtype={self.dtype.__name__})&gt;&#34;,sep=&#34;\n&#34;)
        return str(self)

    def __str__(self):
        return f&#34;&lt;DNAsignal(signal_length={len(self.signal)}, filtered={&#39;Yes&#39; if self.filtered_signal is not None else &#39;No&#39;})&gt;&#34;

    @staticmethod
    def synthetic_signal(x, peaks, baseline=None):
        &#34;&#34;&#34;Generate flexible synthetic signals. (obsolete)&#34;&#34;&#34;
        y = np.zeros_like(x)
        for pos, width, height in peaks:
            y += height * np.exp(-((x - pos) / (0.6006 * width)) ** 2)
        if baseline:
            y += baseline(x)
        return y

    def plot_signals(self, scales=None):
        &#34;&#34;&#34;Plot signals.&#34;&#34;&#34;
        if scales is None:
            scales = self.scales
        plt.figure(figsize=(10, 6))
        plt.plot(self.signal, label=&#39;Original Signal&#39;, linewidth=4, color=&#34;k&#34;)
        for scale in scales:
            plt.plot(self.cwt_coeffs[scale], label=f&#39;Scale {scale}&#39;, linewidth=2, alpha=0.7)
        plt.legend()
        plt.title(&#34;Signal and Transformed Scales&#34;)
        plt.x_label(f&#34;{self.x_label} [{self.x_unit}]&#34;)
        plt.y_label(f&#34;{self.y_label} [{self.y_unit}]&#34;)
        plt.show()

    def plot_transforms(self, indices=None, **kwargs):
        &#34;&#34;&#34;
        Plot the stored CWT-transformed signals as a signal collection.

        Parameters
        ----------
        indices : list[int or str], optional
            Specific scales or names to plot.
        kwargs : passed to `signal_collection.plot`
        &#34;&#34;&#34;
        if not hasattr(self, &#34;transforms&#34;):
            raise AttributeError(&#34;No transformed signals found. Run `compute_cwt()` first.&#34;)
        self.transforms.plot(indices=indices, title=f&#34;CWT Transforms: {self.name}&#34;, **kwargs)

    def plot_codes(self, scale, ax=None, colormap=None, alpha=0.4):
        &#34;&#34;&#34;
        Plot the symbolic DNA-like encoding as colored triangle segments.

        Parameters
        ----------
        scale : int
            The scale at which the signal was encoded.
        ax : matplotlib.axes.Axes, optional
            Axis to draw on. If None, a new figure is created.
        colormap : dict, optional
            Custom mapping of letters to colors. Default uses 7 distinct colors.
        alpha : float
            Transparency for the patches. Default is 0.4.
        &#34;&#34;&#34;

        if ax is None:
            fig, ax = plt.subplots(figsize=(12, 5))
        else:
            fig = plt.gcf()
            ax = plt.gca()

        # Default color mapping
        default_colormap = {
            &#39;A&#39;: &#39;DeepPink&#39;,&#39;B&#39;: &#39;OrangeRed&#39;, &#39;C&#39;: &#39;Gold&#39;,
            &#39;X&#39;: &#39;DeepSkyBlue&#39;,&#39;Y&#39;: &#39;DodgerBlue&#39;, &#39;Z&#39;: &#39;Purple&#39;,
            &#39;_&#39;: &#39;gray&#39;
        }
        cmap = colormap or default_colormap

        # Flags
        cross_flags = self._is_letter_crossing

        # Retrieve segment data
        code_data = self.codes[scale]
        letters = code_data[&#39;letters&#39;]
        widths = code_data[&#39;widths&#39;]
        heights = code_data[&#39;heights&#39;]
        xloc = code_data[&#39;xloc&#39;]
        coef = self.cwt_coeffs[scale]
        x = self.x if hasattr(self, &#39;x&#39;) and self.x is not None else np.arange(len(coef))

        # Generate path data
        last_y = 0.0
        patchxy = []

        # Process segments with continuity enforcement
        nletters = len(letters)
        for i in range(nletters):
            letter = letters[i]
            repeatedletter_withprevious = letter if i&gt;0 else False
            repeatedletter_withnext = letter if i&lt;(nletters-1) else False
            repeated = repeatedletter_withprevious or repeatedletter_withnext
            y0 = last_y if cross_flags[letter] or repeated else 0.0
            x0, w, h = xloc[i][0], widths[i], heights[i]
            last_y = y0 + h
            x,y = self._get_triangle_from_letter(letter,x0,y0,w,h)
            triangle = [[x[0], y[0]], [x[1], y[1]], [x[2], y[2]], [x[0], y[0]]]
            patchxy.append(triangle)

        # Plot patches
        for letter,verts in zip(letters,patchxy):
            poly = Polygon(verts, closed=True, color=cmap.get(letter, &#39;black&#39;), alpha=alpha)
            ax.add_patch(poly)

        # Plot raw and transformed signals
        ax.plot(self.x, self.signal, color=&#39;black&#39;, linewidth=3, label=&#39;Original Signal&#39;)
        ax.plot(self.x, coef, color=&#39;blue&#39;, linewidth=2, label=f&#39;CWT Scale {scale}&#39;)
        ax.set_xlabel(f&#34;{self.x_label} [{self.x_unit}]&#34;)
        ax.set_ylabel(f&#34;{self.y_label} [{self.y_unit}]&#34;)
        ax.set_title(f&#34;Symbolic Segments (Scale {scale})&#34;)
        ax.legend()
        ax.set_xlim([self.x[0], self.x[-1]])
        ax.axhline(0, color=&#39;k&#39;, linewidth=0.5, linestyle=&#39;:&#39;)
        plt.tight_layout()
        plt.show()
        return fig

    @staticmethod
    def _pairwiseEntropyDistance(list_DNAsignals, scale=None,
                  engine=None, engineOpts=None,):
        &#34;&#34;&#34;
        Calculate excess-entropy pairwise distances.

        Parameters
        ----------
        list_DNAsignals : list of valid DNAsignals (mandatory)
        scale           : int (mandatory)
        engine          : {&#39;difflib&#39;, &#39;bio&#39;} or None (default)
        engineOpts      : dict, optional (alignment parameters for the selected engine)

        Returns
        -------
        D      : nxn np.array of excess entropy distances (H(A) + H(B) - 2 * H(A*B))
        names  : list of signal names
        &#34;&#34;&#34;

        if not isinstance(list_DNAsignals, list):
            raise TypeError(f&#34;list_DNAsignals must be list not a {type(list_DNAsignals).__name__}&#34;)
        for o in list_DNAsignals:
            if not isinstance(o, DNAsignal):
                raise TypeError(f&#34;all listed elements must be a DNAsignal not a {type(o).__name__}&#34;)
        if scale is None or not isinstance(scale, int):
            raise TypeError(f&#34;scale must be an int not a {type(scale).__name__}&#34;)
        if scale &lt;= 0:
            raise ValueError(&#34;scale must be positive&#34;)

        n = len(list_DNAsignals)
        D = np.zeros((n, n), dtype=np.float64)

        total_pairs = n * (n - 1) // 2
        pair_index = 0
        start_time = time()

        with tqdm(total=total_pairs, desc=&#34;Pairwise distances&#34;, unit=&#34;pair&#34;) as pbar:
            for i in range(n):
                A = list_DNAsignals[i].codesfull[scale]
                for j in range(i):
                    B = list_DNAsignals[j].codesfull[scale]
                    A.align(B, engine=engine, engineOpts=engineOpts)
                    D[i, j] = A.excess_entropy(B)
                    pair_index += 1
                    pbar.update(1)
                    # Optional: show elapsed/ETA in tqdm (already included by default)

        D += D.T
        names = [o.name for o in list_DNAsignals]
        elapsed = time() - start_time
        print(f&#34;Pairwise distances computation completed in {elapsed:.2f} seconds.&#34;)
        return DNApairwiseAnalysis(D,names,list_DNAsignals)

    @staticmethod
    def _pairwiseJaccardMotifDistance(list_DNAsignals, scale=None,
                                       pattern=&#39;YAZB&#39;, minlen=4,
                                       classification=&#39;any&#39;,  # &#39;canonical&#39;, &#39;variant&#39;, or &#39;any&#39;
                                       plot=True):
        &#34;&#34;&#34;
        Compute pairwise Jaccard distances based on motif presence across symbolic DNAstr sequences.

        Parameters
        ----------
        list_DNAsignals : list of DNAsignal
            List of signals with .codesfull at given scale.
        scale : int
            Scale index for accessing .codesfull[scale].
        pattern : str
            Motif pattern to look for (default &#39;YAZB&#39;).
        minlen : int
            Minimum length of valid motifs.
        classification : {&#39;canonical&#39;, &#39;variant&#39;, &#39;any&#39;}
            Filter for motif type.
        plot : bool
            Whether to plot motif positions for each sequence.

        Returns
        -------
        D : np.ndarray
            Symmetric pairwise Jaccard distance matrix.
        names : list of str
            List of DNAsignal names.
        &#34;&#34;&#34;
        if not isinstance(list_DNAsignals, list):
            raise TypeError(&#34;list_DNAsignals must be a list.&#34;)
        if scale is None or not isinstance(scale, int) or scale &lt;= 0:
            raise ValueError(&#34;scale must be a positive integer.&#34;)

        n = len(list_DNAsignals)
        motif_sets = []

        for i, obj in enumerate(list_DNAsignals):
            if not isinstance(obj, DNAsignal):
                raise TypeError(f&#34;Element {i} is not a DNAsignal.&#34;)
            dna = obj.codesfull[scale]
            df = dna.extract_motifs(pattern=pattern, minlen=minlen, plot=False)
            if classification == &#39;canonical&#39;:
                df = df[df[&#39;classification&#39;] == &#39;canonical&#39;]
            elif classification == &#39;variant&#39;:
                df = df[df[&#39;classification&#39;] == &#39;variant&#39;]
            # Represent a sequence as set of motif *start* positions
            motif_set = set(df[&#39;start&#39;]) if not df.empty else set()
            motif_sets.append(motif_set)

        if plot:
            # Assume all DNAstr have same length, dx, and iloc
            L = len(list_DNAsignals[0].codesfull[scale])
            dx = list_DNAsignals[0].codesfull[scale].dx
            iloc = list_DNAsignals[0].codesfull[scale].iloc
            x_start = iloc * dx if isinstance(iloc, int) else iloc[0] * dx
            x_vals = np.arange(L) * dx + x_start
            prevalence = np.zeros(L, dtype=int)

            for obj in list_DNAsignals:
                dna = obj.codesfull[scale]
                df = dna.extract_motifs(pattern=pattern, minlen=minlen, plot=False)
                if classification == &#39;canonical&#39;:
                    df = df[df[&#39;classification&#39;] == &#39;canonical&#39;]
                elif classification == &#39;variant&#39;:
                    df = df[df[&#39;classification&#39;] == &#39;variant&#39;]
                for _, row in df.iterrows():
                    start = row[&#39;start&#39;]
                    width = row[&#39;end&#39;] - row[&#39;start&#39;]  # assuming inclusive-exclusive
                    prevalence[start:start + width] += 1

            plt.figure(figsize=(12, 4))
            plt.plot(x_vals, prevalence/n, marker=&#39;o&#39;, linestyle=&#39;-&#39;, alpha=0.8)
            plt.title(f&#34;Motif prevalence at each position for pattern &#39;{pattern}&#39;&#34;)
            plt.xlabel(&#34;x position&#34;)
            plt.ylabel(&#34;Number of sequences with motif coverage&#34;)
            plt.grid(True)
            plt.tight_layout()
            plt.show()

        D = np.zeros((n, n), dtype=np.float64)
        total_pairs = n * (n - 1) // 2
        pair_index = 0
        start_time = time()

        with tqdm(total=total_pairs, desc=&#34;Pairwise Jaccard (motif)&#34;, unit=&#34;pair&#34;) as pbar:
            for i in range(n):
                A = motif_sets[i]
                for j in range(i):
                    B = motif_sets[j]
                    intersection = len(A &amp; B)
                    union = len(A | B)
                    distance = 1.0 if union == 0 else 1 - intersection / union
                    D[i, j] = distance
                    pbar.update(1)

        D += D.T
        names = [o.name for o in list_DNAsignals]
        elapsed = time() - start_time
        print(f&#34;Jaccard motif-based distance computation completed in {elapsed:.2f} seconds.&#34;)
        return DNApairwiseAnalysis(D, names, list_DNAsignals)

    @staticmethod
    def _pairwiseJensenShannonDistance(list_DNAsignals, scale=None):
        &#34;&#34;&#34;
        Calculate pairwise Jensen-Shannon distances between DNAstr codes at a given scale.

        Parameters
        ----------
        list_DNAsignals : list of DNAsignal
            List of valid DNAsignal instances.
        scale : int
            Scale index to select the code from `codesfull`.

        Returns
        -------
        DNApairwiseAnalysis
            Matrix object containing pairwise Jensen-Shannon distances.
        &#34;&#34;&#34;
        if not isinstance(list_DNAsignals, list):
            raise TypeError(&#34;list_DNAsignals must be a list&#34;)
        for o in list_DNAsignals:
            if not isinstance(o, DNAsignal):
                raise TypeError(f&#34;All elements must be DNAsignal, not {type(o).__name__}&#34;)
        if scale is None or not isinstance(scale, int):
            raise TypeError(&#34;scale must be an integer&#34;)
        if scale &lt; 0:
            raise ValueError(&#34;scale must be non-negative&#34;)

        n = len(list_DNAsignals)
        D = np.zeros((n, n), dtype=np.float64)
        total_pairs = n * (n - 1) // 2
        start_time = time()

        with tqdm(total=total_pairs, desc=&#34;Jensen-Shannon&#34;, unit=&#34;pair&#34;) as pbar:
            for i in range(n):
                A = list_DNAsignals[i].codesfull[scale]
                for j in range(i):
                    B = list_DNAsignals[j].codesfull[scale]
                    D[i, j] = A.jensen_shannon(B)
                    pbar.update(1)

        D += D.T
        names = [o.name for o in list_DNAsignals]
        elapsed = time() - start_time
        print(f&#34;Jensen-Shannon distance matrix completed in {elapsed:.2f} seconds.&#34;)
        return DNApairwiseAnalysis(D, names, list_DNAsignals)

    @staticmethod
    def _pairwiseLevenshteinDistance(list_DNAsignals, scale=None,
                                      use_alignment=False,
                                      engine=None,
                                      engineOpts=None,
                                      forced=False):
        &#34;&#34;&#34;
        Compute pairwise Levenshtein distances between codes at a given scale.

        Parameters
        ----------
        list_DNAsignals : list of DNAsignal
            List of DNAsignal objects to compare.
        scale : int
            Scale index in codesfull.
        use_alignment : bool, optional
            If True, align codes before computing distance. Default is Full.
        engine : str, optional
            Alignment engine (&#39;difflib&#39; or &#39;bio&#39;) if use_alignment is True.
        engineOpts : dict, optional
            Parameters for the alignment engine.
        forced : bool, optional
            If True, allow forced alignment even if dx mismatches.

        Returns
        -------
        DNApairwiseAnalysis
            Object holding the nxn Levenshtein distance matrix.
        &#34;&#34;&#34;
        if not isinstance(list_DNAsignals, list):
            raise TypeError(&#34;list_DNAsignals must be a list&#34;)
        for o in list_DNAsignals:
            if not isinstance(o, DNAsignal):
                raise TypeError(f&#34;All elements must be DNAsignal, not {type(o).__name__}&#34;)
        if scale is None or not isinstance(scale, int):
            raise TypeError(&#34;scale must be an integer&#34;)
        if scale &lt; 0:
            raise ValueError(&#34;scale must be non-negative&#34;)

        n = len(list_DNAsignals)
        D = np.zeros((n, n), dtype=np.float64)
        total_pairs = n * (n - 1) // 2
        start_time = time()

        with tqdm(total=total_pairs, desc=&#34;Levenshtein&#34;, unit=&#34;pair&#34;) as pbar:
            for i in range(n):
                A = list_DNAsignals[i].codesfull[scale]
                for j in range(i):
                    B = list_DNAsignals[j].codesfull[scale]
                    D[i, j] = A.levenshtein(B,
                                            use_alignment=use_alignment,
                                            engine=engine,
                                            engineOpts=engineOpts,
                                            forced=forced)
                    pbar.update(1)

        D += D.T
        names = [o.name for o in list_DNAsignals]
        elapsed = time() - start_time
        print(f&#34;Levenshtein distance matrix completed in {elapsed:.2f} seconds.&#34;)
        return DNApairwiseAnalysis(D, names, list_DNAsignals)


# ------------------------
# DNAstr class
# ------------------------
class DNAstr(str):
    &#34;&#34;&#34;
    A symbolic DNA-like sequence class supporting alignment, entropy analysis,
    edit-distance metrics, and signal reconstruction from symbolic codes.

    Extended from `str`, it is designed for symbolic transformations of signals
    (e.g., wavelet-encoded GC-MS peaks or time series).

    Main Features
    -------------
    - Supports symbolic operations for pattern recognition, entropy, alignment.
    - Encodes x-resolution (`dx`), original index (`iloc`), and physical x-range (`xloc`).
    - Aligns sequences with visual inspection and rich diffs.
    - Converts symbolic strings into synthetic numerical signals.

    Operators
    ---------
    + : concatenate two DNAstr objects
    - : symbolic difference after alignment (mismatches only)
    == : equality comparison (exact content and dx)

    Key Methods
    -----------
    - __init__ / __new__      : Constructor with metadata (`dx`, `iloc`, `xloc`)
    - align(other)            : Align this DNAstr to another, update mask and aligned views
    - wrapped_alignment()     : Pretty terminal view of the alignment with colors and symbols
    - html_alignment()        : Rich HTML display of the alignment (Jupyter)
    - plot_alignment()        : Visualize waveform alignment with symbolic signals
    - plot_mask()             : Color block plot showing matches/mismatches/gaps
    - find(pattern, regex=False) : Search for symbolic patterns with fuzziness or regex
    - to_signal()             : Convert symbolic code into synthetic signal (NumPy)
    - vectorized()            : Convert string to integer codes
    - summary()               : Print entropy and character frequencies
    - mutation_counts         : Property: {&#39;matches&#39;, &#39;mismatches&#39;, &#39;indels&#39;}
    - entropy                 : Property: Shannon entropy
    - mutual_entropy(other)   : Mutual entropy of two sequences
    - excess_entropy(other)   : Excess entropy H1 + H2 - 2 * H12
    - jensen_shannon(other)   : Jensen-Shannon divergence
    - jaccard(other)          : Jaccard similarity
    - alignment_stats         : Property: Match, substitution, gap counts
    - score(normalized=True) : Alignment score (fraction of matches)
    - has(other: str)         : Check if a pattern or substring exists

    Attributes
    ----------
    dx : float
        Average resolution along the x-axis.
    iloc : int or tuple of int
        Positional index or index range in the source DNA string.
    xloc : float or tuple of float
        Corresponding x-value(s) for the symbolic sequence.
    aligned_with : str or None
        Aligned form of self with insertions (spaces) where needed.
    other_copy : str or None
        Aligned form of the reference sequence.
    ref_hash : str or None
        SHA256 hash of the aligned reference sequence.
    mask : str or None
        Alignment mask: &#39;=&#39; for matches, &#39;*&#39; for substitutions, &#39; &#39; for gaps.
    engine : str
        Alignment engine: &#39;difflib&#39; or &#39;bio&#39;.
    engineOpts : dict
        Options passed to the alignment engine.

    Examples
    --------
    &gt;&gt;&gt; s1 = DNAstr(&#34;YYAAZZBB&#34;, dx=0.5)
    &gt;&gt;&gt; s2 = DNAstr(&#34;YAABZBB&#34;, dx=0.5)
    &gt;&gt;&gt; s1.align(s2)
    &gt;&gt;&gt; print(s1.wrapped_alignment(40))
    &gt;&gt;&gt; s1.plot_alignment()
    &gt;&gt;&gt; segments = s1.find(&#34;YAZB&#34;)
    &gt;&gt;&gt; segments[0].to_signal().plot()

    &#34;&#34;&#34;

    def __new__(cls, content, dx=1.0, iloc=0, xloc=None, x_label=&#34;index&#34;, x_unit=&#34;-&#34;,
                engine=&#34;difflib&#34;, engineOpts=None):
        &#34;&#34;&#34;
        Construct a new DNAstr object.

        Parameters
        ----------
        content : str
            The symbolic DNA-like string content.
        dx : float, optional
            Nominal resolution (default: 1.0).
        iloc : int, optional
            Integer index or start index of the sequence (default: 0).
        xloc : float, optional
            X-coordinate of the sequence origin.
        engine : {&#39;difflib&#39;, &#39;bio&#39;}, optional
            Default alignment engine to use.
        engineOpts : dict, optional
            Dictionary of alignment parameters for the selected engine.

        Returns
        -------
        DNAstr
            Initialized DNAstr instance.
        &#34;&#34;&#34;
        obj = str.__new__(cls, content)
        obj.dx = dx
        obj.iloc = iloc
        obj.xloc = xloc
        obj.x_label = x_label
        obj.x_unit = x_unit
        obj.aligned_with = None
        obj.other_copy = None
        obj.ref_aligned = None
        obj.ref_hash = None
        obj.mask = None
        if engine not in (&#34;difflib&#34;, &#34;bio&#34;):
            raise ValueError(&#39;engine must be &#34;difflib&#34; or &#34;bio&#34;&#39;)
        obj.engine = engine
        obj.engineOpts = engineOpts or {}
        obj._hash = hashlib.sha256(obj.encode()).hexdigest()
        return obj

    def __hash__(self):
        &#34;&#34;&#34;
        Return hash combining the string content and dx.

        Returns
        -------
        int
            Hash of the DNAstr object.
        &#34;&#34;&#34;
        return hash((str(self), self.dx))

    def summary(self):
        &#34;&#34;&#34;
        Summarize the DNAstr with key stats: length, unique letters, entropy, etc.

        Returns
        -------
        dict
            Dictionary containing length, letter frequency, Shannon entropy, and dx.
        &#34;&#34;&#34;
        length = len(self)
        freqs = Counter(self)
        prob = np.array(list(freqs.values())) / length
        entropy = -np.sum(prob * np.log2(prob))
        return {
            &#39;length&#39;: length,
            &#39;letters&#39;: dict(freqs),
            &#39;entropy (Shannon)&#39;: entropy,
            &#39;dx&#39;: self.dx
        }

    def vectorized(self, codebook={&#34;A&#34;:1,&#34;B&#34;:2,&#34;C&#34;:3,&#34;X&#34;:4,&#34;Y&#34;:5,&#34;Z&#34;:6,&#34;_&#34;:0}):
        &#34;&#34;&#34;
        Map the DNAstr content to an integer array using a codebook.

        Parameters
        ----------
        codebook : dict, optional
            Dictionary mapping characters to integer values.
            default = {&#34;A&#34;:1,&#34;B&#34;:2,&#34;C&#34;:3,&#34;X&#34;:4,&#34;Y&#34;:5,&#34;Z&#34;:6,&#34;_&#34;:0}
            None will generate a codebook based on current symbols only

        Returns
        -------
        np.ndarray
            Vectorized integer representation of the string.
        &#34;&#34;&#34;
        from collections import OrderedDict
        if codebook is None:
            unique_chars = list(OrderedDict.fromkeys(self))
            codebook = {c: i for i, c in enumerate(unique_chars)}
        return np.array([codebook.get(c, -1) for c in self], dtype=int)

    def __eq__(self, other):
        &#34;&#34;&#34;
        Check equality based on symbolic content and dx resolution.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr instance.

        Returns
        -------
        bool
            True if both content and dx are equal.
        &#34;&#34;&#34;
        return isinstance(other, DNAstr) and str.__eq__(self, other) and self.dx == other.dx


    def __add__(self, other):
        &#34;&#34;&#34;
        Concatenate two DNAstr instances with identical dx values.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr sequence.

        Returns
        -------
        DNAstr
            Concatenated DNAstr sequence.

        Raises
        ------
        TypeError
            If the argument is not a DNAstr.
        ValueError
            If `dx` values differ.
        &#34;&#34;&#34;
        if not isinstance(other, DNAstr):
            raise TypeError(&#34;Can only concatenate DNAstr (not &#39;{}&#39;)&#34;.format(type(other).__name__))
        if self.dx != other.dx:
            raise ValueError(&#34;dx mismatch. Use forced=True to override.&#34;)
        return DNAstr(str.__add__(self, other), dx=self.dx, iloc=self.iloc, xloc=self.xloc,
                                   x_label=self.x_label, x_unit=self.x_unit)

    def __sub__(self, other):
        &#34;&#34;&#34;
        Subtract two DNAstr sequences by aligning and removing matched regions.

        Parameters
        ----------
        other : DNAstr
            DNAstr instance to align and subtract.

        Returns
        -------
        DNAstr
            A new DNAstr containing mismatched symbols only.
        &#34;&#34;&#34;
        if not isinstance(other, DNAstr):
            raise TypeError(&#34;Can only subtract DNAstr instances&#34;)
        self.align(other)
        mismatch = &#39;&#39;.join([a for a, b in zip(self.aligned_with, self.other_copy) if a != b and b != &#39; &#39;])
        return DNAstr(mismatch, dx=self.dx, iloc=self.iloc, xloc=self.xloc,
                                   x_label=self.x_label, x_unit=self.x_unit)

    @property
    def mutation_counts(self):
        &#34;&#34;&#34;Counts of insertions, deletions/substitutions, and matches.&#34;&#34;&#34;
        m = self.mask
        return {
            &#39;matches&#39;: m.count(&#39;=&#39;),
            &#39;mismatches&#39;: m.count(&#39;*&#39;),
            &#39;indels&#39;: m.count(&#39; &#39;)
        }
    @property
    def entropy(self):
        &#34;&#34;&#34;Compute the Shannon entropy of the DNAstr sequence&#34;&#34;&#34;
        count = Counter(self)
        total = sum(count.values())
        return -sum((v / total) * np.log2(v / total) for v in count.values())

    def mutual_entropy(self, other=None):
        &#34;&#34;&#34;Compute the Shannon mutual entropy of two DNAstr sequences from their aligned segments&#34;&#34;&#34;
        if other is not None and not isinstance(other,DNAstr):
            raise TypeError(f&#34;other must be a DNAstr not a {type(self).__name__}&#34;)
        if other is None and (not hasattr(self,&#34;aligned_with&#34;) or self.aligned_with is None):
            raise ValueError(&#34;align the code with .align(other) or provide other&#34;)
        if isinstance(other,DNAstr):
            self.align(other)
        aligned = self.aligned_code
        count = Counter(aligned)
        total = sum(count.values())
        return -sum((v / total) * np.log2(v / total) for v in count.values())

    def excess_entropy(self, other):
        &#34;&#34;&#34;Compute the excess Shannon entropy of two DNAstr sequences H(A)+H(B)-2*H(AB)&#34;&#34;&#34;
        return self.entropy + other.entropy - 2 * self.mutual_entropy(other)

    def jensen_shannon(self, other, base=2):
        &#34;&#34;&#34;
        Compute the Jensen-Shannon distance between self and another DNAstr.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr instance.
        base : float, optional
            Base for the logarithm (default: 2)

        Returns
        -------
        float
            Jensen-Shannon distance.
        &#34;&#34;&#34;
        v1 = Counter(self)
        v2 = Counter(other)
        all_keys = sorted(set(v1) | set(v2))
        p = np.array([v1.get(k, 0) for k in all_keys], dtype=float)
        q = np.array([v2.get(k, 0) for k in all_keys], dtype=float)
        p /= p.sum()
        q /= q.sum()
        return jensenshannon(p, q, base=base)


    def levenshtein(self, other, use_alignment=True, engine=None, engineOpts=None, forced=False):
        &#34;&#34;&#34;
        Compute the Levenshtein distance between this DNAstr and another one.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr object to compare against.
        use_alignment : bool, default=True
            If True, uses the aligned sequences (computed if necessary).
            If False, compares the raw sequences directly.
        engine : {&#39;difflib&#39;, &#39;bio&#39;}, optional
            Alignment engine to use if alignment is needed.
        engineOpts : dict, optional
            Parameters for the selected alignment engine.
        forced : bool, default=False
            Force alignment even if dx values differ.

        Returns
        -------
        dist : int
            Levenshtein distance between the two sequences (aligned or raw).

        Examples
        --------
        A = DNAstr(&#34;YAZBZAY&#34;)
        B = DNAstr(&#34;YAZBZZY&#34;)
        A.levenshtein_distance(B, use_alignment=False)  # raw
        A.levenshtein_distance(B, use_alignment=True, engine=&#34;bio&#34;)  # aligned
        &#34;&#34;&#34;
        if not isinstance(other, DNAstr):
            raise TypeError(&#34;Argument must be a DNAstr instance&#34;)
        if use_alignment:
            self.align(other, engine=engine, engineOpts=engineOpts, forced=forced)
            s1, s2 = self.aligned_with, self.other_copy
        else:
            s1, s2 = str(self), str(other)
        return Levenshtein.distance(s1, s2)


    def jaccard(self, other):
        &#34;&#34;&#34;
        Compute the Jaccard distance between two DNAstr sequences.

        Parameters
        ----------
        other : DNAstr
            The other DNAstr sequence to compare with.

        Returns
        -------
        float
            Jaccard distance: 1 - (intersection / union) of unique letters.
        &#34;&#34;&#34;
        set_self = set(self)
        set_other = set(other)
        intersection = set_self &amp; set_other
        union = set_self | set_other
        return 1 - len(intersection) / len(union) if union else 0.0

    def align(self, other, engine=None, engineOpts=None, forced=False):
        &#34;&#34;&#34;
        Align this DNAstr sequence to another, allowing insertions/deletions to maximize matches.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr object to align with.
        engine : {&#39;difflib&#39;, &#39;bio&#39;} or None
            Alignment engine to use:
                - &#39;difflib&#39;: uses difflib.SequenceMatcher (fast, approximate).
                - &#39;bio&#39;   : uses Bio.Align.PairwiseAligner (biologically inspired global alignment).
            If None, defaults to self.engine.
        engineOpts : dict, optional
            Dictionary of alignment parameters for the selected engine.
        forced : bool
            If True, allow alignment even if `dx` values differ. If False (default), a mismatch in
            `dx` will raise an error to prevent incorrect alignment of signals with different sampling.

        Returns
        -------
        aligned_self : str
            Aligned version of this sequence (with gaps inserted where needed).
        aligned_other : str
            Aligned version of the other sequence.

        Notes
        -----
        The alignment is symmetric and permanent: both sequences are aligned with
        gaps introduced (spaces) to preserve positional correspondence. A hash of
        the aligned `other` sequence is stored to detect redundant alignments.

        A match mask (`self.mask`) is generated with:
            &#39;=&#39; for exact matches,
            &#39;*&#39; for mismatches (substitutions),
            &#39; &#39; for insertions/deletions (gaps).

        The method updates:
            - self.aligned_with
            - self.other_copy
            - self.mask
            - self.ref_hash

        Example:
        --------
        S1 = DNAstr(&#34;AABBCC&#34;)
        S2 = DNAstr(&#34;AACBCC&#34;)
        S1.align(S2,&#34;difflib&#34;)
        print(S1.mask)
        print(S1.wrapped_alignment())
        ==*===
        AACBCC
        || |||
        AABBCC

        S1 = DNAstr(&#34;AABBCC&#34;)
        S2 = DNAstr(&#34;AACBCC&#34;)
        S1.align(S2,&#34;bio&#34;)
        print(S1.mask)
        print(S1.wrapped_alignment())
        ==  ==
        AAB·CC
        ||  ||
        AA·BCC

        S1 = DNAstr(&#34;AABBCCXYZZZ&#34;)
        S2 = DNAstr(&#34;AACBCCZZXXX&#34;)
        S1.align(S2,&#34;bio&#34;)
        print(S1.mask)
        print(S1.wrapped_alignment())
        == *   ==
        AABCC··ZZ
        ||     ||
        AA·B·CCZZ

        &#34;&#34;&#34;
        if not isinstance(other, DNAstr):
            raise TypeError(&#34;Alignment requires another DNAstr instance&#34;)
        if not forced and self.dx != other.dx:
            raise ValueError(&#34;dx mismatch. Use forced=True to override.&#34;)
        if hasattr(other, &#39;ref_hash&#39;) and self.ref_hash is not None and self.ref_hash == other.ref_hash:
            return self.aligned_with, self.other_copy

        engine = engine or self.engine
        engineOpts = engineOpts or self.engineOpts.get(engine, {})

        if engine == &#39;difflib&#39;:
            sm = SequenceMatcher(None, other, self)
            aligned_self, aligned_other = [], []
            for tag, i1, i2, j1, j2 in sm.get_opcodes():
                if tag == &#39;equal&#39;:
                    aligned_self.extend(self[j1:j2])
                    aligned_other.extend(other[i1:i2])
                elif tag == &#39;replace&#39;:
                    aligned_self.extend(self[j1:j2])
                    aligned_other.extend(other[i1:i2])
                elif tag == &#39;insert&#39;:
                    aligned_self.extend(self[j1:j2])
                    aligned_other.extend(&#39; &#39; * (j2 - j1))
                elif tag == &#39;delete&#39;:
                    aligned_self.extend(&#39; &#39; * (i2 - i1))
                    aligned_other.extend(other[i1:i2])

        elif engine == &#39;bio&#39;:
            aligner = PairwiseAligner()
            for k, v in engineOpts.items():
                setattr(aligner, k, v)

            alignment = aligner.align(other, self)[0]  # Best alignment
            aligned_self = []
            aligned_other = []

            # These are lists of (start, end) index tuples for each sequence
            self_blocks = alignment.aligned[1]
            other_blocks = alignment.aligned[0]

            self_pos = 0
            other_pos = 0

            for (o_start, o_end), (s_start, s_end) in zip(other_blocks, self_blocks):
                # Fill gaps in other
                if o_start &gt; other_pos:
                    gap_len = o_start - other_pos
                    aligned_other.extend(other[other_pos:o_start])
                    aligned_self.extend([&#39; &#39;] * gap_len)
                    other_pos = o_start
                # Fill gaps in self
                if s_start &gt; self_pos:
                    gap_len = s_start - self_pos
                    aligned_self.extend(self[self_pos:s_start])
                    aligned_other.extend([&#39; &#39;] * gap_len)
                    self_pos = s_start

                # Aligned regions
                aligned_self.extend(self[s_start:s_end])
                aligned_other.extend(other[o_start:o_end])
                self_pos = s_end
                other_pos = o_end

            # Tail padding
            aligned_self.extend(self[self_pos:])
            aligned_other.extend([&#39; &#39;] * (len(self) - self_pos))
            aligned_other.extend(other[other_pos:])
            aligned_self.extend([&#39; &#39;] * (len(other) - other_pos))

        else:
            raise ValueError(&#34;Unknown alignment engine: choose &#39;difflib&#39; or &#39;bio&#39;&#34;)

        self.aligned_with = &#39;&#39;.join(aligned_self)
        self.other_copy = &#39;&#39;.join(aligned_other)
        if len(self.aligned_with) != len(self.other_copy):
            raise RuntimeError(&#34;Mismatch in alignment lengths: check alignment logic.&#34;)
        self.mask = &#39;&#39;.join(&#39;=&#39; if a == b else &#39;*&#39; if b != &#39; &#39; and a != &#39; &#39; else &#39; &#39;
                            for a, b in zip(self.aligned_with, self.other_copy))
        self.ref_hash = hashlib.sha256(self.other_copy.encode()).hexdigest()
        self.engine = engine
        self.engineOpts[engine] = engineOpts
        return self.aligned_with, self.other_copy

    @property
    def alignment_stats(self):
        &#34;&#34;&#34;Retrun DNAstr alignment statistics&#34;&#34;&#34;
        if self.mask is None:
            raise ValueError(&#34;No alignment performed yet.&#34;)
        return {
            &#34;matches&#34;: self.mask.count(&#39;=&#39;),
            &#34;substitutions&#34;: self.mask.count(&#39;*&#39;),
            &#34;gaps&#34;: self.mask.count(&#39; &#39;)
        }

    @property
    def aligned_code(self):
        &#34;&#34;&#34;return aligned code&#34;&#34;&#34;
        if not hasattr(self,&#34;aligned_with&#34;) or self.aligned_with is None:
            raise ValueError(&#34;the code is not aligned&#34;)
        return re.sub(r&#39;[^A-CX-Z]&#39;, &#39;&#39;, self.aligned_with)

    def score(self, normalized=True):
        &#34;&#34;&#34;
        Return an alignment score, optionally normalized.

        Parameters
        ----------
        normalized : bool
            If True (default), return score as a fraction of total aligned positions.

        Returns
        -------
        float
            Alignment score.
        &#34;&#34;&#34;
        stats = self.alignment_stats
        score = stats[&#34;matches&#34;]
        return score / len(self.mask) if normalized else score

    @staticmethod
    def _supports_color():
        &#34;&#34;&#34;Returns True if ther terminal supports colors&#34;&#34;&#34;
        return hasattr(sys.stdout, &#34;isatty&#34;) and sys.stdout.isatty() and os.getenv(&#34;TERM&#34;) not in (None, &#34;dumb&#34;)

    def wrapped_alignment(self, width=80, colors=True):
        &#34;&#34;&#34;
        Return a line-wrapped alignment view (multi-line), optionally color-coded
        for terminal/IPython usage (Spyder, Jupyter).

        Parameters
        ----------
        width : int
            Number of characters per line in wrapped display.
        colors : bool
            If True, use ANSI codes to highlight differences. May be overridden
            if terminal does not support ANSI (e.g., Spyder).

        Returns
        -------
        str
            Wrapped, optionally colorized alignment.
        &#34;&#34;&#34;
        if self.aligned_with is None or self.other_copy is None:
            raise ValueError(&#34;Alignment has not been computed yet.&#34;)

        match_mask = self.mask
        s1 = self.other_copy
        s2 = self.aligned_with

        if colors and not DNAstr._supports_color():
            colors = False

        def colorize(c, match):
            if not colors:
                return c
            if c == &#39; &#39;:
                return &#39;\x1b[90m·\x1b[0m&#39;
            elif match == &#39;|&#39;:
                return f&#39;\x1b[92m{c}\x1b[0m&#39;
            else:
                return f&#39;\x1b[91m{c}\x1b[0m&#39;

        lines = []
        for i in range(0, len(s1), width):
            s1_block = s1[i:i+width]
            s2_block = s2[i:i+width]
            msk_block = match_mask[i:i+width]
            s1c = &#39;&#39;.join(colorize(c, m) for c, m in zip(s1_block, msk_block))
            s2c = &#39;&#39;.join(colorize(c, m) for c, m in zip(s2_block, msk_block))
            match_line = &#39;&#39;.join(&#39;|&#39; if m == &#39;=&#39; else &#39; &#39; for m in msk_block)
            lines.extend([s1c, match_line, s2c, &#39;&#39;])
        return &#39;\n&#39;.join(lines)

    def html_alignment(self):
        &#34;&#34;&#34;
        Render the alignment using HTML with color coding:
        - green: match
        - blue: gap
        - red: substitution

        Returns
        -------
        None
            Displays HTML directly in Jupyter/Notebook environments.
        &#34;&#34;&#34;
        if not self.aligned_with or not self.other_copy:
            raise ValueError(&#34;Alignment not available. Call .align() first.&#34;)
        html = &#34;&lt;pre style=&#39;font-family: monospace;&#39;&gt;&#34;
        for a, b in zip(self.other_copy, self.aligned_with):
            if a == b:
                html += f&#34;&lt;span style=&#39;color:green&#39;&gt;{b}&lt;/span&gt;&#34;
            elif a == &#39; &#39; or b == &#39; &#39;:
                html += f&#34;&lt;span style=&#39;color:blue&#39;&gt;{b}&lt;/span&gt;&#34;
            else:
                html += f&#34;&lt;span style=&#39;color:red&#39;&gt;{b}&lt;/span&gt;&#34;
        html += &#34;&lt;/pre&gt;&#34;
        display(HTML(html))

    def __repr__(self):
        &#34;&#34;&#34;
        Return a short technical representation of the DNAstr instance.

        Returns
        -------
        str
            Description of alignment status and length.
        &#34;&#34;&#34;
        base = f&#34;&lt;DNAstr: {len(self)} symbols&#34;
        if self.aligned_with:
            base += f&#34; - aligned against &lt;HASH {self.ref_hash[:8]}&gt;&gt;&#34;
        else:
            base += &#34; - not aligned&gt;&#34;
        return base

    def __str__(self):
        &#34;&#34;&#34;
        String representation.

        Returns
        -------
        str
            Original string content.
        &#34;&#34;&#34;
        #return repr(self) if self.aligned_with else str.__str__(self)
        return super().__str__()

    def find(self, pattern, regex=False):
        &#34;&#34;&#34;
        Finds all fuzzy (or regex-based) occurrences of a DNA-like sequence pattern.

        Parameters
        ----------
        pattern : str
            The symbolic sequence to search for (e.g., &#34;YAZB&#34;).
        regex : bool, optional
            If False (default), interprets pattern as symbolic and inserts &#39;.&#39; between characters.
            If True, uses the raw pattern as a regular expression.

        Returns
        -------
        list of DNAstr
            A list of DNAstr slices with attributes:
                - iloc: (start_idx, end_idx)
                - xloc: (x_start, x_end)
                - width: segment width
        &#34;&#34;&#34;
        if not regex:
            # Turn &#39;YAZB&#39; into &#39;Y+A+Z+B+?&#39;
            pattern = &#39;&#39;.join(f&#34;{c}+&#34; for c in pattern)  # Greedy
        matches = []
        for m in re.finditer(pattern, str(self)):
            start, end = m.span()
            substr = self[start:end]
            dna = DNAstr(substr,
                         dx=self.dx,
                         iloc=(start,end),
                         xloc=(self.xloc[0]+start*self.dx,self.xloc[0]+end*self.dx),
                         x_label=self.x_label, x_unit=self.x_unit)
            dna.iloc = (start, end)
            if hasattr(self, &#34;xloc&#34;) and self.xloc is not None:
                x_start = self.xloc[0] + self.dx * start
                x_end = self.xloc[0] + self.dx * end
                dna.xloc = (x_start, x_end)
            else:
                dna.xloc = (start * self.dx, end * self.dx)
            dna.width = end - start
            matches.append(dna)
        return matches


    def to_signal(self):
        &#34;&#34;&#34;
        Converts the symbolic DNA sequence into a synthetic NumPy array mimicking the original wavelet-transformed signal.

        Rules per letter:
            - &#39;A&#39;: Crosses zero upward → linear from -1 to +1, zero in the middle
            - &#39;Z&#39;: Crosses zero downward → linear from +1 to -1, zero in the middle
            - &#39;B&#39;: Increasing negative → from -1 to 0
            - &#39;Y&#39;: Decreasing negative → from 0 to -1
            - &#39;C&#39;: Increasing positive → from 0 to +1
            - &#39;X&#39;: Decreasing positive → from +1 to 0
            - &#39;_&#39;: Flat at 0

        Returns
        -------
        numpy.ndarray
            Synthetic signal array matching the symbolic encoding.
        &#34;&#34;&#34;
        s = []
        i = 0
        while i &lt; len(self):
            letter = self[i]
            j = i
            while j &lt; len(self) and self[j] == letter:
                j += 1
            width = j - i
            if width &lt; 2:
                i = j
                continue  # skip invalid segments
            if letter == &#39;A&#39;:
                seg = np.linspace(-1.0, 1.0, width)
            elif letter == &#39;Z&#39;:
                seg = np.linspace(1.0, -1.0, width)
            elif letter == &#39;B&#39;:
                seg = np.linspace(-1.0, 0, width)
            elif letter == &#39;Y&#39;:
                seg = np.linspace(0, -1.0, width)
            elif letter == &#39;C&#39;:
                seg = np.linspace(0, 1.0, width)
            elif letter == &#39;X&#39;:
                seg = np.linspace(1, 0, width)
            else:  # &#39;_&#39;
                seg = np.zeros(width)

            s.append(seg)
            i = j
        y = np.concatenate(s)
        if self.xloc is None:
            x = None
        else:
            n = len(y)
            x0 = self.xloc[0] if isinstance(self.xloc,(tuple,list)) else self.xloc
            x = np.linspace(x0,x0+self.dx*n,n,endpoint=True,dtype=type(x0))
        return signal(x=x,y=y,name=self._hash)

    def plot_mask(self):
        &#34;&#34;&#34;
        Plot a color-coded mask of the alignment between sequences.

        Returns
        -------
        matplotlib.figure.Figure
            Matplotlib figure of the alignment mask.
        &#34;&#34;&#34;
        if not self.other_copy:
            raise ValueError(&#34;Alignment required for plotting.&#34;)
        fig, ax = plt.subplots(figsize=(12, 2))
        colors = {&#39;=&#39;: &#39;green&#39;, &#39;*&#39;: &#39;red&#39;, &#39; &#39;: &#39;gray&#39;}
        for i, (a, b, m) in enumerate(zip(self.aligned_with, self.other_copy, self.mask)):
            ax.add_patch(Rectangle((i, 0), 1, 1, color=colors[m]))
        ax.set_xlim(0, len(self.aligned_with))
        ax.set_yticks([])
        ax.set_title(&#34;DNAstr Alignment Mask&#34;)
        ax.set_xlabel(&#34;Position&#34;)
        return fig

    def plot_alignment(self, dx=1.0, dy=1.0, width=20, normalize=True):
        &#34;&#34;&#34;
        Plot a block alignment view of two DNAstr sequences with color-coded segments.

        Parameters
        ----------
        dx : float
            Horizontal step between segments (defaults to 1.0).
        dy : float
            Vertical height increment for symbolic waveform visualization.
        width : int
            Number of characters per row (line wrapping).

        Returns
        -------
        matplotlib.figure.Figure
        matplotlib.axes.Axes
        &#34;&#34;&#34;
        if not self.other_copy:
            raise ValueError(&#34;Alignment required for plotting.&#34;)
        aligned_self, aligned_other, mask = self.aligned_with, self.other_copy, self.mask
        n = len(aligned_self)
        fig, ax = plt.subplots(figsize=(12, 3))

        def letter_to_height(letter, base=0):
            &#34;&#34;&#34;Simple deterministic up/down movement from symbolic codes.&#34;&#34;&#34;
            return base + {
                &#39;A&#39;: +1, &#39;B&#39;: +1, &#39;C&#39;: +1,
                &#39;X&#39;: -1, &#39;Y&#39;: -1, &#39;Z&#39;: -1,
                &#39;_&#39;: 0, &#39; &#39;: 0
            }.get(letter, 0) * dy

        x, y1, y2 = 0, -0.5, -4
        xs, ys1, ys2 = [0], [0], [y2]

        for i in range(n):
            ax.add_patch(Rectangle((x, y1), dx, dy, color=&#39;lightgreen&#39; if mask[i] == &#39;=&#39; else &#39;salmon&#39;, alpha=0.6))
            ys1.append(letter_to_height(aligned_self[i], ys1[-1]))
            ys2.append(letter_to_height(aligned_other[i], ys2[-1]))
            xs.append(x + dx)
            x += dx

        # Convert to numpy arrays and normalize
        if normalize:
            xs = np.array(xs)
            ys1 = np.array(ys1)
            ys2 = np.array(ys2)
            ymax = max(abs(ys1).max(), abs(ys2).max())
            scale = ymax if ymax&gt;1e-12 else 1.0
            ys1 = ys1 / scale
            ys2 = ys2 / scale

        ax.plot(xs, ys1, label=&#34;Self&#34;, color=&#34;DarkMagenta&#34;, linewidth=4)
        ax.plot(xs, ys2, label=&#34;Reference&#34;, color=&#34;DodgerBlue&#34;, linestyle=&#39;-&#39;, linewidth=4)

        ax.set_title(&#34;Waveform Alignment Visualization&#34;)
        ax.set_xlabel(&#34;Position&#34;)
        ax.set_ylabel(&#34;Symbolic Signal&#34;)
        ax.legend()
        ax.grid(True)
        plt.tight_layout()
        return fig, ax

    def extract_motifs(self, pattern=&#39;YAZB&#39;, minlen=4, plot=True):
        &#34;&#34;&#34;
        Extract and analyze YAZB motifs (canonical and distorted) from the symbolic sequence.

        Parameters
        ----------
        pattern : str
            Canonical motif pattern (default is &#39;YAZB&#39;).
        minlen : int
            Minimum motif length to be considered valid.
        plot : bool
            If True, generate a motif density plot using xloc or sequence index.

        Returns
        -------
        pd.DataFrame
            Table of detected motifs with start/end positions, length, and classification.
        &#34;&#34;&#34;
        sequence = str(self)
        canonical = pattern
        motif_re = re.compile(r&#39;Y+A+Z+B+&#39;)

        matches = []
        for m in motif_re.finditer(sequence):
            start, end = m.span()
            substr = m.group()
            motif_len = end - start
            canonical_match = substr == canonical
            classification = &#39;canonical&#39; if canonical_match else &#39;variant&#39;
            if motif_len &gt;= minlen:
                matches.append({
                    &#39;start&#39;: start,
                    &#39;end&#39;: end,
                    &#39;length&#39;: motif_len,
                    &#39;sequence&#39;: substr,
                    &#39;classification&#39;: classification
                })

        df = pd.DataFrame(matches)

        if plot and not df.empty:
            # Basic position handling
            if hasattr(self, &#39;xloc&#39;) and isinstance(self.xloc, (tuple, list)) and len(self.xloc) == 2:
                x0, x1 = self.xloc
                xspan = np.linspace(x0, x1, len(sequence)+1)
                df[&#39;x_start&#39;] = df[&#39;start&#39;].apply(lambda i: xspan[i])
                df[&#39;x_end&#39;] = df[&#39;end&#39;].apply(lambda i: xspan[i])
                xvals = xspan
            else:
                df[&#39;x_start&#39;] = df[&#39;start&#39;]
                df[&#39;x_end&#39;] = df[&#39;end&#39;]
                xvals = np.arange(len(sequence))

            fig, ax = plt.subplots(figsize=(12, 2.5))
            ax.plot(xvals, [1]*len(xvals), alpha=0.1)  # Background for alignment
            for _, row in df.iterrows():
                color = &#39;green&#39; if row[&#39;classification&#39;] == &#39;canonical&#39; else &#39;orange&#39;
                ax.axvspan(row[&#39;x_start&#39;], row[&#39;x_end&#39;], color=color, alpha=0.4)
            ax.set_title(f&#34;Motif Regions in `{getattr(self, &#39;_hash&#39;, &#39;DNAstr&#39;)}`&#34;)
            ax.set_yticks([])
            ax.set_xlabel(&#34;Position (xloc or index)&#34;)
            ax.set_xlim([xvals[0], xvals[-1]])
            ax.grid(True, axis=&#39;x&#39;, linestyle=&#39;--&#39;, alpha=0.3)
            plt.tight_layout()
            plt.show()
            return df,fig

        return df

# --------------------------
# DNAPairwiseAnalysis class
# --------------------------

class DNApairwiseAnalysis:
    &#34;&#34;&#34;
    Class to handle pairwise distance analysis, PCoA, clustering, and visualization
    for DNA-coded signals.

    Attributes
    ----------
    D : np.ndarray
        Pairwise excess entropy distance matrix.
    names : list
        Names of the DNA signals.
    DNAsignals : list
        original DNAsignal objects
    coords : np.ndarray
        Coordinates in reduced space (PCoA).
    dimensions : list
        Selected dimensions for reduced analysis.
    linkage_matrix : np.ndarray
        Linkage matrix used for hierarchical clustering.
    &#34;&#34;&#34;

    def __init__(self, D, names, DNAsignals, name=None):
        self.name = name if not name is None else &#34;unamed&#34;
        self.D = np.array(D)
        self.names = list(names)
        self.n = len(self.names)
        self.DNAsignals = DNAsignals
        self.coords = None
        self.dimensions = list(range(self.n))  # All by default
        self.linkage_matrix = None
        self.pcoa()

    def pcoa(self, n_components=None):
        &#34;&#34;&#34;Perform Principal Coordinate Analysis (PCoA).&#34;&#34;&#34;
        if n_components is None:
            n_components = min(self.n, 1000)
        mds = MDS(n_components=n_components, dissimilarity=&#39;precomputed&#39;, random_state=42)
        self.coords = mds.fit_transform(self.D)
        self.dimensions = list(range(n_components))

    def select_dimensions(self, dims):
        &#34;&#34;&#34;Update active dimensions.&#34;&#34;&#34;
        if isinstance(dims,int):
            self.dimensions = list(range(dims))
        elif isinstance(dims,(list,tuple)):
            self.dimensions = dims
        else:
            raise TypeError(f&#34;dims must be a int, list or tuple not a {type(dims).__name__}&#34;)

    def reduced_distances(self):
        &#34;&#34;&#34;Recompute distances on selected subspace.&#34;&#34;&#34;
        coords_sel = self.coords[:, self.dimensions]
        return pairwise_distances(coords_sel)

    def compute_linkage(self, method=&#39;ward&#39;):
        &#34;&#34;&#34;Compute hierarchical clustering.&#34;&#34;&#34;
        D = self.reduced_distances()
        D = (D + D.T) / 2  # force symmetry
        reduced_D = squareform(D)
        self.linkage_matrix = linkage(reduced_D, method=method)

    def heatmap(self, figsize=(10, 8)):
        &#34;&#34;&#34;Plot heatmap of pairwise distances.&#34;&#34;&#34;
        fig=plt.figure(figsize=figsize)
        sns.heatmap(self.D, xticklabels=self.names, yticklabels=self.names, cmap=&#39;viridis&#39;)
        title = f&#39;Pairwise Excess Entropy Distances — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.tight_layout()
        plt.show()
        return fig

    def get_cluster_labels(self, n_clusters=2, method=&#39;ward&#39;):
        &#34;&#34;&#34;
        Returns cluster labels from hierarchical clustering. If not computed yet, computes linkage.

        Parameters
        ----------
        n_clusters : int
            Number of clusters to assign.
        method : str
            Linkage method to use if recomputing linkage.

        Returns
        -------
        labels : np.ndarray of int
            Cluster IDs for each sample.
        &#34;&#34;&#34;
        if self.linkage_matrix is None:
            self.compute_linkage(method=method)
        self.cluster_labels = fcluster(self.linkage_matrix, t=n_clusters, criterion=&#39;maxclust&#39;)
        return self.cluster_labels

    def scatter(self, dims=(0, 1), annotate=True, figsize=(8, 6), n_clusters=None):
        &#34;&#34;&#34;
        2D scatter plot in selected dimensions with optional cluster-based coloring.

        Parameters
        ----------
        dims : tuple
            Dimensions to plot (default: (0, 1)).
        annotate : bool
            If True, annotate points with their index.
        figsize : tuple
            Size of the plot.
        n_clusters : int or None
            If provided, use clustering to color points.

        Returns
        -------
        fig : matplotlib.figure.Figure
        &#34;&#34;&#34;
        fig = plt.figure(figsize=figsize)
        x, y = self.coords[:, dims[0]], self.coords[:, dims[1]]

        if n_clusters is not None:
            labels = self.get_cluster_labels(n_clusters=n_clusters)
            scatter = plt.scatter(x, y, c=labels, cmap=&#39;tab10&#39;, s=50)
        else:
            scatter = plt.scatter(x, y, s=50)

        if annotate:
            for i, name in enumerate(self.names):
                plt.text(x[i], y[i], str(i), fontsize=9)

        plt.xlabel(f&#34;Dimension {dims[0] + 1}&#34;)
        plt.ylabel(f&#34;Dimension {dims[1] + 1}&#34;)
        title = f&#39;PCoA Scatter Plot — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.grid(True)
        plt.tight_layout()
        plt.show()
        return fig


    def scatter3d(self, dims=(0, 1, 2), annotate=True, n_clusters=None):
        &#34;&#34;&#34;
        3D scatter plot in selected dimensions with optional cluster-based coloring.

        Parameters
        ----------
        dims : tuple
            Dimensions to plot.
        annotate : bool
            Annotate points with their index.
        n_clusters : int or None
            If provided, use clustering to color points.

        Returns
        -------
        fig : matplotlib.figure.Figure
        &#34;&#34;&#34;
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection=&#39;3d&#39;)
        x, y, z = self.coords[:, dims[0]], self.coords[:, dims[1]], self.coords[:, dims[2]]

        if n_clusters is not None:
            labels = self.get_cluster_labels(n_clusters=n_clusters)
            scatter = ax.scatter(x, y, z, c=labels, cmap=&#39;tab10&#39;, s=50)
        else:
            scatter = ax.scatter(x, y, z, s=50)
        if annotate:
            for i, name in enumerate(self.names):
                ax.text(x[i], y[i], z[i], str(i), fontsize=9)

        ax.set_xlabel(f&#34;Dim {dims[0] + 1}&#34;)
        ax.set_ylabel(f&#34;Dim {dims[1] + 1}&#34;)
        ax.set_zlabel(f&#34;Dim {dims[2] + 1}&#34;)
        title = f&#39;3D PCoA Scatter Plot — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.tight_layout()
        plt.show()
        return fig


    def plot_dendrogram(self, truncate_mode=None, p=10):
        &#34;&#34;&#34;Plot dendrogram from linkage matrix.&#34;&#34;&#34;
        if self.linkage_matrix is None:
            self.compute_linkage()
        fig=plt.figure(figsize=(10, 6))
        dendrogram(self.linkage_matrix, labels=self.names, truncate_mode=truncate_mode, p=p)
        plt.title(&#34;Hierarchical Clustering Dendrogram&#34;)
        plt.xlabel(&#34;Sample Index or Name&#34;)
        plt.ylabel(&#34;Distance&#34;)
        plt.tight_layout()
        title = f&#39;PCoA Dendrogram — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.show()
        return fig

    def cluster(self, t=1.0, criterion=&#39;distance&#39;):
        &#34;&#34;&#34;Assign cluster labels from linkage matrix.&#34;&#34;&#34;
        if self.linkage_matrix is None:
            self.compute_linkage()
        return fcluster(self.linkage_matrix, t=t, criterion=criterion)

    def best_dimension(self, max_dim=10):
        &#34;&#34;&#34;Determine optimal dimension by maximizing silhouette score.&#34;&#34;&#34;
        scores = []
        for d in range(2, min(self.n, max_dim + 1)):
            coords = self.coords[:, :d]
            labels = fcluster(linkage(coords, method=&#39;ward&#39;), t=2, criterion=&#39;maxclust&#39;)
            try:
                score = silhouette_score(coords, labels)
                scores.append((d, score))
            except:
                continue
        if scores:
            best_d, best_score = max(scores, key=lambda x: x[1])
            self.select_dimensions(list(range(best_d)))
            return best_d, best_score
        return None, None

    def save(self, path):
        &#34;&#34;&#34;Save current analysis to file.&#34;&#34;&#34;
        with open(path, &#39;wb&#39;) as f:
            pickle.dump(self, f)

    @staticmethod
    def load(path):
        &#34;&#34;&#34;Load analysis from file.&#34;&#34;&#34;
        with open(path, &#39;rb&#39;) as f:
            return pickle.load(f)

    def __repr__(self):
        return (f&#34;DNAPairwiseAnalysis(\n&#34;
                f&#34;  name={self.name},\n&#34;
                f&#34;  n_samples={self.n},\n&#34;
                f&#34;  dimensions={len(self.dimensions)},\n&#34;
                f&#34;  active_dims={self.dimensions},\n&#34;
                f&#34;  linkage_computed={&#39;Yes&#39; if self.linkage_matrix is not None else &#39;No&#39;}\n)&#34;)

    def __str__(self):
        return f&#34;DNAPairwiseAnalysis with {self.n} samples in {len(self.dimensions)} dimensions&#34;

    def dimension_variance_curve(self, threshold=0.5, plot=True, figsize=(8, 5)):
        &#34;&#34;&#34;
        Computes the cumulative explained variance (based on pairwise distances) as a function of
        the number of dimensions used (from 1 to n-1). Optionally plots the curve and the point
        where the threshold (default 0.5) is reached.

        Parameters
        ----------
        threshold : float
            Fraction of total variance to reach (default 0.5).
        plot : bool
            If True, display the variance curve and highlight dhalf.
        figsize : tuple
            Size of the figure if plotted.

        Returns
        -------
        dhalf : int
            Number of dimensions needed to reach the threshold.
        curve : list of float
            Normalized cumulative variance (in [0, 1]) for dimensions 1 to n-1.
        &#34;&#34;&#34;
        max_d = self.coords.shape[1] # min(self.n - 1, self.coords.shape[1])
        total_var = np.sum(pairwise_distances(self.coords[:, :max_d]))
        curve = []
        for d in range(1, max_d + 1):
            d_var = np.sum(pairwise_distances(self.coords[:, :d]))
            curve.append(d_var / total_var)

        dhalf = next((i + 1 for i, v in enumerate(curve) if v &gt;= threshold), max_d)

        if plot:
            fig=plt.figure(figsize=figsize)
            plt.plot(range(1, max_d + 1), curve, marker=&#39;o&#39;, label=&#39;Cumulative variance&#39;)
            plt.axhline(y=threshold, color=&#39;gray&#39;, linestyle=&#39;--&#39;, label=f&#39;Threshold = {threshold}&#39;)
            plt.axvline(x=dhalf, color=&#39;red&#39;, linestyle=&#39;--&#39;, label=f&#39;dhalf = {dhalf}&#39;)
            plt.xlabel(&#39;Number of dimensions used&#39;)
            plt.ylabel(&#39;Normalized cumulative variance (distance)&#39;)
            title = f&#39;Cumulative Variance vs. Dimensions — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
            plt.title(title)
            plt.grid(True)
            plt.legend()
            plt.tight_layout()
            plt.show()

        return dhalf, fig




# %% signal and signal_collection classes

# ------------------------
# signal
# ------------------------
class signal:
    &#34;&#34;&#34;
    signal: A self-documented 1D analytical signal container for reproducible scientific workflows.

    This class is designed for lab-grade signal processing and traceable data storage.
    It represents a discrete 1D signal (e.g., chromatogram, spectrum, transient) with full metadata,
    support for symbolic transformation, numerical operations, plotting, and structured saving/loading.

    Key features include:
    - Portable metadata (user, time, host, cwd, version)
    - Domain-aware plots and operations
    - Reproducible signal serialization in JSON or compressed format
    - Full traceability of all transformation events
    - Optional recursive backup of prior states

    Attributes
    ----------
    x : np.ndarray
        Sampling domain (e.g., time, wavelength, chemical shift).
    y : np.ndarray
        Signal values aligned with x.
    name : str
        Label for plots and file storage (used as default filename).
    type : str
        Optional tag (e.g., &#39;GC-MS&#39;, &#39;FTIR&#39;, &#39;NMR&#39;, &#39;synthetic&#39;).
    x_label : str
        Label for the x-axis (e.g., &#39;wavenumber&#39;).
    x_unit : str
        Unit of the x-axis (e.g., &#39;cm⁻¹&#39;).
    source : str
        Origin label (&#39;array&#39;, &#39;peaks&#39;, &#39;noise&#39;, &#39;imported&#39;...).
    metadata : dict
        Includes user, date, host, cwd, version — filled automatically unless overridden.
    color (str or [rgb]), linestyle (str), linewidth (str)
    _previous: signal
        deep-copy of current object
    _history: dict
        &#34;user@host:timestamp | uidkey&#34; :{&#34;action&#34;:str, &#34;details&#34;: str}

    Key Methods
    -----------
    - from_peaks(...)         : Construct signal from a `peaks` object
    - add_noise(...)          : Return noisy variant (Poisson, Gaussian, ramp or constant bias)
    - align_with(...)         : Align this signal with another (same x domain)
    - copy()                  : Deep copy
    - save(...)               : Save as JSON or .gz (optional CSV export)
    - load(...)               : Load from saved file
    - plot(...)               : Plot the signal with axis labels
    - backup(...)             : Backup current signal (deep-copy stored in _previous)
    - restore(...)            : Restore the previous state of the signal
    - apply_poisson_baseline_filter(...) : Apply a Poisson-based filter
    - enable_fullhistory      : enable full history
    - disable_fullhistory     : disable full history
    - _toDNA(signal)          : DNAsignal

    Overloaded Operators
    --------------------
    - +, -, *, /              : Operates on signals or scalars, aligns if needed
    - +=, -=, *=, /=          : In-place functional versions (returns new signal)

    Low-level Methods
    -----------------
    - _current_stamp()        : stamp for events (static method)
    - _copystatic()           : deep-copy of signal only (use copy for a full copy) (static method)
    - _events()               : register a processing step
    - _to_serializable        : Convert the signal into a dictionary suitable for JSON export
    - _from_serizalizable     : convert a dict (e.g., from JSON import) to signal

    Example
    -------
    &gt;&gt;&gt; s = signal(x, y, name=&#34;sample&#34;, type=&#34;FTIR&#34;, x_label=&#34;wavenumber&#34;, x_unit=&#34;cm⁻¹&#34;)
    &gt;&gt;&gt; s.add_noise(&#34;gaussian&#34;, 0.05).plot()
    &gt;&gt;&gt; s.save()  # saves to ./sample.json.gz
    &gt;&gt;&gt; s2 = signal.load(&#34;sample.json.gz&#34;)
    &#34;&#34;&#34;

    def __init__(self, x=None, y=None,
                 name=&#34;signal&#34;,
                 type=&#34;generic&#34;,
                 x_label=&#34;index&#34;,x_unit=&#34;-&#34;,
                 y_label=&#34;intensity&#34;,y_unit=&#34;a.u.&#34;,
                 metadata=None,
                 source=&#34;array&#34;,
                 user=None, date=None, host=None, cwd=None, version=None,
                 color=None,linewidth=2,linestyle=&#39;-&#39;,message=None,fullhistory=True,):
        &#34;&#34;&#34;
        Initialize a signal instance.

        Parameters
        ----------
        x : array-like, optional
            Sampling domain (e.g., time, wavelength, chemical shift).
        y : array-like, optional
            Signal values aligned with x.
        name : str, optional
            Label for plots and file storage (used as default filename).
        type : str, optional
            Optional tag (e.g., &#39;GC-MS&#39;, &#39;FTIR&#39;, &#39;NMR&#39;, &#39;synthetic&#39;).
        x_label : str, optional
            Label for the x-axis (e.g., &#39;wavenumber&#39;).
        x_unit : str, optional
            Unit of the x-axis (e.g., &#39;cm⁻¹&#39;).
        y_label : str, optional
            Label for the y-axis (e.g., &#39;intensity&#39;).
        y_unit : str, optional
            Unit of the y-axis (e.g., &#39;a.u.&#39;).
        source : str, optional
            Origin label (&#39;array&#39;, &#39;peaks&#39;, &#39;noise&#39;, &#39;imported&#39;...).
        metadata : dict, optional
            Full metadata dictionary. If None, fields below are auto-filled.
        user : str, optional
            Username (defaults to current user).
        date : str, optional
            ISO timestamp of creation.
        host : str, optional
            Hostname of the machine.
        cwd : str, optional
            Current working directory at creation time.
        version : str, optional
            Software version (defaults to global __version__).
        color (default=None), linestyle (default=&#34;-&#34;), linewidth (default=2): optional
            Plot styling.
        message : str, optional
            message to record
        fullhistory : bool, optional (default=True)
            flag to enable full history
        &#34;&#34;&#34;

        self.x = np.asarray(x) if x is not None else None
        self.y = np.asarray(y) if y is not None else None
        self.name = name
        self.type = type
        self.x_label = x_label
        self.x_unit = x_unit
        self.y_label = y_label
        self.y_unit = y_unit
        self.source = source
        self.metadata = metadata or {
            &#34;user&#34;: user or getpass.getuser(),
            &#34;date&#34;: date or datetime.datetime.now().isoformat(),
            &#34;host&#34;: host or socket.gethostname(),
            &#34;cwd&#34;: cwd or os.getcwd(),
            &#34;version&#34;: version or globals().get(&#34;__version__&#34;, &#34;undefined&#34;),
            &#34;other&#34;: &#34;&#34;
        }
        self.color = color
        self.linestyle = linestyle
        self.linewidth = linewidth
        self._previous = None
        self._history = {}
        self._fullhistory = fullhistory  # Do not serialize this field
        self._events(&#34;init&#34;, {&#34;from&#34;: self.source, &#34;message&#34;: message})

    @property
    def n(self):
        &#34;&#34;&#34;Return the length of the signal and None if it is None&#34;&#34;&#34;
        return len(self.y) if self.y is not None else None

    @staticmethod
    def _current_stamp():
        timestamp = datetime.datetime.now().isoformat(timespec=&#34;seconds&#34;)
        userhost = f&#34;{getpass.getuser()}@{socket.gethostname()}&#34;
        idstamp = uuid.uuid4().hex[:6]
        return f&#34;{timestamp}:{userhost} | {idstamp}&#34;

    @staticmethod
    def _copystatic(s):
        &#34;&#34;&#34;Static copy of a signal (x and y only)&#34;&#34;&#34;
        return s.__class__(x=s.x.copy(), y=s.y.copy(), name=s.name + &#34;_backup&#34;)

    def _events(self, action, details=None):
        &#34;&#34;&#34;
        Register a traceable action in the signal&#39;s history.

        Each event is stored with a unique timestamp-based key and includes:
        - user@host
        - timestamp
        - action (string)
        - details (optional dictionary)

        Parameters
        ----------
        action : str
            Description of the event (e.g., &#39;baseline_filter&#39;, &#39;restore&#39;).
        details : dict, optional
            Additional parameters relevant to the action.
        &#34;&#34;&#34;
        if not hasattr(self, &#34;_history&#34;) or not isinstance(self._history, dict):
            self._history = {}
        key = signal._current_stamp()
        if not hasattr(self, &#34;_history&#34;):
            self._history = {}
        self._history[key] = {&#34;action&#34;: action,&#34;details&#34;: details}

    def backup(self,fullhistory=None,message=None):
        &#34;&#34;&#34;Backup current state in _previous&#34;&#34;&#34;
        previous = self.copy()
        fullhistory = self._fullhistory if fullhistory is None else fullhistory
        if not fullhistory:
            previous._previous = None
        self._previous = previous
        self._events(&#34;backup&#34;, {&#34;from&#34;: self._fullhistory,&#39;message&#39;: message})

    def restore(self):
        &#34;&#34;&#34;Restore the previous signal version if available&#34;&#34;&#34;
        if hasattr(self, &#34;_previous&#34;) and isinstance(self._previous, signal):
            restored = self._previous.copy()
            for attr in [&#39;x&#39;, &#39;y&#39;, &#39;name&#39;, &#39;type&#39;, &#39;x_label&#39;, &#39;x_unit&#39;,
                         &#39;y_label&#39;, &#39;y_unit&#39;, &#39;color&#39;, &#39;linestyle&#39;,
                         &#39;linewidth&#39;, &#39;source&#39;, &#39;metadata&#39;, &#39;_previous&#39;, &#39;_history&#39;]:
                setattr(self, attr, getattr(restored, attr))
            self._events(&#34;restore&#34;, {&#34;from&#34;: restored.name})
        else:
            raise AttributeError(&#34;No previous signal to restore&#34;)

    def enable_fullhistory(self):
        &#34;&#34;&#34;Enable full history tracking&#34;&#34;&#34;
        self._events(&#34;enable full history&#34;, {&#34;from&#34;: &#34;enable_fullhistory&#34;})
        set._fullhistory = True

    def disable_fullhistory(self):
        &#34;&#34;&#34;Disable full history tracking&#34;&#34;&#34;
        set._fullhistory = True
        self._previous = False
        self._events(&#34;disable full history&#34;, {&#34;from&#34;: &#34;disable_fullhistory&#34;})

    @classmethod
    def from_peaks(cls, peaks_obj, x=None, generator_map=None, name=&#34;from_peaks&#34;, x0=None, n=1000):
        &#34;&#34;&#34;
        Generate a signal from a set of peaks.

        Parameters
        ----------
        peaks_obj : peaks
            A list-like object containing peak definitions.
        x : array-like, float, or None
            If None: compute x domain from peaks.
            If scalar: interpreted as xmax; linspace from x0 to xmax.
            If array: use as x directly.
        generator_map : dict or None
            Optional map of peak type → generator instance (default is Gaussian).
        name : str
            Name of the signal instance.
        x0 : float or None
            Left bound of the domain (used only if x is None or scalar).
            If None: inferred from peaks.
        n : int
            Number of points in the generated x array.

        Returns
        -------
        signal
            A new signal instance generated from the peaks.

        Example
        -------
        p = peaks()
        p.add(x=[400, 800, 1600], w=30, h=[1.0, 0.6, 0.9], type=&#34;gauss&#34;)
        s = signal.from_peaks(p, x0=300, n=2048)
        s.plot()
        &#34;&#34;&#34;
        if x is None:
            xmin = min(p[&#39;x&#39;] - 3 * p[&#39;w&#39;] for p in peaks_obj)
            xmax = max(p[&#39;x&#39;] + 3 * p[&#39;w&#39;] for p in peaks_obj)
            if x0 is not None:
                xmin = x0
            x = np.linspace(xmin, xmax, n)
        elif np.isscalar(x):
            xmin = x0 if x0 is not None else min(p[&#39;x&#39;] - 3 * p[&#39;w&#39;] for p in peaks_obj)
            x = np.linspace(xmin, float(x), n)
        else:
            x = np.asarray(x)

        y = np.zeros_like(x)
        generator_map = generator_map or {}
        for p in peaks_obj:
            g = generator_map.get(p[&#39;type&#39;], generator(p[&#39;type&#39;]))
            y += g(x, p[&#39;x&#39;], p[&#39;w&#39;], p[&#39;h&#39;])
        s = cls(x, y, name=name)
        s.source = &#34;peaks&#34;
        return s

    def sample(self, x_new):
        &#34;&#34;&#34;Interpolate values from x&#34;&#34;&#34;
        return np.interp(x_new, self.x, self.y)

    def plot(self, ax=None, label=None, color=None, linestyle=None, linewidth=None,
             fontsize=12, newfig=False):
        &#34;&#34;&#34;
        Plot the signal using matplotlib, applying either internal style settings
        or overrides provided at call time.

        Parameters
        ----------
        ax : matplotlib.axes.Axes, optional
            Axis to plot on. If None, uses current axis or new figure if newfig=True.
        label : str, optional
            Legend label. Defaults to self.name.
        color : str or None
            Line color. If None, uses default matplotlib cycling.
        linestyle : str or None
            Line style (e.g., &#39;-&#39;, &#39;--&#39;). If None, uses self.linestyle.
        linewidth : float or None
            Line width. If None, uses self.linewidth.
        fontsize : int or str
            Font size for axis labels and legend. Can use values like &#39;small&#39;, &#39;large&#39;.
        newfig : bool
            If True, creates a new figure before plotting.

        Returns
        -------
        matplotlib.figure.Figure
        matplotlib.axes.Axes
        &#34;&#34;&#34;
        # Convert font size keywords to numeric
        fontsize_map = {
            &#34;xx-small&#34;: 6, &#34;x-small&#34;: 8, &#34;small&#34;: 10,
            &#34;medium&#34;: 12, &#34;large&#34;: 14, &#34;x-large&#34;: 16, &#34;xx-large&#34;: 18
        }
        if isinstance(fontsize, str):
            fontsize = fontsize_map.get(fontsize.lower(), 12)

        if newfig:
            fig = plt.figure()
        else:
            fig = plt.gcf()

        ax = ax or plt.gca()

        # Final style resolution
        label = label if label is not None else self.name
        color = color if color is not None else self.color
        linestyle = linestyle if linestyle is not None else self.linestyle
        linewidth = linewidth if linewidth is not None else self.linewidth

        # Plot
        if self.x is None:
            ax.plot(self.y, label=label, color=color,
                    linestyle=linestyle, linewidth=linewidth)
        else:
            ax.plot(self.x, self.y, label=label, color=color,
                    linestyle=linestyle, linewidth=linewidth)

        # Axes labeling and legend
        if self.x_label and self.x_unit:
            ax.set_xlabel(f&#34;{self.x_label} [{self.x_unit}]&#34;, fontsize=fontsize)
        elif self.x_label:
            ax.set_xlabel(self.x_label, fontsize=fontsize)

        if self.y_label and self.y_unit:
            ax.set_ylabel(f&#34;{self.y_label} [{self.y_unit}]&#34;, fontsize=fontsize)
        elif self.y_label:
            ax.set_ylabel(self.y_label, fontsize=fontsize)

        if label:
            ax.legend(fontsize=fontsize)

        return fig, ax


    def __repr__(self):
        def fmt_str(s, maxlen=60):
            s = str(s)
            if len(s) &lt;= maxlen:
                return s
            return f&#34;{s[:maxlen//2 - 2]}...{s[-maxlen//2 + 1:]}&#34;
        meta = self.metadata
        span = (f&#34;{self.x[0]:.2f}&#34;, f&#34;{self.x[-1]:.2f}&#34;) if self.x is not None else (&#34;?&#34;, &#34;?&#34;)
        size = len(self.x) if self.x is not None else self.n
        field_width = 10
        lines = [
            f&#34;&lt;signal &#39;{self.name}&#39; [{self.type}]&gt;&#34;,
            f&#34;{&#39;domain:&#39;.ljust(field_width)} {self.x_label} [{self.x_unit}], span: {span[0]} → {span[1]}, points: {size}&#34;,
            f&#34;{&#39;source:&#39;.ljust(field_width)} {self.source}&#34;,
            f&#34;{&#39;created:&#39;.ljust(field_width)} {fmt_str(meta.get(&#39;date&#39;, &#39;?&#39;))}&#34;,
            f&#34;{&#39;user:&#39;.ljust(field_width)} {meta.get(&#39;user&#39;, &#39;?&#39;)}@{meta.get(&#39;host&#39;, &#39;?&#39;)}&#34;,
            f&#34;{&#39;cwd:&#39;.ljust(field_width)} {fmt_str(meta.get(&#39;cwd&#39;, &#39;?&#39;))}&#34;,
            f&#34;{&#39;version:&#39;.ljust(field_width)} {meta.get(&#39;version&#39;, &#39;?&#39;)}&#34;
        ]
        print(&#34;\n&#34;.join(lines))
        return str(self)

    def __str__(self):
        if self.y is None:
            return f&#34;&lt;empty {self.type}-signal - source=&#39;{self.source}&#39;&gt;&#34;
        else:
            return f&#34;&lt;{self.name}:{self.type}-signal of length={self.n} source=&#39;{self.source}&#39;&gt;&#34;

    def align_with(self, other, mode=&#39;union&#39;, n=1000):
        &#34;&#34;&#34;
        Align two signals to a common x grid with interpolation and padding.

        Parameters:
            other (signal): the other signal to align with
            mode (str): &#39;union&#39; (default) or &#39;intersection&#39;
            n (int): number of points for the new grid

        Returns:
            tuple: (self_interp, other_interp) as new signal instances
        &#34;&#34;&#34;
        if not isinstance(other, signal):
            raise TypeError(&#34;Can only align with another signal.&#34;)

        # Determine new x-axis
        if mode == &#39;union&#39;:
            x_min = min(self.x[0], other.x[0])
            x_max = max(self.x[-1], other.x[-1])
        elif mode == &#39;intersection&#39;:
            x_min = max(self.x[0], other.x[0])
            x_max = min(self.x[-1], other.x[-1])
            if x_min &gt;= x_max:
                raise ValueError(&#34;No overlapping x-range for &#39;intersection&#39; mode.&#34;)
        else:
            raise ValueError(&#34;mode must be &#39;union&#39; or &#39;intersection&#39;&#34;)

        x_new = np.linspace(x_min, x_max, n)

        # Interpolate and zero outside original domain
        def interp_with_padding(sig):
            y_new = np.interp(x_new, sig.x, sig.y, left=0, right=0)
            return signal(x_new, y_new, name=sig.name, source=sig.source)

        return interp_with_padding(self), interp_with_padding(other)

    def add_noise(self, kind=&#34;gaussian&#34;, scale=1.0, bias=None):
        &#34;&#34;&#34;Return a new signal with noise and/or bias added.&#34;&#34;&#34;
        new_y = self.y.copy()

        # --- Apply bias ---
        if bias is not None:
            if isinstance(bias, (int, float)):
                new_y += bias
            elif isinstance(bias, np.ndarray):
                if bias.shape != self.x.shape:
                    raise ValueError(&#34;Bias array must match x domain.&#34;)
                new_y += bias
            elif bias == &#34;ramp&#34;:
                ramp = np.linspace(0, 1, len(self.x))
                new_y += ramp
            elif isinstance(bias, signal):
                interp_bias = np.interp(self.x, bias.x, bias.y)
                new_y += interp_bias
            else:
                raise TypeError(&#34;Invalid bias type.&#34;)

        # --- Apply noise ---
        rng = np.random.default_rng()
        if kind == &#34;gaussian&#34;:
            new_y += rng.normal(loc=0.0, scale=scale, size=self.y.shape)
        elif kind == &#34;poisson&#34;:
            if np.any(new_y &lt; 0):
                raise ValueError(&#34;Poisson noise requires non-negative values.&#34;)
            new_y = rng.poisson(lam=new_y * scale) / scale
        else:
            raise ValueError(&#34;Unknown noise type.&#34;)

        return signal(self.x.copy(), new_y, name=self.name + &#34;+noise&#34;, source=self.source + &#34;+noise&#34;)

    def copy(self):
        &#34;&#34;&#34;Deep copy of the signal, excluding full history control flag&#34;&#34;&#34;
        new = signal(
            x=self.x.copy() if self.x is not None else None,
            y=self.y.copy() if self.y is not None else None,
            name=self.name,
            type=self.type,
            x_label=self.x_label,
            x_unit=self.x_unit,
            y_label=self.y_label,
            y_unit=self.y_unit,
            metadata=self.metadata.copy(),
            source=self.source,
            color=self.color,
            linewidth=self.linewidth,
            linestyle=self.linestyle,
            fullhistory=self._fullhistory
        )
        new._history = self._history.copy()
        if self._fullhistory and self._previous is not None:
            new._previous = self._previous.copy()
        else:
            new._previous = None
        return new

    def _binary_op(self, other, op):
        &#34;&#34;&#34;Binary operation on signals&#34;&#34;&#34;
        if isinstance(other, (int, float)):
            return signal(self.x.copy(), op(self.y, other), name=self.name, source=self.source)

        if isinstance(other, signal):
            s1, s2 = self.align_with(other)
            return signal(s1.x, op(s1.y, s2.y), name=f&#34;({s1.name}){op.__name__}({s2.name})&#34;)

        raise TypeError(f&#34;Unsupported operand type(s) for {op.__name__}: &#39;signal&#39; and &#39;{type(other).__name__}&#39;&#34;)

    def __add__(self, other): return self._binary_op(other, operator.add)
    def __sub__(self, other): return self._binary_op(other, operator.sub)
    def __mul__(self, other): return self._binary_op(other, operator.mul)
    def __truediv__(self, other): return self._binary_op(other, operator.truediv)
    def __iadd__(self, other): return self._binary_op(other, operator.add)
    def __isub__(self, other): return self._binary_op(other, operator.sub)
    def __imul__(self, other): return self._binary_op(other, operator.mul)
    def __itruediv__(self, other): return self._binary_op(other, operator.truediv)

    def _to_serializable(self):
        &#34;&#34;&#34;Convert the signal into a dictionary suitable for JSON export.&#34;&#34;&#34;
        return {
            &#34;x&#34;: self.x.tolist() if self.x is not None else None,
            &#34;y&#34;: self.y.tolist() if self.y is not None else None,
            &#34;name&#34;: self.name,
            &#34;type&#34;: self.type,
            &#34;x_label&#34;: self.x_label,
            &#34;x_unit&#34;: self.x_unit,
            &#34;y_label&#34;: self.y_label,
            &#34;y_unit&#34;: self.y_unit,
            &#34;source&#34;: self.source,
            &#34;metadata&#34;: self.metadata,
            &#34;color&#34;: self.color,
            &#34;linestyle&#34;: self.linestyle,
            &#34;linewidth&#34;: self.linewidth,
            &#34;_history&#34;: self._history,
            &#34;_previous&#34;: self._previous.to_serializable() if self._fullhistory and self._previous else None
        }

    @staticmethod
    def _from_serializable(data,message=None):
        &#34;&#34;&#34;Convert a serialized dict to a signal&#34;&#34;&#34;
        s = signal(
            x=np.array(data[&#34;x&#34;]) if data[&#34;x&#34;] is not None else None,
            y=np.array(data[&#34;y&#34;]) if data[&#34;y&#34;] is not None else None,
            name=data.get(&#34;name&#34;, &#34;signal&#34;),
            type=data.get(&#34;type&#34;, &#34;generic&#34;),
            x_label=data.get(&#34;x_label&#34;, &#34;index&#34;),
            x_unit=data.get(&#34;x_unit&#34;, &#34;-&#34;),
            y_label=data.get(&#34;y_label&#34;, &#34;intensity&#34;),
            y_unit=data.get(&#34;y_unit&#34;, &#34;a.u.&#34;),
            metadata=data.get(&#34;metadata&#34;, {}),
            source=data.get(&#34;source&#34;, &#34;array&#34;),
            color=data.get(&#34;color&#34;, None),
            linestyle=data.get(&#34;linestyle&#34;, &#34;-&#34;),
            linewidth=data.get(&#34;linewidth&#34;, 2),
            fullhistory=True,  # Set default on load
            message = message
        )
        s._history = data.get(&#34;_history&#34;, {})
        prev = data.get(&#34;_previous&#34;, None)
        s._previous = signal._from_serializable(prev) if prev else None
        return s

    def save(self, filepath=None, zip=True, export_csv=False):
        &#34;&#34;&#34;
        Save signal to JSON (optionally compressed) and optionally CSV.

        Parameters
        ----------
        filepath : str or Path or None
            If None, builds path from metadata[&#39;cwd&#39;] and self.name + &#39;.json[.gz]&#39;.
            If a directory, appends name + &#39;.json[.gz]&#39;.
            If a file, uses as is.
        zip : bool
            Whether to compress the JSON file using gzip. Default: True.
        export_csv : bool
            If True, also save a .csv file (x,y) alongside the JSON.
        &#34;&#34;&#34;
        # Resolve filepath
        if filepath is None:
            filepath = os.path.join(self.metadata[&#34;cwd&#34;], f&#34;{self.name}.json.gz&#34; if zip else f&#34;{self.name}.json&#34;)
        elif os.path.isdir(filepath):
            filepath = os.path.join(filepath, f&#34;{self.name}.json.gz&#34; if zip else f&#34;{self.name}.json&#34;)
        filepath = Path(filepath)
        data = self._to_serializable()
        if zip or str(filepath).endswith(&#34;.gz&#34;):
            with gzip.open(filepath, &#34;wt&#34;, encoding=&#34;utf-8&#34;) as f:
                json.dump(data, f, indent=2)
        else:
            with open(filepath, &#34;w&#34;, encoding=&#34;utf-8&#34;) as f:
                json.dump(data, f, indent=2)

        # Optionally export to CSV
        if export_csv and self.x is not None and self.y is not None:
            csv_path = filepath.with_suffix(&#34;.csv&#34;)
            with open(csv_path, &#34;w&#34;, encoding=&#34;utf-8&#34;) as f:
                f.write(&#34;x,y\n&#34;)
                for xi, yi in zip(self.x, self.y):
                    f.write(f&#34;{xi},{yi}\n&#34;)

    @staticmethod
    def load(filepath):
        &#34;&#34;&#34;
        Load a signal from a JSON or gzipped JSON file, including recursive _previous.

        Parameters
        ----------
        filepath : str or Path
            Path to the JSON or .gz file

        Returns
        -------
        signal
            A fully reconstructed signal object
        &#34;&#34;&#34;
        filepath = Path(filepath)
        if filepath.suffix == &#34;.gz&#34;:
            with gzip.open(filepath, &#34;rt&#34;, encoding=&#34;utf-8&#34;) as f:
                data = json.load(f)
        else:
            with open(filepath, &#34;r&#34;, encoding=&#34;utf-8&#34;) as f:
                data = json.load(f)
        return signal._from_serializable(data,message=f&#34;loaded from {filepath}&#34;)

    def apply_poisson_baseline_filter(self, window_ratio=0.02, gain=1.0, proba=0.9):
        &#34;&#34;&#34;
        Apply a baseline filter assuming Poisson-dominated statistics with adjustable gain
        and a rejection threshold based on the Bienaymé-Tchebychev inequality.

        The signal is filtered by removing values likely caused by statistical noise
        (false peaks) using a per-point threshold defined from local statistics:

        - Local mean: $$ \mu_t = \frac{1}{w} \sum_{i \in W(t)} y_i $$
        - Local std dev: $$ \sigma_t = \sqrt{\mu_t \cdot \text{gain}} $$
        - Coefficient of variation: $$ \text{cv}_t = \frac{\sigma_t}{\mu_t} $$
        - Estimated local intensity (lambda): $$ \lambda_t = \frac{1}{\text{cv}_t^2} $$
        - Bienaymé-Tchebychev threshold: $$ \text{threshold}_t = \frac{1}{\sqrt{1 - p}} \cdot \sqrt{10 \lambda_t \cdot \Delta t} $$

        Parameters
        ----------
        window_ratio : float, default=0.02
            Ratio of signal length used as window size (must yield odd integer ≥ 11).
        gain : float, default=1.0
            Linear amplification factor applied to simulate signal counts.
        proba : float, default=0.9
            Minimum probability to consider a signal point significant. Must be in (0, 1).

        Returns
        -------
        signal
            The current signal instance (self), with updated `y`.

        Raises
        ------
        ValueError
            If the window size is too small for reliable statistics.
        &#34;&#34;&#34;
        import numpy as np

        y = self.y
        n = len(y)

        # --- Window size ---
        w = int(window_ratio * n)
        if w &lt; 11:
            raise ValueError(f&#34;Window too small ({w} &lt; 11); increase signal length or window_ratio.&#34;)
        if w % 2 == 0:
            w += 1

        # --- Sliding window views ---
        padded = np.pad(y, w//2, mode=&#39;reflect&#39;)
        windows = sliding_window_view(padded, w)  # shape: (n, w)
        # --- Robust local statistics ---
        local_mean = np.mean(windows, axis=1)
        local_std = np.std(windows, axis=1)
        # Prevent division by zero
        eps = 1e-12
        cv = np.where(local_mean &gt; eps, local_std / local_mean, np.inf)
        # Estimate lambda from CV (avoid inf/NaN)
        lam = np.where(cv &gt; 0, 1 / (cv ** 2), 0)
        # Bienaymé-Tchebychev threshold with gain
        delta_t = self.sampling_dt if hasattr(self, &#34;sampling_dt&#34;) else 1.0
        k = 1 / np.sqrt(1 - proba)
        threshold = k * np.sqrt(lam * delta_t * gain)

        # --- Backup and History ---
        self.backup()
        event = f&#34;apply_poisson_baseline_filter(window={w}, proba={proba:.2f}, gain={gain})&#34;
        self._events(&#34;filter&#34;, {&#34;from&#34;: event})

        # --- Apply filter ---
        self.y = np.where(self.y &gt; threshold, self.y, 0.0)
        return self


    def _toDNA(self,encode=True,scales=[1,3,4,8,16,32]):
        &#34;&#34;&#34;
        Return a DNA encoded signal

        Parameters
            encode : bool (default=True)
            scales : list (default=[1,3,4,8,16,32])
        &#34;&#34;&#34;
        return DNAsignal(self,encode=encode)

# ------------------------
# Signal collection class
# ------------------------
class signal_collection(list):
    &#34;&#34;&#34;
    A container class for multiple `signal` instances that ensures alignment on a shared x-grid.

    The collection is used to manage, compare, combine, or visualize multiple signals (e.g., from
    replicates, experiments, synthetic scenarios). Signals are interpolated and padded on insertion
    so all have the same shape and domain. Arithmetic, matrix extraction, and overlay plots are supported.

    Parameters:
    -----------
    *signals : signal
        One or more signal instances to include (they are copied and aligned).
    n : int
        Number of sampling points in the aligned x grid (default: 1000).
    mode : str
        Alignment mode: &#39;union&#39; or &#39;intersection&#39; of x-ranges.

    Core Attributes:
    ----------------
    mode : str
        Alignment strategy used (&#34;union&#34; or &#34;intersection&#34;).
    n : int
        Number of x-points used in alignment (default=1024).

    Key Methods:
    ------------
    - append(signal)              → add and align a new signal
    - to_matrix()                 → convert signals to a 2D array (n_signals x n_points)
    - mean(coeffs=None)           → weighted or unweighted mean
    - sum(coeffs=None)            → weighted or unweighted sum
    - plot(...)                   → overlay signals with optional mean/sum
    - copy                        → all signals stored are deep copies
    - generate_synthetic          → signal collection composed of random peaks.
    - __getitem__(...)            → slice, list, or name-based access to signals
    - __repr__ / __str__          → report contents with span and names
    - _toDNA(signal_collection)   → list of DNAsignals

    Access Patterns:
    ----------------
    - sc[0:3]           → subcollection by slice
    - sc[[0, 2]]        → subcollection by list of indices
    - sc[&#34;name&#34;]        → return a copy of signal with that name
    - sc[&#34;A&#34;, &#34;B&#34;]      → return a subcollection with those names

    Examples:
    ---------
    &gt;&gt;&gt; sc = signal_collection(s1, s2, s3)
    &gt;&gt;&gt; sc.plot(show_mean=True)

    &gt;&gt;&gt; sc[0:2]         # sub-collection (copy)
    &gt;&gt;&gt; sc[&#34;peak1&#34;]     # get copy of signal named &#39;peak1&#39;
    &gt;&gt;&gt; mat = sc.to_matrix()

    &gt;&gt;&gt; sc.mean().plot()
    &gt;&gt;&gt; sc.sum(coeffs=[0.4, 0.6]).plot()
    &#34;&#34;&#34;

    def __init__(self, *signals, n=1024, mode=&#39;union&#39;, name=None, force=True):
        &#34;&#34;&#34;
        Initialize collection with aligned signals of the same type.

        Parameters
        ----------
        *signals : signal
            Signal instances to include.
        n : int (default=1000)
            Number of points on the common x grid.
        mode : str (default=&#34;union&#34;)
            &#39;union&#39; or &#39;intersection&#39; for domain alignment.
        force : bool (default=True)
            If False, require all signals to have the same type.
        &#34;&#34;&#34;
        nsignals = len(signals)
        self.name = f&#34;Collection of {nsignals} signals&#34; if name is None else name
        self.mode = mode
        self.n = n
        if not force and nsignals &gt; 1:
            types = {s.type for s in signals}
            if len(types) &gt; 1:
                raise ValueError(f&#34;Incompatible signal types: {types}. Use force=True to override.&#34;)
        s_copy = [s.copy() for s in signals]
        for s in s_copy:
            if s.x is None:
                s.x = np.linspace(0,s.n-1,s.n,endpoint=True,dtype=np.uint32)
        aligned = self._align_all(s_copy)
        super().__init__(aligned)
        self._plotted_once = False # flag to track plotting

    def append(self, new_signal):
        &#34;&#34;&#34;Append and align the new signal to the existing collection.&#34;&#34;&#34;
        aligned = self._align_all(self + [new_signal.copy()])
        self.clear()
        self.extend(aligned)

    def __getitem__(self, key):
        &#34;&#34;&#34;
            sc[&#34;my_signal&#34;]                  # returns a copy of the signal named &#34;my_signal&#34;
            sc[&#34;A&#34;, &#34;B&#34;, &#34;C&#34;]                # returns a sub-collection with those names
            sc[0:2] or sc[[0, 2]]            # still works for index-based access
        &#34;&#34;&#34;
        if isinstance(key, slice):
            return signal_collection(*(s.copy() for s in super().__getitem__(key)))
        elif isinstance(key, list):
            return signal_collection(*(self[k].copy() for k in key))
        elif isinstance(key, tuple):
            return signal_collection(*(s.copy() for s in self if s.name in key))
        elif isinstance(key, str):
            for s in self:
                if s.name == key:
                    return s.copy()
            raise KeyError(f&#34;No signal named &#39;{key}&#39; in collection.&#34;)
        else:
            return super().__getitem__(key)


    def __setitem__(self, key, value):
        if not isinstance(value, signal):
            raise TypeError(&#34;Only signal instances can be assigned.&#34;)
        aligned = self._align_all(self[:key] + [value.copy()] + self[key+1:])
        super().__setitem__(key, aligned[key])

    def __delitem__(self, key):
        if isinstance(key, list):
            # delete in reverse to preserve indices
            for k in sorted(key, reverse=True):
                super().__delitem__(k)
        else:
            super().__delitem__(key)

    def _align_all(self, signals):
        if not signals:
            return []
        # Determine common grid
        x_min = min(s.x[0] for s in signals)
        x_max = max(s.x[-1] for s in signals)
        x_common = np.linspace(x_min, x_max, self.n)
        # Interpolate all to shared grid
        aligned = [signal(x_common, np.interp(x_common, s.x, s.y, left=0, right=0),
                          name=s.name, source=s.source) for s in signals]
        return aligned

    def __str__(self):
        return f&#34;&lt;signal_collection with {len(self)} aligned signals&gt;&#34;

    def __repr__(self):
        lines = [f&#34;[{i}] &#39;{s.name}&#39; span=({s.x[0]:.2f}, {s.x[-1]:.2f})&#34; for i, s in enumerate(self)]
        print(&#34;&lt;signal_collection&gt;\n&#34; + &#34;\n&#34;.join(lines))
        return str(self)

    def to_matrix(self):
        &#34;&#34;&#34;Return a 2D array (n_signals x n_points) of aligned signal values.&#34;&#34;&#34;
        return np.vstack([s.y for s in self])

    def sum(self, indices_or_names=None, coeffs=None):
        &#34;&#34;&#34;
        Sum selected signals, optionally weighted by coeffs.

        Parameters
        ----------
        indices_or_names : list[int or str], optional
            If provided, selects a subset by index or name.
        coeffs : list[float], optional
            Weights matching the number of selected signals.

        Returns
        -------
        signal
            Summed signal.
        &#34;&#34;&#34;
        if indices_or_names is None:
            selected = self
        else:
            selected = []
            for k in indices_or_names:
                if isinstance(k, int):
                    selected.append(self[k])
                elif isinstance(k, str):
                    found = next((s for s in self if s.name == k), None)
                    if found is None:
                        raise KeyError(f&#34;Signal name &#39;{k}&#39; not found.&#34;)
                    selected.append(found)
                else:
                    raise TypeError(&#34;indices_or_names must contain ints or strs.&#34;)

        matrix = np.vstack([s.y for s in selected])
        if coeffs is not None:
            coeffs = np.asarray(coeffs)
            if coeffs.shape[0] != len(selected):
                raise ValueError(&#34;Length of coeffs must match number of selected signals.&#34;)
            result = np.dot(coeffs, matrix)
        else:
            result = np.sum(matrix, axis=0)

        return signal(selected[0].x.copy(), result, name=&#34;sum&#34;, source=&#34;signal_collection&#34;)

    def mean(self, indices_or_names=None, coeffs=None):
        &#34;&#34;&#34;
        Mean of selected signals, optionally weighted.

        Parameters
        ----------
        indices_or_names : list[int or str], optional
            Signal names or indices to include.
        coeffs : list[float], optional
            Weights for selected signals.

        Returns
        -------
        signal
            Averaged signal.
        &#34;&#34;&#34;
        if coeffs is not None:
            total_weight = np.sum(coeffs)
        else:
            total_weight = len(indices_or_names) if indices_or_names else len(self)

        s = self.sum(indices_or_names=indices_or_names, coeffs=coeffs)
        return signal(s.x.copy(), s.y / total_weight, name=&#34;mean&#34;, source=&#34;signal_collection&#34;)

    def plot(self, indices=None, labels=True, title=None, newfig=None, ax=None,
             show_mean=False, show_sum=False, coeffs=None, fontsize=12, colormap=None):
        &#34;&#34;&#34;
        Plot selected signals with style attributes and optional overlays.

        Parameters
        ----------
        indices : list[int] or list[str], optional
            Signals to plot by index or name.
        labels : bool
            Whether to show signal labels.
        title : str
            Plot title.
        newfig : bool or None
            If True, always open a new figure.
            If False, use current axes.
            If None, open new figure only the first time this collection is plotted.
        ax : matplotlib axis, optional
            Axis to draw on.
        show_mean : bool
            Overlay mean curve.
        show_sum : bool
            Overlay sum curve.
        coeffs : list[float], optional
            Optional weights for mean/sum.
        fontsize : int or str
            Font size for labels and legend.
        colormap : list[str], optional
            List of colors to cycle through when signal.color is None.

        Returns
        -------
        matplotlib.figure.Figure
        &#34;&#34;&#34;
        if not self:
            return
        # Select signals to plot
        if indices is None:
            selected = self
        else:
            if isinstance(indices[0], str):
                selected = [s for s in self if s.name in indices]
            else:
                selected = [self[i] for i in indices]
        # Circular color iterator
        if colormap is None:
            colormap = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key().get(&#39;color&#39;, [])
        color_cycle = (colormap * ((len(selected) // len(colormap)) + 1)) if colormap else [None] * len(selected)
        # Determine whether to create new figure
        if newfig is None:
            newfig = not self._plotted_once
        if newfig:
            fig = plt.figure()
        else:
            fig = plt.gcf()
        self._plotted_once = True
        ax = ax or plt.gca()
        for i, s in enumerate(selected):
            c = s.color if s.color is not None else color_cycle[i]
            s.plot(ax=ax, label=s.name if labels else None,
                   color=c, linestyle=s.linestyle, linewidth=s.linewidth, fontsize=fontsize)
        # Overlay mean and sum
        if show_mean:
            self.mean(coeffs).plot(ax=ax, label=&#34;mean&#34;, color=&#34;black&#34;, linewidth=2, fontsize=fontsize)
        if show_sum:
            self.sum(coeffs).plot(ax=ax, label=&#34;sum&#34;, color=&#34;red&#34;, linestyle=&#34;--&#34;, linewidth=2, fontsize=fontsize)

        title = self.name if title is None else title
        title = &#34;Signal Collection&#34; if title is None else title
        ax.set_title(title, fontsize=fontsize)
        ax.tick_params(labelsize=fontsize)
        if labels:
            ax.legend(fontsize=fontsize)
        plt.show()
        return fig

    @classmethod
    def generate_synthetic(cls,
                           n_signals=5,
                           n_peaks=5,
                           kind_distribution=&#34;uniform&#34;,  # or &#34;random&#34;
                           kinds=(&#34;gauss&#34;, &#34;lorentz&#34;, &#34;triangle&#34;),
                           x_range=(0, 1000),
                           n_points=1024,
                           avoid_overlap=True,
                           width_range=(20, 60),
                           height_range=(0.5, 1.0),
                           normalize=True,
                           noise=None,    # e.g. {&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.05}
                           bias=None,     # can be scalar, &#34;ramp&#34;, or signal instance
                           name_prefix=&#34;synthetic&#34;,
                           seed=None):
        &#34;&#34;&#34;
        Generate a synthetic signal collection composed of random peaks.

        Parameters
        ----------
        n_signals : int
            Number of synthetic signals to generate.
        n_peaks : int
            Number of peaks per signal.
        kind_distribution : str
            &#39;uniform&#39; → use all peak kinds equally; &#39;random&#39; → random draw from kinds.
        kinds : tuple[str]
            Generator types to choose from (&#39;gauss&#39;, &#39;lorentz&#39;, &#39;triangle&#39;).
        x_range : tuple[float, float]
            Start and end of x-domain.
        n_points : int
            Number of sampling points for each signal (default: 1024).
        avoid_overlap : bool
            Prevent peaks from overlapping by checking spacing vs. width.
        width_range : tuple[float, float]
            Range of widths for the peaks.
        height_range : tuple[float, float]
            Range of peak heights.
        normalize : bool
            Normalize each signal so the highest peak has intensity 1.
        noise : dict or None
            Optional noise model, e.g. {&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.01}.
        bias : float, str, np.ndarray, or signal
            Optional signal bias: can be a constant, &#39;ramp&#39;, or signal.
        name_prefix : str
            Base name for each generated signal.
        seed : int or None
            Random seed for reproducibility.

        Returns
        -------
        signal_collection
            A collection of generated signals.

        Examples
        ---------
        # 1. Default random peaks, Gaussian + ramp bias
        sc = signal_collection.generate_synthetic(
            n_signals=5,
            n_peaks=6,
            kinds=(&#34;gauss&#34;, &#34;lorentz&#34;, &#34;triangle&#34;),
            noise={&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.02},
            bias=&#34;ramp&#34;,
            name_prefix=&#34;test&#34;
        )
        sc.plot(show_mean=True, fontsize=&#34;large&#34;)

        # 2. High-res signal, fixed width and height
        sc2 = signal_collection.generate_synthetic(
            n_signals=3,
            n_peaks=8,
            kinds=(&#34;gauss&#34;,),
            width_range=(30, 30),
            height_range=(1.0, 1.0),
            x_range=(0, 500),
            n_points=2048,
            normalize=False,
            seed=123
        )
        sc2.plot(fontsize=14)

        # 3. Poisson noise, no overlap, save output
        sc3 = signal_collection.generate_synthetic(
            n_signals=2,
            n_peaks=5,
            noise={&#34;kind&#34;: &#34;poisson&#34;, &#34;scale&#34;: 2.0},
            name_prefix=&#34;poisson_example&#34;
        )
        for s in sc3:
            s.save(export_csv=True)
        &#34;&#34;&#34;
        rng = np.random.default_rng(seed)
        xmin, xmax = x_range
        x = np.linspace(xmin, xmax, n_points)
        all_peak_centers = []
        all_peak_widths = []
        signals = []

        for i in range(n_signals):
            p = peaks()
            attempts = 0
            while len(p) &lt; n_peaks and attempts &lt; 100 * n_peaks:
                w = rng.uniform(*width_range)
                h = rng.uniform(*height_range)
                x0 = rng.uniform(xmin + 3 * w, xmax - 3 * w)

                # Check for global overlap
                if avoid_overlap:
                    if any(abs(x0 - xj) &lt; 3 * max(w, wj) for xj, wj in zip(all_peak_centers, all_peak_widths)):
                        attempts += 1
                        continue

                if kind_distribution == &#34;uniform&#34;:
                    kind = kinds[len(p) % len(kinds)]
                else:
                    kind = rng.choice(kinds)

                p.add(x=x0, w=w, h=h, type=kind)
                all_peak_centers.append(x0)
                all_peak_widths.append(w)
                attempts += 1

            # warning if the number of peaks is lower than expected
            if len(p) &lt; n_peaks:
                warnings.warn(f&#34;Signal {i+1}: only placed {len(p)} of {n_peaks} peaks due to overlap constraints.&#34;)

            # Generate signal
            generator_map = {k: generator(k) for k in kinds}
            s = signal.from_peaks(p, x=x, generator_map=generator_map, name=f&#34;{name_prefix}_{i+1}&#34;)
            s.y_label = &#34;intensity&#34;
            s.y_unit = &#34;a.u.&#34;

            # Normalize
            if normalize:
                ymax = np.max(np.abs(s.y))
                if ymax &gt; 0:
                    s.y /= ymax

            # Add noise or bias
            if noise:
                s = s.add_noise(**noise, bias=bias)
            elif bias is not None:
                s = s.add_noise(kind=&#34;gaussian&#34;, scale=0.0, bias=bias)  # bias only

            s._source_peaks = p
            signals.append(s)

        return cls(*signals, n=n_points, mode=&#39;union&#39;, force=True), [s._source_peaks for s in signals]

    @classmethod
    def generate_mixtures(cls,
                          n_mixtures=10,             # int
                          max_peaks = 16,            # int,
                          peaks_per_mixture = (3,8), # tuple[int, int],
                          amplitude_range = (0.5,2), # tuple[float, float],
                          flatten = &#39;mean&#39;,          # literal[&#39;sum&#39;, &#39;mean&#39;]
                          # parameters
                          n_signals=1,
                          n_peaks=1,
                          kinds=(&#34;gauss&#34;,),
                          width_range=(0.5, 3),
                          height_range=(1.0, 5.0),
                          x_range=(0, 500),
                          n_points=1024,
                          normalize=False,
                          seed=None,
                          **kwargs):
        &#34;&#34;&#34;
        Generate synthetic mixtures of signals by combining a subset of base peaks.

        Parameters
        ----------
        n_mixtures : int
            Number of synthetic mixtures to generate.

        max_peaks : int
            Maximum number of base signals (from which peaks are taken).

        peaks_per_mixture : tuple of (int, int)
            Range (min, max) for the number of peaks to combine in each mixture.
            Cannot exceed `max_peaks`.

        amplitude_range : tuple of (float, float)
            Random scaling range applied to peak amplitudes in each mixture.

        flatten : {&#39;sum&#39;, &#39;mean&#39;}, default=&#39;mean&#39;
            How to combine the signals for each mixture.

        **kwargs : dict
            All other keyword arguments passed to `generate_synthetic`.

        Returns
        -------
        result_collection : signal_collection
            A collection of synthetic mixed signals.

        all_peaks : list of dict
            All individual peaks originally generated.

        used_peak_ids : list of list of str
            For each mixture, the list of peak names used.

        Examples
        --------
        S, pS = signal_collection.generate_mixtures(
        ...     n_mixtures=30,
        ...     max_peaks=12,
        ...     peaks_per_mixture=(4, 8),
        ...     amplitude_range=(0.2, 1.5),
        ...     n_signals=12,
        ...     kinds=(&#34;gauss&#34;,),
        ...     width_range=(0.5, 3),
        ...     height_range=(1.0, 5.0),
        ...     x_range=(0, 500),
        ...     n_points=2048,
        ...     normalize=False,
        ...     seed=123
        ... )
        &gt;&gt;&gt; S.plot()
        &#34;&#34;&#34;

        # Step 1: Set defaults and validate
        if not (0 &lt; peaks_per_mixture[0] &lt;= peaks_per_mixture[1] &lt;= max_peaks):
            raise ValueError(&#34;Invalid peaks_per_mixture range.&#34;)

        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)

        # Step 2: Generate base signals and flatten peaks
        S, peak_list = cls.generate_synthetic(
            n_signals=max_peaks,
            n_peaks=n_peaks,
            kinds=(&#34;gauss&#34;,),
            width_range=width_range,
            height_range=height_range,
            x_range=x_range,
            n_points=n_points,
            normalize=normalize,
            seed=seed,
            **kwargs
            )
        peak_objs = peaks(peak_list)  # Flatten into a peak collection

        all_peaks = list(peak_objs)
        peak_id_map = {p[&#39;name&#39;]: p for p in all_peaks}

        mixtures = []
        used_peak_ids = []

        for i in range(n_mixtures):
            n_peaks_in_mix = random.randint(*peaks_per_mixture)
            selected_peaks = random.sample(all_peaks, n_peaks_in_mix)
            mixture_signal = np.zeros_like(S[0].y)

            current_ids = []
            for p in selected_peaks:
                scale = random.uniform(*amplitude_range)
                yvals = generator(p[&#39;type&#39;])(S[0].x, p[&#39;x&#39;], p[&#39;w&#39;], p[&#39;h&#39;] * scale)
                mixture_signal += yvals
                current_ids.append(p[&#39;name&#39;])

            if flatten == &#39;mean&#39;:
                mixture_signal /= len(selected_peaks)

            sig = signal(x=S[0].x, y=mixture_signal, name=f&#34;mixture {i} of {n_mixtures}&#34;)
            mixtures.append(sig)
            used_peak_ids.append(current_ids)

        result_collection = cls(*mixtures,n=n_points, mode=&#39;union&#39;, force=True)

        return result_collection, all_peaks, used_peak_ids


    def _toDNA(self,encode=True,scales=[1,3,4,8,16,32]):
        &#34;&#34;&#34;
        Return a DNA encoded signal

        Parameters
            encode : bool (default=True)
            scales : list (default=[1,3,4,8,16,32])
        &#34;&#34;&#34;
        return [DNAsignal(s,scales=scales,encode=encode) for s in self]
# %% peaks class
# ------------------------
class peaks:
    &#34;&#34;&#34;
    A class for managing a collection of peak definitions used in synthetic signal generation.

    Each peak is represented as a dictionary with the following fields:
    - &#39;name&#39; (str): unique identifier (autogenerated if not provided)
    - &#39;x&#39; (float): center position (e.g., time, wavenumber, index)
    - &#39;w&#39; (float): width (related to FWHM)
    - &#39;h&#39; (float): peak height
    - &#39;type&#39; (str): generator type (e.g., &#39;gauss&#39;, &#39;lorentz&#39;, &#39;triangle&#39;)

    Supports:
    - Flexible addition and broadcasting of peak parameters
    - Named or indexed access to individual or multiple peaks
    - Overloaded operators for peak translation and scaling
    - Utility methods: update, sort, rename, remove_duplicates, copy
    - Conversion to signal object via `.to_signal()`
    - Informative __str__ and __repr__ output

    This class is used to build reproducible and structured test cases for symbolic encoding (e.g., sig2dna).
    &#34;&#34;&#34;

    def __init__(self, data=None):
        &#34;&#34;&#34;
        Initialize a peak collection.

        Parameters
        ----------
        data : list of dict, list of peaks, or None
            - If None: create an empty peaks object.
            - If list of dict: must contain at least &#39;x&#39;, &#39;w&#39;, &#39;h&#39;; &#39;name&#39; and &#39;type&#39; are optional.
            - If list of peaks: flattens into a single collection.

            If provided, must be a list of dictionaries with the keys:
            - &#39;name&#39; : str (optional; auto-generated if missing or duplicated)
            - &#39;x&#39;    : float (center position)
            - &#39;w&#39;    : float (width)
            - &#39;h&#39;    : float (height)
            - &#39;type&#39; : str (e.g., &#39;gauss&#39;)

        If data is None, initializes an empty peaks object.
        &#34;&#34;&#34;
        self._peaks = []
        self._names = set()
        if data:
            flat_list = []
            if all(isinstance(p, peaks) for p in data):
                # Merge from list of peaks instances
                for p_obj in data:
                    flat_list.extend(p_obj._peaks)
            else:
                flat_list = data
            for p in flat_list:
                name = p.get(&#34;name&#34;, f&#34;P{len(self._peaks)}&#34;)
                while name in self._names:
                    base = name or f&#34;P{len(self._peaks)}&#34;
                    suffix = 0
                    while True:
                        unique_name = f&#34;{base}_{suffix}&#34; if suffix &gt; 0 else base
                        if unique_name not in self._names:
                            break
                        suffix += 1
                    name = unique_name
                peak = {
                    &#34;name&#34;: name,
                    &#34;x&#34;: float(p[&#34;x&#34;]),
                    &#34;w&#34;: float(p[&#34;w&#34;]),
                    &#34;h&#34;: float(p[&#34;h&#34;]),
                    &#34;type&#34;: p.get(&#34;type&#34;, &#34;gauss&#34;)
                }
                self._peaks.append(peak)
                self._names.add(name)
                self.sort()

    def update(self, data):
        &#34;&#34;&#34;
        Update or insert peaks from a list of dictionaries.

        Parameters
        ----------
        data : list of dict
            Each dict must include at least &#39;x&#39;, &#39;w&#39;, &#39;h&#39;.
            If &#39;name&#39; matches an existing peak, it will be updated.
            If &#39;name&#39; is new or missing, the peak is appended.
        &#34;&#34;&#34;
        for p in data:
            name = p.get(&#34;name&#34;, None)
            peak = {
                &#34;name&#34;: name,
                &#34;x&#34;: float(p[&#34;x&#34;]),
                &#34;w&#34;: float(p[&#34;w&#34;]),
                &#34;h&#34;: float(p[&#34;h&#34;]),
                &#34;type&#34;: p.get(&#34;type&#34;, &#34;gauss&#34;)
            }

            if name and name in self._names:
                for i, existing in enumerate(self._peaks):
                    if existing[&#34;name&#34;] == name:
                        self._peaks[i].update(peak)
                        break
            else:
                peak[&#34;name&#34;] = name or f&#34;P{len(self._peaks)}&#34;
                while peak[&#34;name&#34;] in self._names:
                    peak[&#34;name&#34;] += &#34;_&#34;
                self._peaks.append(peak)
                self._names.add(peak[&#34;name&#34;])
        return self

    def add(self, x, w=1.0, h=1.0, name=None, type=&#34;gauss&#34;):
        &#34;&#34;&#34;
        Add one or multiple peaks to the collection.

        Parameters
        ----------
        x : float or array-like
            Center positions of the peaks.
        w : float or array-like
            Width(s) of the peaks (broadcastable).
        h : float or array-like
            Height(s) of the peaks (broadcastable).
        name : str or list of str or None
            Peak name(s); auto-generated if None or duplicate.
        type : str
            Generator type, e.g., &#39;gauss&#39;, &#39;lorentz&#39;, etc.
        &#34;&#34;&#34;
        x = np.atleast_1d(x)
        w = np.full_like(x, w) if np.isscalar(w) else np.asarray(w)
        h = np.full_like(x, h) if np.isscalar(h) else np.asarray(h)
        names = name if isinstance(name, (list, tuple)) else [name] * len(x)

        for i, (xi, wi, hi, ni) in enumerate(zip(x, w, h, names)):
            base = ni or f&#34;P{len(self._peaks)}&#34;
            suffix = 0
            while True:
                candidate = f&#34;{base}_{suffix}&#34; if suffix &gt; 0 else base
                if candidate not in self._names:
                    break
                suffix += 1
            ni = candidate

            self._peaks.append({
                &#34;name&#34;: ni,
                &#34;x&#34;: float(xi),
                &#34;w&#34;: float(wi),
                &#34;h&#34;: float(hi),
                &#34;type&#34;: type
            })
            self._names.add(ni)

    def __getitem__(self, key):
        if isinstance(key, str):
            next((p for p in self._peaks if p[&#39;name&#39;] == key), None)
        elif isinstance(key, int):
            return self._peaks[key]
        elif isinstance(key, (list, tuple)):
            return [self[k] for k in key]
        elif isinstance(key, slice):
            return self._peaks[key]
        else:
            raise KeyError(&#34;Unsupported index type&#34;)

    def __delitem__(self, key):
        if isinstance(key, str):
            self._peaks = [p for p in self._peaks if p[&#39;name&#39;] != key]
            self._names.discard(key)
        elif isinstance(key, int):
            self._names.discard(self._peaks[key][&#39;name&#39;])
            del self._peaks[key]
        elif isinstance(key, (list, tuple)):
            for k in key:
                self.__delitem__(k)
        elif isinstance(key, slice):
            for p in self._peaks[key]:
                self._names.discard(p[&#39;name&#39;])
            del self._peaks[key]

    def __add__(self, shift):
        p = peaks()
        for peak in self._peaks:
            new_peak = peak.copy()
            new_peak[&#39;x&#39;] += shift if np.isscalar(shift) else shift.pop(0)
            p._peaks.append(new_peak)
            p._names.add(new_peak[&#39;name&#39;])
        return p

    def __mul__(self, factor):
        p = peaks()
        for peak in self._peaks:
            new_peak = peak.copy()
            if isinstance(factor, tuple):
                new_peak[&#39;w&#39;] *= factor[0]
                new_peak[&#39;h&#39;] *= factor[1]
            else:
                f = factor if np.isscalar(factor) else factor.pop(0)
                new_peak[&#39;w&#39;] *= f
                new_peak[&#39;h&#39;] *= f
            p._peaks.append(new_peak)
            p._names.add(new_peak[&#39;name&#39;])
        return p

    def __truediv__(self, factor):
        inv = (1/factor[0], 1/factor[1]) if isinstance(factor, tuple) else 1/factor
        return self * inv

    def rename(self, prefix=&#34;P&#34;):
        self._names.clear()
        for i, peak in enumerate(self._peaks):
            peak[&#39;name&#39;] = f&#34;{prefix}{i}&#34;
            self._names.add(peak[&#39;name&#39;])

    def remove_duplicates(self):
        seen = set()
        unique_peaks = []
        for peak in self._peaks:
            key = (peak[&#39;x&#39;], peak[&#39;w&#39;], peak[&#39;h&#39;], peak[&#39;type&#39;])
            if key not in seen:
                seen.add(key)
                unique_peaks.append(peak)
        self._peaks = unique_peaks
        self._names = {p[&#39;name&#39;] for p in self._peaks}

    def __len__(self):
        return len(self._peaks)

    def __repr__(self):
        if not self._peaks:
            return str(self)

        # Compute max name width
        name_width = max(len(p[&#39;name&#39;]) for p in self._peaks)
        type_width = max(len(p[&#39;type&#39;]) for p in self._peaks)

        # Format header (optional)
        header = f&#34;{&#39;name&#39;:&lt;{name_width}}  {&#39;x&#39;:&gt;8}  {&#39;w&#39;:&gt;8}  {&#39;h&#39;:&gt;8}  {&#39;type&#39;:&lt;{type_width}}&#34;
        lines = [header, &#34;-&#34; * len(header)]

        # Format each peak
        for p in self._peaks:
            lines.append(
                f&#34;{p[&#39;name&#39;]:&lt;{name_width}}  &#34;
                f&#34;{p[&#39;x&#39;]:&gt;8.2f}  {p[&#39;w&#39;]:&gt;8.2f}  {p[&#39;h&#39;]:&gt;8.2f}  {p[&#39;type&#39;]:&lt;{type_width}}&#34;
            )

        return &#34;\n&#34;.join(lines)

    def __str__(self):
        if not self._peaks:
            return &#34;&lt;peaks instance with 0 peaks&gt;&#34;
        xmin = min(p[&#39;x&#39;] for p in self._peaks)
        xmax = max(p[&#39;x&#39;] for p in self._peaks)
        return f&#34;&lt;peaks instance with {len(self._peaks)} peaks&gt; spanned from x={xmin:.2f} to x={xmax:.2f}&#34;

    def names(self):
        &#34;&#34;&#34;Return the list of names&#34;&#34;&#34;
        return [p[&#39;name&#39;] for p in self._peaks]

    def as_dict(self):
        &#34;&#34;&#34;Return the list of peaks as dict&#34;&#34;&#34;
        return self._peaks.copy()

    def to_signal(self, index=None, name=None, generator_map=None, x=None, x0=0.0, n=1000):
        &#34;&#34;&#34;Generate a signal from a peaks object. Optionally restrict to a subset.&#34;&#34;&#34;
        selected = self._peaks
        if index is not None:
            if isinstance(index, (str, int)):
                index = [index]
            selected = [self[k] for k in index]
        return signal.from_peaks(selected, x=x, name=name or &#34;from_peaks&#34;, generator_map=generator_map, x0=x0, n=n)

    def copy(self):
        &#34;&#34;&#34;Return a deep-copy of the peaks&#34;&#34;&#34;
        new = peaks()
        new._peaks = deepcopy(self._peaks)
        return new

    def sort(self, order=&#34;asc&#34;):
        &#34;&#34;&#34;
        Sort peaks in-place based on their center positions (x values).

        Parameters
        ----------
        order : str
            Sorting direction. Use:
                - &#34;asc&#34; for ascending (default)
                - &#34;desc&#34; for descending
        &#34;&#34;&#34;
        reverse = {&#34;asc&#34;: False, &#34;desc&#34;: True}.get(order)
        if reverse is None:
            raise ValueError(&#34;order must be &#39;asc&#39; or &#39;desc&#39;&#34;)

        self._peaks.sort(key=lambda p: p[&#39;x&#39;], reverse=reverse)
        return self

# ------------------------
# Generator
# ------------------------
class generator:
    def __init__(self, kind=&#34;gauss&#34;):
        &#34;&#34;&#34;define a peak generator gauss/lorentz/triangle&#34;&#34;&#34;
        self.kind = kind.lower()

    def __call__(self, x, x0, w, h):
        if self.kind.startswith(&#34;gauss&#34;): #simplified Gaussian kernel
            # area: 0.6006*sqrt(pi)*w*h
            # standard deviation: 0.6006/sqrt(2)*w
            return h * np.exp(-((x - x0) / (0.6006 * w)) ** 2)
        elif self.kind.startswith(&#34;lorentz&#34;):
            return  h * 1/(1+((x-x0) / (0.5*w)) ** 2)
        elif self.kind.startswith(&#34;triang&#34;):
            d = np.abs(x - x0)
            return h * np.maximum(1 - d / (0.6006 * w), 0)
        else:
            raise ValueError(f&#34;Unknown generator kind: {self.kind}&#34;)

    def __repr__(self):
        return f&#34;&lt;generator kind=&#39;{self.kind}&#39;&gt;&#34;


# %% Example usage
if __name__ == &#34;__main__&#34;:

    # output folder
    outputfolder = &#34;./images&#34; if os.path.isdir(&#34;./images&#34;) else (&#34;../images&#34; if os.path.isdir(&#34;../images&#34;) else None)

    # Define peaks
    p = peaks()
    p.add(x=10, w=2, h=1)
    p.add(x=20, w=2, h=1)
    p.add(x=30, w=2, h=1)

    # Convert to signal
    s = p.to_signal()  # defaults to x0=0, n=1000
    print(s)
    fig,_ = s.plot(); fig.print(&#34;simple_signal&#34;,outputfolder)

    # Generate variants
    s_noisy1 = s.add_noise(kind=&#34;gaussian&#34;, scale=0.01, bias=5)
    s_noisy2 = s.add_noise(kind=&#34;poisson&#34;, scale=10, bias=&#34;ramp&#34;)
    s_scaled = s * 0.5


    # Create a signal collection
    collection = signal_collection(s, s_noisy1, s_noisy2, s_scaled)
    print(collection)
    fig = collection.plot(); fig.print(&#34;collection_simple_signals&#34;,outputfolder)

    s_mean = collection.mean()
    s_sum = collection.sum()

    s_mean.plot(label=&#34;Mean&#34;)
    s_sum.plot(label=&#34;Sum&#34;)


    # Synthetic signals
    S,pS = signal_collection.generate_synthetic(
        n_signals=12,
        n_peaks=1,
        kinds=(&#34;gauss&#34;,),
        width_range=(0.5, 3),
        height_range=(1.0, 5.0),
        x_range=(0, 500),
        n_points=2048,
        normalize=False,
        seed=123
    )
    pS = peaks(pS) # flatten all peaks
    S.plot(fontsize=14)
    Sfull = S.mean()
    fig,_ = Sfull.plot(newfig=True); fig.print(&#34;synthetic_signal&#34;,outputfolder)

    # Transform
    dna = DNAsignal(Sfull)
    dna.compute_cwt()
    # dna.transforms.plot()
    dna.encode_dna()
    dna.encode_dna_full()
    dna.plot_codes(4)
    A=dna.codesfull[4]
    B=dna.codesfull[2]
    # Alignement
    A.align(B)
    A.html_alignment()
    print(A.wrapped_alignment(40))
    A.plot_alignment()
    As = A.to_signal()
    Bs = B.to_signal()
    ABs = signal_collection(As,Bs)
    plt.figure(); As.plot()
    ABs.plot()
    # substring (peaks) extraction
    pA_list = A.find(&#34;YAZB&#34;)
    pA =[s.to_signal() for s in pA_list]
    pAs = signal_collection(*[s.to_signal() for s in pA_list])
    pAs.plot()

    # Signal mixtures and their classification
    Smix, pSmix, idSmix = signal_collection.generate_mixtures(
        n_mixtures=30,
        max_peaks=16,
        peaks_per_mixture=(4, 8),
        amplitude_range=(0.5, 2),
        n_signals=1,
        kinds=(&#34;gauss&#34;,),
        width_range=(0.5, 3),
        height_range=(1.0, 5.0),
        x_range=(0, 500),
        n_points=2048,
        normalize=False,
        seed=123
        )

    dnaSmix = Smix._toDNA(scales=[1,2,4,8,16,32])
    D = DNAsignal._pairwiseEntropyDistance(dnaSmix,scale=4,engine=&#34;bio&#34;)
    D.name = &#34;Excess Entropy&#34;
    Ddhalf, figD1 = D.dimension_variance_curve(); figD1.print(&#34;Entropy_dimensions&#34;,outputfolder)
    D.select_dimensions(10)
    figD2 = D.plot_dendrogram(); figD2.print(&#34;Entropy_dendrogram&#34;,outputfolder)
    figD3 = D.scatter3d(n_clusters=5); figD3.print(&#34;Entropy_scatter&#34;,outputfolder)

    J = DNAsignal._pairwiseJaccardMotifDistance(dnaSmix,scale=4)
    J.name = &#34;YAZB Jaccard&#34;
    Jdhalf,figJ1 = J.dimension_variance_curve(); figJ1.print(&#34;Jaccard_dimensions&#34;,outputfolder)
    J.select_dimensions(10)
    figJ2 = J.plot_dendrogram(); figJ2.print(&#34;Jaccard_dendrogram&#34;,outputfolder)
    figJ3 = J.scatter3d(n_clusters=5); figJ3.print(&#34;Jaccard_scatter3&#34;,outputfolder)

    L = DNAsignal._pairwiseLevenshteinDistance(dnaSmix,scale=4)
    L.name = &#34;Levenshtein&#34;
    Ldhalf,figL1 = L.dimension_variance_curve(); figL1.print(&#34;Lenvenshtein_dimensions&#34;,outputfolder)
    L.select_dimensions(10)
    figL2 = L.plot_dendrogram(); figL2.print(&#34;Lenvenshtein_dendrogram&#34;,outputfolder)
    figL3 = L.scatter3d(n_clusters=5); figL3.print(&#34;Lenvenshtein_scatter3&#34;,outputfolder)

    S = DNAsignal._pairwiseJensenShannonDistance(dnaSmix,scale=4)
    S.name = &#34;Jensen-Shannon&#34;
    Sdhalf,figJ1 = S.dimension_variance_curve(); figJ1.print(&#34;JensenShannon_dimensions&#34;,outputfolder)
    S.select_dimensions(10);
    figJ2 = S.plot_dendrogram(); figJ2.print(&#34;JensenShannon_dendrogram&#34;,outputfolder)
    figJ3 = S.scatter3d(n_clusters=5); figJ3.print(&#34;JensenShannon_scatter3&#34;,outputfolder)

    # Final summary table
    print(&#39;\nNumber of dimensions to recover 50% of total distance:\n&#39;)

    header = f&#34;{&#39;Distance Metric&#39;:&lt;20} | {&#39;dhalf&#39;:&gt;6}&#34;
    separator = &#34;-&#34; * len(header)
    rows = [
        (&#34;Excess Entropy&#34;, Ddhalf),
        (&#34;YAZB Jaccard&#34;, Jdhalf),
        (&#34;Levenshtein&#34;, Ldhalf),
        (&#34;Jensen-Shannon&#34;, Sdhalf),
    ]

    print(header)
    print(separator)
    for name, val in rows:
        print(f&#34;{name:&lt;20} | {val:6}&#34;)

    # Demo Alignment on Banner
    S1 = signal_collection.generate_synthetic(
        n_signals=8,
        n_peaks=2, kinds=(&#34;gauss&#34;,),
        width_range=(0.5, 2), height_range=(1.0, 5.0),
        x_range=(0, 127), n_points=128, normalize=False, seed=123)[0].mean()
    S1.name = &#34;S1&#34;

    S2 = signal_collection.generate_synthetic(
        n_signals=6,
        n_peaks=2, kinds=(&#34;gauss&#34;,),
        width_range=(0.4, 1.5), height_range=(1.0, 5.0),
        x_range=(0, 127), n_points=128, normalize=False, seed=456)[0].mean()
    S2.name = &#34;S2&#34;
    S12 = signal_collection(S1,S2,n=128)
    S12.name = &#34;S1 vs. S2&#34;
    S12.plot()
    S12dna = S12._toDNA(scales=[1,2,4,8,16,32])
    s1 = signal(y=S12dna[0].cwt_coeffs[2], name=&#34;S1&#34;)
    s2 =  signal(y=S12dna[1].cwt_coeffs[2], name=&#34;S2&#34;)
    s1code = S12dna[0].codesfull[2]
    s2code = S12dna[1].codesfull[2]
    s1code.align(s2code,&#34;bio&#34;)
    S12dna_scale2 = signal_collection(s1,s2)
    S12dna_scale2.name=&#34;S1 vs. S2 - CWT at scale 2&#34;
    S12dna_scale2.plot()
    s1code.plot_alignment()
    s1code.plot_mask()
    print(s1code.wrapped_alignment(width=1024))

# %% obsolete
&#34;&#34;&#34;
    # Early examples
    x = np.linspace(0, 1000, 1000)
    sig = np.exp(-((x - 500) ** 2) / (2 * 30 ** 2))

    s2d = sig2dna(sig)
    s2d.compute_cwt(scales=[1, 2, 4, 8])
    s2d.encode_dna(scale=4)

    print(s2d.get_code(scale=4))
    print(&#34;Entropy:&#34;, s2d.get_entropy(scale=4))

    matches = s2d.find_sequence(&#34;A&#34;, scale=4)
    print(&#34;Matches:&#34;, matches)

    reconstructed = s2d.reconstruct_signal(scale=4)

    plt.plot(sig, label=&#39;Original Signal&#39;)
    plt.plot(reconstructed, label=&#39;Reconstructed Signal&#39;, linestyle=&#39;--&#39;)
    plt.legend()
    plt.show()
&#34;&#34;&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="signomics.DNApairwiseAnalysis"><code class="flex name class">
<span>class <span class="ident">DNApairwiseAnalysis</span></span>
<span>(</span><span>D, names, DNAsignals, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Class to handle pairwise distance analysis, PCoA, clustering, and visualization
for DNA-coded signals.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>D</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Pairwise excess entropy distance matrix.</dd>
<dt><strong><code>names</code></strong> :&ensp;<code>list</code></dt>
<dd>Names of the DNA signals.</dd>
<dt><strong><code>DNAsignals</code></strong> :&ensp;<code>list</code></dt>
<dd>original DNAsignal objects</dd>
<dt><strong><code>coords</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Coordinates in reduced space (PCoA).</dd>
<dt><strong><code>dimensions</code></strong> :&ensp;<code>list</code></dt>
<dd>Selected dimensions for reduced analysis.</dd>
<dt><strong><code>linkage_matrix</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Linkage matrix used for hierarchical clustering.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DNApairwiseAnalysis:
    &#34;&#34;&#34;
    Class to handle pairwise distance analysis, PCoA, clustering, and visualization
    for DNA-coded signals.

    Attributes
    ----------
    D : np.ndarray
        Pairwise excess entropy distance matrix.
    names : list
        Names of the DNA signals.
    DNAsignals : list
        original DNAsignal objects
    coords : np.ndarray
        Coordinates in reduced space (PCoA).
    dimensions : list
        Selected dimensions for reduced analysis.
    linkage_matrix : np.ndarray
        Linkage matrix used for hierarchical clustering.
    &#34;&#34;&#34;

    def __init__(self, D, names, DNAsignals, name=None):
        self.name = name if not name is None else &#34;unamed&#34;
        self.D = np.array(D)
        self.names = list(names)
        self.n = len(self.names)
        self.DNAsignals = DNAsignals
        self.coords = None
        self.dimensions = list(range(self.n))  # All by default
        self.linkage_matrix = None
        self.pcoa()

    def pcoa(self, n_components=None):
        &#34;&#34;&#34;Perform Principal Coordinate Analysis (PCoA).&#34;&#34;&#34;
        if n_components is None:
            n_components = min(self.n, 1000)
        mds = MDS(n_components=n_components, dissimilarity=&#39;precomputed&#39;, random_state=42)
        self.coords = mds.fit_transform(self.D)
        self.dimensions = list(range(n_components))

    def select_dimensions(self, dims):
        &#34;&#34;&#34;Update active dimensions.&#34;&#34;&#34;
        if isinstance(dims,int):
            self.dimensions = list(range(dims))
        elif isinstance(dims,(list,tuple)):
            self.dimensions = dims
        else:
            raise TypeError(f&#34;dims must be a int, list or tuple not a {type(dims).__name__}&#34;)

    def reduced_distances(self):
        &#34;&#34;&#34;Recompute distances on selected subspace.&#34;&#34;&#34;
        coords_sel = self.coords[:, self.dimensions]
        return pairwise_distances(coords_sel)

    def compute_linkage(self, method=&#39;ward&#39;):
        &#34;&#34;&#34;Compute hierarchical clustering.&#34;&#34;&#34;
        D = self.reduced_distances()
        D = (D + D.T) / 2  # force symmetry
        reduced_D = squareform(D)
        self.linkage_matrix = linkage(reduced_D, method=method)

    def heatmap(self, figsize=(10, 8)):
        &#34;&#34;&#34;Plot heatmap of pairwise distances.&#34;&#34;&#34;
        fig=plt.figure(figsize=figsize)
        sns.heatmap(self.D, xticklabels=self.names, yticklabels=self.names, cmap=&#39;viridis&#39;)
        title = f&#39;Pairwise Excess Entropy Distances — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.tight_layout()
        plt.show()
        return fig

    def get_cluster_labels(self, n_clusters=2, method=&#39;ward&#39;):
        &#34;&#34;&#34;
        Returns cluster labels from hierarchical clustering. If not computed yet, computes linkage.

        Parameters
        ----------
        n_clusters : int
            Number of clusters to assign.
        method : str
            Linkage method to use if recomputing linkage.

        Returns
        -------
        labels : np.ndarray of int
            Cluster IDs for each sample.
        &#34;&#34;&#34;
        if self.linkage_matrix is None:
            self.compute_linkage(method=method)
        self.cluster_labels = fcluster(self.linkage_matrix, t=n_clusters, criterion=&#39;maxclust&#39;)
        return self.cluster_labels

    def scatter(self, dims=(0, 1), annotate=True, figsize=(8, 6), n_clusters=None):
        &#34;&#34;&#34;
        2D scatter plot in selected dimensions with optional cluster-based coloring.

        Parameters
        ----------
        dims : tuple
            Dimensions to plot (default: (0, 1)).
        annotate : bool
            If True, annotate points with their index.
        figsize : tuple
            Size of the plot.
        n_clusters : int or None
            If provided, use clustering to color points.

        Returns
        -------
        fig : matplotlib.figure.Figure
        &#34;&#34;&#34;
        fig = plt.figure(figsize=figsize)
        x, y = self.coords[:, dims[0]], self.coords[:, dims[1]]

        if n_clusters is not None:
            labels = self.get_cluster_labels(n_clusters=n_clusters)
            scatter = plt.scatter(x, y, c=labels, cmap=&#39;tab10&#39;, s=50)
        else:
            scatter = plt.scatter(x, y, s=50)

        if annotate:
            for i, name in enumerate(self.names):
                plt.text(x[i], y[i], str(i), fontsize=9)

        plt.xlabel(f&#34;Dimension {dims[0] + 1}&#34;)
        plt.ylabel(f&#34;Dimension {dims[1] + 1}&#34;)
        title = f&#39;PCoA Scatter Plot — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.grid(True)
        plt.tight_layout()
        plt.show()
        return fig


    def scatter3d(self, dims=(0, 1, 2), annotate=True, n_clusters=None):
        &#34;&#34;&#34;
        3D scatter plot in selected dimensions with optional cluster-based coloring.

        Parameters
        ----------
        dims : tuple
            Dimensions to plot.
        annotate : bool
            Annotate points with their index.
        n_clusters : int or None
            If provided, use clustering to color points.

        Returns
        -------
        fig : matplotlib.figure.Figure
        &#34;&#34;&#34;
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection=&#39;3d&#39;)
        x, y, z = self.coords[:, dims[0]], self.coords[:, dims[1]], self.coords[:, dims[2]]

        if n_clusters is not None:
            labels = self.get_cluster_labels(n_clusters=n_clusters)
            scatter = ax.scatter(x, y, z, c=labels, cmap=&#39;tab10&#39;, s=50)
        else:
            scatter = ax.scatter(x, y, z, s=50)
        if annotate:
            for i, name in enumerate(self.names):
                ax.text(x[i], y[i], z[i], str(i), fontsize=9)

        ax.set_xlabel(f&#34;Dim {dims[0] + 1}&#34;)
        ax.set_ylabel(f&#34;Dim {dims[1] + 1}&#34;)
        ax.set_zlabel(f&#34;Dim {dims[2] + 1}&#34;)
        title = f&#39;3D PCoA Scatter Plot — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.tight_layout()
        plt.show()
        return fig


    def plot_dendrogram(self, truncate_mode=None, p=10):
        &#34;&#34;&#34;Plot dendrogram from linkage matrix.&#34;&#34;&#34;
        if self.linkage_matrix is None:
            self.compute_linkage()
        fig=plt.figure(figsize=(10, 6))
        dendrogram(self.linkage_matrix, labels=self.names, truncate_mode=truncate_mode, p=p)
        plt.title(&#34;Hierarchical Clustering Dendrogram&#34;)
        plt.xlabel(&#34;Sample Index or Name&#34;)
        plt.ylabel(&#34;Distance&#34;)
        plt.tight_layout()
        title = f&#39;PCoA Dendrogram — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.show()
        return fig

    def cluster(self, t=1.0, criterion=&#39;distance&#39;):
        &#34;&#34;&#34;Assign cluster labels from linkage matrix.&#34;&#34;&#34;
        if self.linkage_matrix is None:
            self.compute_linkage()
        return fcluster(self.linkage_matrix, t=t, criterion=criterion)

    def best_dimension(self, max_dim=10):
        &#34;&#34;&#34;Determine optimal dimension by maximizing silhouette score.&#34;&#34;&#34;
        scores = []
        for d in range(2, min(self.n, max_dim + 1)):
            coords = self.coords[:, :d]
            labels = fcluster(linkage(coords, method=&#39;ward&#39;), t=2, criterion=&#39;maxclust&#39;)
            try:
                score = silhouette_score(coords, labels)
                scores.append((d, score))
            except:
                continue
        if scores:
            best_d, best_score = max(scores, key=lambda x: x[1])
            self.select_dimensions(list(range(best_d)))
            return best_d, best_score
        return None, None

    def save(self, path):
        &#34;&#34;&#34;Save current analysis to file.&#34;&#34;&#34;
        with open(path, &#39;wb&#39;) as f:
            pickle.dump(self, f)

    @staticmethod
    def load(path):
        &#34;&#34;&#34;Load analysis from file.&#34;&#34;&#34;
        with open(path, &#39;rb&#39;) as f:
            return pickle.load(f)

    def __repr__(self):
        return (f&#34;DNAPairwiseAnalysis(\n&#34;
                f&#34;  name={self.name},\n&#34;
                f&#34;  n_samples={self.n},\n&#34;
                f&#34;  dimensions={len(self.dimensions)},\n&#34;
                f&#34;  active_dims={self.dimensions},\n&#34;
                f&#34;  linkage_computed={&#39;Yes&#39; if self.linkage_matrix is not None else &#39;No&#39;}\n)&#34;)

    def __str__(self):
        return f&#34;DNAPairwiseAnalysis with {self.n} samples in {len(self.dimensions)} dimensions&#34;

    def dimension_variance_curve(self, threshold=0.5, plot=True, figsize=(8, 5)):
        &#34;&#34;&#34;
        Computes the cumulative explained variance (based on pairwise distances) as a function of
        the number of dimensions used (from 1 to n-1). Optionally plots the curve and the point
        where the threshold (default 0.5) is reached.

        Parameters
        ----------
        threshold : float
            Fraction of total variance to reach (default 0.5).
        plot : bool
            If True, display the variance curve and highlight dhalf.
        figsize : tuple
            Size of the figure if plotted.

        Returns
        -------
        dhalf : int
            Number of dimensions needed to reach the threshold.
        curve : list of float
            Normalized cumulative variance (in [0, 1]) for dimensions 1 to n-1.
        &#34;&#34;&#34;
        max_d = self.coords.shape[1] # min(self.n - 1, self.coords.shape[1])
        total_var = np.sum(pairwise_distances(self.coords[:, :max_d]))
        curve = []
        for d in range(1, max_d + 1):
            d_var = np.sum(pairwise_distances(self.coords[:, :d]))
            curve.append(d_var / total_var)

        dhalf = next((i + 1 for i, v in enumerate(curve) if v &gt;= threshold), max_d)

        if plot:
            fig=plt.figure(figsize=figsize)
            plt.plot(range(1, max_d + 1), curve, marker=&#39;o&#39;, label=&#39;Cumulative variance&#39;)
            plt.axhline(y=threshold, color=&#39;gray&#39;, linestyle=&#39;--&#39;, label=f&#39;Threshold = {threshold}&#39;)
            plt.axvline(x=dhalf, color=&#39;red&#39;, linestyle=&#39;--&#39;, label=f&#39;dhalf = {dhalf}&#39;)
            plt.xlabel(&#39;Number of dimensions used&#39;)
            plt.ylabel(&#39;Normalized cumulative variance (distance)&#39;)
            title = f&#39;Cumulative Variance vs. Dimensions — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
            plt.title(title)
            plt.grid(True)
            plt.legend()
            plt.tight_layout()
            plt.show()

        return dhalf, fig</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="signomics.DNApairwiseAnalysis.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>path)</span>
</code></dt>
<dd>
<div class="desc"><p>Load analysis from file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def load(path):
    &#34;&#34;&#34;Load analysis from file.&#34;&#34;&#34;
    with open(path, &#39;rb&#39;) as f:
        return pickle.load(f)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="signomics.DNApairwiseAnalysis.best_dimension"><code class="name flex">
<span>def <span class="ident">best_dimension</span></span>(<span>self, max_dim=10)</span>
</code></dt>
<dd>
<div class="desc"><p>Determine optimal dimension by maximizing silhouette score.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def best_dimension(self, max_dim=10):
    &#34;&#34;&#34;Determine optimal dimension by maximizing silhouette score.&#34;&#34;&#34;
    scores = []
    for d in range(2, min(self.n, max_dim + 1)):
        coords = self.coords[:, :d]
        labels = fcluster(linkage(coords, method=&#39;ward&#39;), t=2, criterion=&#39;maxclust&#39;)
        try:
            score = silhouette_score(coords, labels)
            scores.append((d, score))
        except:
            continue
    if scores:
        best_d, best_score = max(scores, key=lambda x: x[1])
        self.select_dimensions(list(range(best_d)))
        return best_d, best_score
    return None, None</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.cluster"><code class="name flex">
<span>def <span class="ident">cluster</span></span>(<span>self, t=1.0, criterion='distance')</span>
</code></dt>
<dd>
<div class="desc"><p>Assign cluster labels from linkage matrix.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cluster(self, t=1.0, criterion=&#39;distance&#39;):
    &#34;&#34;&#34;Assign cluster labels from linkage matrix.&#34;&#34;&#34;
    if self.linkage_matrix is None:
        self.compute_linkage()
    return fcluster(self.linkage_matrix, t=t, criterion=criterion)</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.compute_linkage"><code class="name flex">
<span>def <span class="ident">compute_linkage</span></span>(<span>self, method='ward')</span>
</code></dt>
<dd>
<div class="desc"><p>Compute hierarchical clustering.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_linkage(self, method=&#39;ward&#39;):
    &#34;&#34;&#34;Compute hierarchical clustering.&#34;&#34;&#34;
    D = self.reduced_distances()
    D = (D + D.T) / 2  # force symmetry
    reduced_D = squareform(D)
    self.linkage_matrix = linkage(reduced_D, method=method)</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.dimension_variance_curve"><code class="name flex">
<span>def <span class="ident">dimension_variance_curve</span></span>(<span>self, threshold=0.5, plot=True, figsize=(8, 5))</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the cumulative explained variance (based on pairwise distances) as a function of
the number of dimensions used (from 1 to n-1). Optionally plots the curve and the point
where the threshold (default 0.5) is reached.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>Fraction of total variance to reach (default 0.5).</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, display the variance curve and highlight dhalf.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Size of the figure if plotted.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dhalf</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of dimensions needed to reach the threshold.</dd>
<dt><strong><code>curve</code></strong> :&ensp;<code>list</code> of <code>float</code></dt>
<dd>Normalized cumulative variance (in [0, 1]) for dimensions 1 to n-1.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dimension_variance_curve(self, threshold=0.5, plot=True, figsize=(8, 5)):
    &#34;&#34;&#34;
    Computes the cumulative explained variance (based on pairwise distances) as a function of
    the number of dimensions used (from 1 to n-1). Optionally plots the curve and the point
    where the threshold (default 0.5) is reached.

    Parameters
    ----------
    threshold : float
        Fraction of total variance to reach (default 0.5).
    plot : bool
        If True, display the variance curve and highlight dhalf.
    figsize : tuple
        Size of the figure if plotted.

    Returns
    -------
    dhalf : int
        Number of dimensions needed to reach the threshold.
    curve : list of float
        Normalized cumulative variance (in [0, 1]) for dimensions 1 to n-1.
    &#34;&#34;&#34;
    max_d = self.coords.shape[1] # min(self.n - 1, self.coords.shape[1])
    total_var = np.sum(pairwise_distances(self.coords[:, :max_d]))
    curve = []
    for d in range(1, max_d + 1):
        d_var = np.sum(pairwise_distances(self.coords[:, :d]))
        curve.append(d_var / total_var)

    dhalf = next((i + 1 for i, v in enumerate(curve) if v &gt;= threshold), max_d)

    if plot:
        fig=plt.figure(figsize=figsize)
        plt.plot(range(1, max_d + 1), curve, marker=&#39;o&#39;, label=&#39;Cumulative variance&#39;)
        plt.axhline(y=threshold, color=&#39;gray&#39;, linestyle=&#39;--&#39;, label=f&#39;Threshold = {threshold}&#39;)
        plt.axvline(x=dhalf, color=&#39;red&#39;, linestyle=&#39;--&#39;, label=f&#39;dhalf = {dhalf}&#39;)
        plt.xlabel(&#39;Number of dimensions used&#39;)
        plt.ylabel(&#39;Normalized cumulative variance (distance)&#39;)
        title = f&#39;Cumulative Variance vs. Dimensions — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
        plt.title(title)
        plt.grid(True)
        plt.legend()
        plt.tight_layout()
        plt.show()

    return dhalf, fig</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.get_cluster_labels"><code class="name flex">
<span>def <span class="ident">get_cluster_labels</span></span>(<span>self, n_clusters=2, method='ward')</span>
</code></dt>
<dd>
<div class="desc"><p>Returns cluster labels from hierarchical clustering. If not computed yet, computes linkage.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n_clusters</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of clusters to assign.</dd>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code></dt>
<dd>Linkage method to use if recomputing linkage.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>labels</code></strong> :&ensp;<code>np.ndarray</code> of <code>int</code></dt>
<dd>Cluster IDs for each sample.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_cluster_labels(self, n_clusters=2, method=&#39;ward&#39;):
    &#34;&#34;&#34;
    Returns cluster labels from hierarchical clustering. If not computed yet, computes linkage.

    Parameters
    ----------
    n_clusters : int
        Number of clusters to assign.
    method : str
        Linkage method to use if recomputing linkage.

    Returns
    -------
    labels : np.ndarray of int
        Cluster IDs for each sample.
    &#34;&#34;&#34;
    if self.linkage_matrix is None:
        self.compute_linkage(method=method)
    self.cluster_labels = fcluster(self.linkage_matrix, t=n_clusters, criterion=&#39;maxclust&#39;)
    return self.cluster_labels</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.heatmap"><code class="name flex">
<span>def <span class="ident">heatmap</span></span>(<span>self, figsize=(10, 8))</span>
</code></dt>
<dd>
<div class="desc"><p>Plot heatmap of pairwise distances.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def heatmap(self, figsize=(10, 8)):
    &#34;&#34;&#34;Plot heatmap of pairwise distances.&#34;&#34;&#34;
    fig=plt.figure(figsize=figsize)
    sns.heatmap(self.D, xticklabels=self.names, yticklabels=self.names, cmap=&#39;viridis&#39;)
    title = f&#39;Pairwise Excess Entropy Distances — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
    plt.title(title)
    plt.tight_layout()
    plt.show()
    return fig</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.pcoa"><code class="name flex">
<span>def <span class="ident">pcoa</span></span>(<span>self, n_components=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform Principal Coordinate Analysis (PCoA).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pcoa(self, n_components=None):
    &#34;&#34;&#34;Perform Principal Coordinate Analysis (PCoA).&#34;&#34;&#34;
    if n_components is None:
        n_components = min(self.n, 1000)
    mds = MDS(n_components=n_components, dissimilarity=&#39;precomputed&#39;, random_state=42)
    self.coords = mds.fit_transform(self.D)
    self.dimensions = list(range(n_components))</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.plot_dendrogram"><code class="name flex">
<span>def <span class="ident">plot_dendrogram</span></span>(<span>self, truncate_mode=None, p=10)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot dendrogram from linkage matrix.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_dendrogram(self, truncate_mode=None, p=10):
    &#34;&#34;&#34;Plot dendrogram from linkage matrix.&#34;&#34;&#34;
    if self.linkage_matrix is None:
        self.compute_linkage()
    fig=plt.figure(figsize=(10, 6))
    dendrogram(self.linkage_matrix, labels=self.names, truncate_mode=truncate_mode, p=p)
    plt.title(&#34;Hierarchical Clustering Dendrogram&#34;)
    plt.xlabel(&#34;Sample Index or Name&#34;)
    plt.ylabel(&#34;Distance&#34;)
    plt.tight_layout()
    title = f&#39;PCoA Dendrogram — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
    plt.title(title)
    plt.show()
    return fig</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.reduced_distances"><code class="name flex">
<span>def <span class="ident">reduced_distances</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Recompute distances on selected subspace.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reduced_distances(self):
    &#34;&#34;&#34;Recompute distances on selected subspace.&#34;&#34;&#34;
    coords_sel = self.coords[:, self.dimensions]
    return pairwise_distances(coords_sel)</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, path)</span>
</code></dt>
<dd>
<div class="desc"><p>Save current analysis to file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, path):
    &#34;&#34;&#34;Save current analysis to file.&#34;&#34;&#34;
    with open(path, &#39;wb&#39;) as f:
        pickle.dump(self, f)</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.scatter"><code class="name flex">
<span>def <span class="ident">scatter</span></span>(<span>self, dims=(0, 1), annotate=True, figsize=(8, 6), n_clusters=None)</span>
</code></dt>
<dd>
<div class="desc"><p>2D scatter plot in selected dimensions with optional cluster-based coloring.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Dimensions to plot (default: (0, 1)).</dd>
<dt><strong><code>annotate</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, annotate points with their index.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Size of the plot.</dd>
<dt><strong><code>n_clusters</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>If provided, use clustering to color points.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>matplotlib.figure.Figure</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scatter(self, dims=(0, 1), annotate=True, figsize=(8, 6), n_clusters=None):
    &#34;&#34;&#34;
    2D scatter plot in selected dimensions with optional cluster-based coloring.

    Parameters
    ----------
    dims : tuple
        Dimensions to plot (default: (0, 1)).
    annotate : bool
        If True, annotate points with their index.
    figsize : tuple
        Size of the plot.
    n_clusters : int or None
        If provided, use clustering to color points.

    Returns
    -------
    fig : matplotlib.figure.Figure
    &#34;&#34;&#34;
    fig = plt.figure(figsize=figsize)
    x, y = self.coords[:, dims[0]], self.coords[:, dims[1]]

    if n_clusters is not None:
        labels = self.get_cluster_labels(n_clusters=n_clusters)
        scatter = plt.scatter(x, y, c=labels, cmap=&#39;tab10&#39;, s=50)
    else:
        scatter = plt.scatter(x, y, s=50)

    if annotate:
        for i, name in enumerate(self.names):
            plt.text(x[i], y[i], str(i), fontsize=9)

    plt.xlabel(f&#34;Dimension {dims[0] + 1}&#34;)
    plt.ylabel(f&#34;Dimension {dims[1] + 1}&#34;)
    title = f&#39;PCoA Scatter Plot — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
    plt.title(title)
    plt.grid(True)
    plt.tight_layout()
    plt.show()
    return fig</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.scatter3d"><code class="name flex">
<span>def <span class="ident">scatter3d</span></span>(<span>self, dims=(0, 1, 2), annotate=True, n_clusters=None)</span>
</code></dt>
<dd>
<div class="desc"><p>3D scatter plot in selected dimensions with optional cluster-based coloring.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dims</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Dimensions to plot.</dd>
<dt><strong><code>annotate</code></strong> :&ensp;<code>bool</code></dt>
<dd>Annotate points with their index.</dd>
<dt><strong><code>n_clusters</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>If provided, use clustering to color points.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>matplotlib.figure.Figure</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scatter3d(self, dims=(0, 1, 2), annotate=True, n_clusters=None):
    &#34;&#34;&#34;
    3D scatter plot in selected dimensions with optional cluster-based coloring.

    Parameters
    ----------
    dims : tuple
        Dimensions to plot.
    annotate : bool
        Annotate points with their index.
    n_clusters : int or None
        If provided, use clustering to color points.

    Returns
    -------
    fig : matplotlib.figure.Figure
    &#34;&#34;&#34;
    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection=&#39;3d&#39;)
    x, y, z = self.coords[:, dims[0]], self.coords[:, dims[1]], self.coords[:, dims[2]]

    if n_clusters is not None:
        labels = self.get_cluster_labels(n_clusters=n_clusters)
        scatter = ax.scatter(x, y, z, c=labels, cmap=&#39;tab10&#39;, s=50)
    else:
        scatter = ax.scatter(x, y, z, s=50)
    if annotate:
        for i, name in enumerate(self.names):
            ax.text(x[i], y[i], z[i], str(i), fontsize=9)

    ax.set_xlabel(f&#34;Dim {dims[0] + 1}&#34;)
    ax.set_ylabel(f&#34;Dim {dims[1] + 1}&#34;)
    ax.set_zlabel(f&#34;Dim {dims[2] + 1}&#34;)
    title = f&#39;3D PCoA Scatter Plot — {getattr(self, &#34;name&#34;, &#34;Unnamed Analysis&#34;)}&#39;
    plt.title(title)
    plt.tight_layout()
    plt.show()
    return fig</code></pre>
</details>
</dd>
<dt id="signomics.DNApairwiseAnalysis.select_dimensions"><code class="name flex">
<span>def <span class="ident">select_dimensions</span></span>(<span>self, dims)</span>
</code></dt>
<dd>
<div class="desc"><p>Update active dimensions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_dimensions(self, dims):
    &#34;&#34;&#34;Update active dimensions.&#34;&#34;&#34;
    if isinstance(dims,int):
        self.dimensions = list(range(dims))
    elif isinstance(dims,(list,tuple)):
        self.dimensions = dims
    else:
        raise TypeError(f&#34;dims must be a int, list or tuple not a {type(dims).__name__}&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="signomics.DNAsignal"><code class="flex name class">
<span>class <span class="ident">DNAsignal</span></span>
<span>(</span><span>signal_obj, sampling_dt=1.0, dtype=numpy.float64, encode=False, encoder=['compute_cwt', 'encode_dna', 'encode_dna_full'], scales=[1, 2, 4, 8, 16, 32], x_label='index', x_unit='-', y_label='Intensity', y_unit='', plot=False, plotter=['plot_signals', 'plot_transforms', 'plot_codes'])</span>
</code></dt>
<dd>
<div class="desc"><h1 id="dnasignalsignal">DNAsignal(signal):</h1>
<p>A class to encode a numerical signal (typically a 1D GC-MS trace, NMR/FTIR/Raman spectra
or time series) into a DNA-like symbolic representation using wavelet analysis.
This symbolic coding enables fast comparison, search, and alignment of signal features
using abstracted patterns (e.g., 'YAZB').</p>
<p>The class supports:
- Continuous Wavelet Transform (CWT) using Ricker wavelets
- Symbolic conversion of wavelet features to DNA-like letters (A, B, C, X, Y, Z)
- Visualization of CWTs, symbolic encodings, and signal overlays
- Reversible decoding of symbolic segments back into approximate signals
- Substring extraction and matching
- Storage of multi-scale representations (multi-resolution DNA encoding)</p>
<p>This class is part of the symbolic signal transformation pipeline (<code>sig2dna</code>), compatible with <code><a title="signomics.signal" href="#signomics.signal">signal</a></code>, <code><a title="signomics.peaks" href="#signomics.peaks">peaks</a></code>, and <code><a title="signomics.signal_collection" href="#signomics.signal_collection">signal_collection</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>signal</code></strong> :&ensp;<code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>An instance of the <code><a title="signomics.signal" href="#signomics.signal">signal</a></code> class representing a sampled waveform. It must
have <code>x</code>, <code>y</code>, and a valid name or identifier.</dd>
<dt><strong><code>encode</code></strong> :&ensp;<code>bool (default = False)</code></dt>
<dd>Launch encoders = ["compute_cwt","encode_dna","encode_dna_full"] if True</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool (default = False)</code></dt>
<dd>Plot with plotter = ["plot_signals","plot_transforms","plot_codes"]</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>signal</code></strong> :&ensp;<code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>The raw signal object being encoded.</dd>
<dt><strong><code>dx</code></strong> :&ensp;<code>float</code></dt>
<dd>The nominal x-resolution of the signal (automatically derived).</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points in the signal (length of x/y arrays).</dd>
<dt><strong><code>scales</code></strong> :&ensp;<code>array-like</code></dt>
<dd>Set of scales used in the Continuous Wavelet Transform (powers of 2 by default).</dd>
<dt><strong><code>transforms</code></strong> :&ensp;<code><a title="signomics.signal_collection" href="#signomics.signal_collection">signal_collection</a></code></dt>
<dd>Stores the CWT-transformed signals, each as a <code><a title="signomics.signal" href="#signomics.signal">signal</a></code> object, indexed by scale.</dd>
<dt><strong><code>codes</code></strong> :&ensp;<code>dict[int, <a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a>]</code></dt>
<dd>Symbolic codes by scale level. Each is a <code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code> object representing
the symbolic sequence at that scale.</dd>
<dt><strong><code>codesfull</code></strong> :&ensp;<code>dict[int, <a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a>]</code></dt>
<dd>Same as <code>codes</code>, but uses full resolution symbolic representation.</dd>
<dt><strong><code>peaks</code></strong> :&ensp;<code><a title="signomics.peaks" href="#signomics.peaks">peaks</a></code></dt>
<dd>Optional <code><a title="signomics.peaks" href="#signomics.peaks">peaks</a></code> object used to index real peak positions from the signal.</dd>
<dt><strong><code>codebook</code></strong> :&ensp;<code>dict</code></dt>
<dd>Mapping between symbolic characters (A, B, C, X, Y, Z, _) and wavelet features.</dd>
<dt><strong><code>generator</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the wavelet basis used (default: 'ricker').</dd>
</dl>
<h2 id="methods">Methods</h2>
<p>compute_cwt(scales=None, normalize=False)
Computes the Continuous Wavelet Transform using the Ricker wavelet
and stores the transformed signals in <code>transforms</code>.
encode_dna()
Encodes each scale's transformed signal into a symbolic <code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code> sequence
using local maximum coding (ABCXYZ).
encode_dna_full()
Encodes signals at each scale using the full encoding scheme, preserving
the flat regions (_) and finer symbolic transitions.
plot_codes(scale)
Plots both the wavelet transform and the symbolic code for the given scale.
decode_dna(scale)
Reconstructs the approximate signal for a given scale from its DNA encoding.
<strong>getitem</strong>(scale)
Shortcut to access the <code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code> object for a specific scale.
summary()
Returns a dictionary summarizing encoded scales and metadata.
has(scale)
Checks whether a DNAstr encoding exists at the given scale.</p>
<h2 id="static-pairwise-distance-methods">Static Pairwise Distance Methods</h2>
<p>_pairwiseEntropyDistance(list of DNAstr objects, scale)
Return a DNApairwiseAnalysis instance based on the mutually exclusive information
after DNA/code alignment.
_pairwiseJaccardMotifDistance(list of DNAstr objects, scale)
Return a DNApairwisedistance based on the presence/absence of a pattern (default=YAZB)
_pairwiseJensenShannonDistance(list of DNAstr objects, scale)
Return a DNApairwisedistance based on the Jensen-Shannon distance of a pattern
_pairwiseLevenshteinDistance(list of DNAstr objects, scale)
Return a DNApairwisedistance based on the Levenshtein Distance</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; S = signal.from_peaks(...)  # define a signal
&gt;&gt;&gt; dna = DNAsignal(S)
&gt;&gt;&gt; dna.compute_cwt()
&gt;&gt;&gt; dna.encode_dna()
&gt;&gt;&gt; dna.codes[4]
DNAstr(&quot;AAAZZZYY...&quot;)
&gt;&gt;&gt; dna.plot_codes(4)
&gt;&gt;&gt; dna.codes[4].find(&quot;YAZB&quot;)
</code></pre>
<p>Initialize DNAsignal with a signal object or 1D array.</p>
<h2 id="parameters_1">Parameters</h2>
<dl>
<dt><strong><code>signal_obj</code></strong> :&ensp;<code><a title="signomics.signal" href="#signomics.signal">signal</a></code> or <code>np.ndarray</code></dt>
<dd>The input signal (preferably a signal object).</dd>
<dt><strong><code>sampling_dt</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling interval (used for filtering).</dd>
<dt><strong><code>dtype</code></strong> :&ensp;<code>data-type</code></dt>
<dd>Data type to cast the signal (default: np.float64).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DNAsignal:
    &#34;&#34;&#34;
    DNAsignal(signal):
    ==================
    A class to encode a numerical signal (typically a 1D GC-MS trace, NMR/FTIR/Raman spectra
    or time series) into a DNA-like symbolic representation using wavelet analysis.
    This symbolic coding enables fast comparison, search, and alignment of signal features
    using abstracted patterns (e.g., &#39;YAZB&#39;).

    The class supports:
    - Continuous Wavelet Transform (CWT) using Ricker wavelets
    - Symbolic conversion of wavelet features to DNA-like letters (A, B, C, X, Y, Z)
    - Visualization of CWTs, symbolic encodings, and signal overlays
    - Reversible decoding of symbolic segments back into approximate signals
    - Substring extraction and matching
    - Storage of multi-scale representations (multi-resolution DNA encoding)

    This class is part of the symbolic signal transformation pipeline (`sig2dna`), compatible with `signal`, `peaks`, and `signal_collection`.

    Parameters
    ----------
    signal : signal
        An instance of the `signal` class representing a sampled waveform. It must
        have `x`, `y`, and a valid name or identifier.
    encode : bool (default = False)
        Launch encoders = [&#34;compute_cwt&#34;,&#34;encode_dna&#34;,&#34;encode_dna_full&#34;] if True
    plot : bool (default = False)
        Plot with plotter = [&#34;plot_signals&#34;,&#34;plot_transforms&#34;,&#34;plot_codes&#34;]

    Attributes
    ----------
    signal : signal
        The raw signal object being encoded.
    dx : float
        The nominal x-resolution of the signal (automatically derived).
    n : int
        Number of points in the signal (length of x/y arrays).
    scales : array-like
        Set of scales used in the Continuous Wavelet Transform (powers of 2 by default).
    transforms : signal_collection
        Stores the CWT-transformed signals, each as a `signal` object, indexed by scale.
    codes : dict[int, DNAstr]
        Symbolic codes by scale level. Each is a `DNAstr` object representing
        the symbolic sequence at that scale.
    codesfull : dict[int, DNAstr]
        Same as `codes`, but uses full resolution symbolic representation.
    peaks : peaks
        Optional `peaks` object used to index real peak positions from the signal.
    codebook : dict
        Mapping between symbolic characters (A, B, C, X, Y, Z, _) and wavelet features.
    generator : str
        Name of the wavelet basis used (default: &#39;ricker&#39;).

    Methods
    -------
    compute_cwt(scales=None, normalize=False)
        Computes the Continuous Wavelet Transform using the Ricker wavelet
        and stores the transformed signals in `transforms`.
    encode_dna()
        Encodes each scale&#39;s transformed signal into a symbolic `DNAstr` sequence
        using local maximum coding (ABCXYZ).
    encode_dna_full()
        Encodes signals at each scale using the full encoding scheme, preserving
        the flat regions (_) and finer symbolic transitions.
    plot_codes(scale)
        Plots both the wavelet transform and the symbolic code for the given scale.
    decode_dna(scale)
        Reconstructs the approximate signal for a given scale from its DNA encoding.
    __getitem__(scale)
        Shortcut to access the `DNAstr` object for a specific scale.
    summary()
        Returns a dictionary summarizing encoded scales and metadata.
    has(scale)
        Checks whether a DNAstr encoding exists at the given scale.

    Static pairwise distance methods
    --------------------------------
    _pairwiseEntropyDistance(list of DNAstr objects, scale)
        Return a DNApairwiseAnalysis instance based on the mutually exclusive information
        after DNA/code alignment.
    _pairwiseJaccardMotifDistance(list of DNAstr objects, scale)
        Return a DNApairwisedistance based on the presence/absence of a pattern (default=YAZB)
    _pairwiseJensenShannonDistance(list of DNAstr objects, scale)
        Return a DNApairwisedistance based on the Jensen-Shannon distance of a pattern
    _pairwiseLevenshteinDistance(list of DNAstr objects, scale)
        Return a DNApairwisedistance based on the Levenshtein Distance

    Examples
    --------
    &gt;&gt;&gt; S = signal.from_peaks(...)  # define a signal
    &gt;&gt;&gt; dna = DNAsignal(S)
    &gt;&gt;&gt; dna.compute_cwt()
    &gt;&gt;&gt; dna.encode_dna()
    &gt;&gt;&gt; dna.codes[4]
    DNAstr(&#34;AAAZZZYY...&#34;)
    &gt;&gt;&gt; dna.plot_codes(4)
    &gt;&gt;&gt; dna.codes[4].find(&#34;YAZB&#34;)
    &#34;&#34;&#34;

    def __init__(self, signal_obj, sampling_dt=1.0, dtype=np.float64,
                 encode=False,
                 encoder=[&#34;compute_cwt&#34;,&#34;encode_dna&#34;,&#34;encode_dna_full&#34;],
                 scales=[1,2,4,8,16,32],
                 x_label=&#34;index&#34;, x_unit = &#34;-&#34;, y_label=&#34;Intensity&#34;, y_unit = &#34;&#34;,
                 plot=False,
                 plotter=[&#34;plot_signals&#34;,&#34;plot_transforms&#34;,&#34;plot_codes&#34;]):
        &#34;&#34;&#34;
        Initialize DNAsignal with a signal object or 1D array.

        Parameters
        ----------
        signal_obj : signal or np.ndarray
            The input signal (preferably a signal object).
        sampling_dt : float
            Sampling interval (used for filtering).
        dtype : data-type
            Data type to cast the signal (default: np.float64).
        &#34;&#34;&#34;
        if isinstance(signal_obj, signal):
            self.signal_obj = signal_obj.copy()
            self.signal = np.asarray(signal_obj.y, dtype=dtype)
            self.x = signal_obj.x
            self.x_label = signal_obj.x_label or x_label
            self.x_unit = signal_obj.x_unit or x_unit
            self.y_label = signal_obj.y_label or y_label
            self.y_unit = signal_obj.y_unit or y_unit
            self.name = signal_obj.name
            self.sampling_dt = signal_obj.x[1] - signal_obj.x[0]
        else:
            self.signal_obj = None
            self.signal = np.asarray(signal_obj, dtype=dtype)
            self.x = np.arange(len(self.signal)) * sampling_dt
            self.x_label = x_label
            self.x_unit =  x_unit
            self.y_label = y_label
            self.y_unit = y_unit
            self.name = &#34;array&#34;
            self.sampling_dt = sampling_dt
        self.dtype = dtype
        self.filtered_signal = None
        self.scales = []
        self.cwt_coeffs = {}  # scale -&gt; array
        self.codes = {}       # scale -&gt; {letters, widths, heights}

        # encode and plots on request
        if plot and &#34;plot_signals&#34; in plotter:
            self.plot_signals()
        if encode:
            self.compute_cwt(scales=scales) # minimum encoder
            if plot and &#34;plot_transforms&#34; in plotter:
                self.plot_transforms()
            if (&#34;encode_dna&#34; in encoder) or (&#34;encode_dna_full&#34; in encoder):
                self.encode_dna(scales=scales)
                if plot and &#34;plot_codes&#34; in plotter:
                    self.plot_codes(scales=scales)
            if (&#34;encode_dna_full&#34; in encoder):
                self.encode_dna_full()


    def has(self, scale):
        &#34;&#34;&#34;
        Check if a DNA encoding exists for the specified scale.

        Parameters
        ----------
        scale : int
            The wavelet scale to check.

        Returns
        -------
        bool
            True if a symbolic DNAstr encoding exists at the given scale, False otherwise.

        Examples
        --------
        &gt;&gt;&gt; dna.has(4)
        True
        &gt;&gt;&gt; dna.has(16)
        False
        &#34;&#34;&#34;
        return scale in self.codes

    @staticmethod
    def apply_baseline_filter(signal, w=None, k=2, delta_t=1.0):
        &#34;&#34;&#34;
        Apply baseline filtering using moving median and local Poisson-based thresholding.

        Parameters
        ----------
        signal : np.ndarray
            Input signal (expected to be non-negative or baseline-dominated).
        w : int or None
            Window size for baseline and statistics (must be odd).
            Defaults to max(11, 2% of signal length).
        k : float
            Bienaymé-Tchebychev multiplier.
        delta_t : float
            Sampling time step.

        Returns
        -------
        filtered : np.ndarray
            Signal with baseline removed and low-intensity noise suppressed.

        Note
        ----
        This method is static, use signal.apply_baseline_filter() whenever appropriate instead.

        &#34;&#34;&#34;
        signal = np.asarray(signal)
        m = len(signal)

        # Determine appropriate window width
        if w is None:
            w = max(11, int(0.01 * m))
        if w % 2 == 0:
            w += 1
        if w &gt;= m:
            raise ValueError(f&#34;Window width w={w} must be smaller than signal length {m}.&#34;)

        # Step 1: remove baseline via moving median
        baseline = medfilt(signal, kernel_size=w)
        s = signal - baseline
        s[s &lt; 0] = 0  # force non-negativity

        # Step 2: moving mean and std (uniform filter = moving average)
        # signal.apply_baseline_filter() uses np.sliding_window_view() instead.
        mean = uniform_filter1d(s, size=w, mode=&#39;nearest&#39;)
        sq = uniform_filter1d(s**2, size=w, mode=&#39;nearest&#39;)
        std = np.sqrt(np.maximum(sq - mean**2, 0))

        # Step 3: Poisson λ from cv = std / mean
        with np.errstate(divide=&#39;ignore&#39;, invalid=&#39;ignore&#39;):
            cv = np.where(mean &gt; 0, std / mean, 0)
            lam = np.where(cv &gt; 0, 1 / (cv**2), 0)

        # Step 4: BT thresholding
        threshold = k * np.sqrt(10 * lam * delta_t)
        s[s &lt; threshold] = 0
        return s

    def compute_cwt(self, scales=None, apply_filter=False):
        &#34;&#34;&#34;
        Compute Continuous Wavelet Transform (CWT) using the Mexican Hat wavelet.

        Parameters
        ----------
        scales : list, int, or None
            List of scales (or a single scale) to compute. If None, default to [1, 2, 4, 8, 16].
        apply_filter : bool
            Whether to apply a baseline filter to the input signal before transforming.

        Sets
        ----
        self.scales : list
            The list of actual scales used.
        self.filtered_signal : ndarray
            Filtered or raw signal used for CWT.
        self.cwt_coeffs : dict
            Dictionary mapping each scale to its 1D coefficient array.
        self.transforms : signal_collection
            Collection of `signal` objects storing the transformed signals for each scale.
        &#34;&#34;&#34;
        if scales is None:
            scales = [2 ** i for i in range(5)]
        if not isinstance(scales,(list,tuple)):
            scales = [scales]
        self.scales = scales
        if apply_filter:
            self.filtered_signal = self.apply_baseline_filter(self.signal,delta_t=self.sampling_dt)
        else:
            self.filtered_signal = self.signal
        self.transforms = signal_collection()
        for scale in self.scales:
            coef, _ = pywt.cwt(self.filtered_signal, [scale], &#39;mexh&#39;)
            self.cwt_coeffs[scale] = coef[0]  # Access directly via scale
            sig = signal(
                x=self.x.copy(),
                y=coef[0],
                name=f&#34;CWT_scale_{scale}&#34;,
                x_label=&#34;x&#34;,
                y_label=&#34;CWT amplitude&#34;,
                y_unit=&#34;a.u.&#34;,
                source=&#34;CWT&#34;)
            self.transforms.append(sig)

    def encode_dna(self, scales=None):
        &#34;&#34;&#34;
        Encode each transformed signal into a symbolic DNA-like sequence of monotonic segments.

        Parameters
        ----------
        scales : list, int, or None
            List of scales (or a single scale) to encode. If None, use self.scales.

        The encoding detects strictly monotonic (or flat) segments and labels them with symbolic letters:
        - A: crosses 0 upward (neg → pos)
        - Z: crosses 0 downward (pos → neg)
        - B: strictly increasing negative segment
        - Y: strictly decreasing negative segment
        - C: strictly increasing positive segment
        - X: strictly decreasing positive segment
        - _: flat or ambiguous segment

        Sets
        ----
        self.codes : dict
            Dictionary mapping each scale to a struct with:
                - letters : str (symbolic encoding)
                - widths  : list of float (x-span of each segment)
                - heights : list of float (y-delta of each segment)
                - iloc    : list of index-pair tuples (start, end+1)
                - xloc    : list of x-span tuples (x_start, x_end)
                - dx      : segment step (dx)
        &#34;&#34;&#34;
        if scales is None:
            scales = self.scales
        if not isinstance(scales,(list,tuple)):
            scales = [scales]
        if not hasattr(self, &#39;cwt_coeffs&#39;) or not self.cwt_coeffs:
            self.compute_cwt(scales)
        dx = self.x[1]-self.x[0]
        for scale in scales:
            coef = self.cwt_coeffs[scale]
            letters, widths, heights, iloc, xloc = [], [], [], [], []
            monotonic = np.diff(coef)
            mono_sign = np.sign(monotonic)
            sign_changes = np.where(np.diff(mono_sign) != 0)[0] + 1  # +1 because diff shortens by 1
            start_idx = 0
            segment_ends = np.append(sign_changes, len(coef) - 1)
            for count, idx in enumerate(segment_ends):
                xsegment = self.x[start_idx:idx + 1]
                segment = coef[start_idx:idx + 1]
                if len(segment) &lt; 2:
                    letters.append(&#39;_&#39;)
                else:
                    start, end = segment[0], segment[-1]
                    letter = self._get_letter(start, end)
                    letters.append(letter)
                widths.append(xsegment[-1] - xsegment[0])
                heights.append(segment[-1] - segment[0])
                xloc.append((xsegment[0],xsegment[-1]))
                is_last = count == len(segment_ends) - 1
                iloc.append((start_idx, idx + 1 if is_last else idx))
                start_idx = idx #idx + 1 (segments are continguous)
            # update codes
            self.codes[scale] = {&#39;letters&#39;: &#39;&#39;.join(letters),
                                 &#39;widths&#39;: widths,
                                 &#39;heights&#39;: heights,
                                 &#39;xloc&#39;:xloc,
                                 &#39;iloc&#39;:iloc,
                                 &#39;dx&#39;:dx}

    def encode_dna_full(self, scales=None, resolution=&#39;index&#39;, repeat=True, n_points=None):
        &#34;&#34;&#34;
        Convert symbolic codes into DNA-like strings by repeating letters proportionally to their span.

        Parameters
        ----------
        scales : list, int, or None
            List of scales (or a single scale) to convert. If None, use self.scales.
        resolution : {&#39;index&#39;, &#39;x&#39;}
            Repetition mode:
                - &#39;index&#39;: repeat letters by number of indices (j - i from iloc)
                - &#39;x&#39;    : interpolate letter values over physical x-axis distance (xloc)
        repeat : bool
            If True, repeat or interpolate letters to form a string of desired resolution.
            If False, return the symbolic sequence without repetition.
        n_points : int or None
            Used only for resolution=&#39;x&#39; to control the number of interpolation points.
            If None, defaults to ~10 points per x-unit.

        Returns
        -------
        dict
            Dictionary mapping each scale to its DNA-like string.

        Sets
        ----
        self.codesfull : dict
            Dictionary storing the resulting full DNA-like string per scale.
        &#34;&#34;&#34;
        if scales is None:
            scales = self.scales
        elif isinstance(scales, (int, float)):
            scales = [scales]
        elif not isinstance(scales, (list, tuple)):
            raise TypeError(&#34;scales must be a list, int, or None&#34;)

        if not hasattr(self, &#39;codes&#39;) or not self.codes:
            self.encode_dna(scales)

        result = {}
        for scale in scales:
            if scale not in self.codes:
                self.encode_dna([scale])
            code = self.codes[scale]
            if not repeat:
                result[scale] = code[&#39;letters&#39;]
                continue
            if resolution == &#39;index&#39;:
                sequence = &#39;&#39;.join(
                    letter * max(1, (j - i)) for letter, (i, j) in zip(code[&#39;letters&#39;], code[&#39;iloc&#39;])
                )
            elif resolution == &#39;x&#39;:
                if n_points is None:
                    total_span = sum(x2 - x1 for x1, x2 in code[&#39;xloc&#39;])
                    n_points = int(np.ceil(total_span * 10))  # adjustable density
                x_start = code[&#39;xloc&#39;][0][0]
                x_end = code[&#39;xloc&#39;][-1][1]
                grid = np.linspace(x_start, x_end, n_points, endpoint=True)
                centers = [(x1 + x2) / 2 for x1, x2 in code[&#39;xloc&#39;]]
                # Encode letters as integers
                unique_letters = list(OrderedDict.fromkeys(code[&#39;letters&#39;]))
                letter_to_int = {ch: i for i, ch in enumerate(unique_letters)}
                int_to_letter = {i: ch for ch, i in letter_to_int.items()}

                int_vals = [letter_to_int[ch] for ch in code[&#39;letters&#39;]]
                interp_func = interp1d(centers, int_vals, kind=&#39;nearest&#39;,
                                       bounds_error=False, fill_value=int_vals[-1])
                interpolated = np.round(interp_func(grid)).astype(int)
                sequence = &#39;&#39;.join(int_to_letter[i] for i in interpolated)
            else:
                raise ValueError(&#34;resolution must be either &#39;index&#39; or &#39;x&#39;&#34;)
            result[scale] = DNAstr(sequence,
                                   dx=code[&#34;dx&#34;],
                                   iloc=(code[&#34;iloc&#34;][0][0],code[&#34;iloc&#34;][-1][-1]),
                                   xloc=(code[&#34;xloc&#34;][0][0],code[&#34;xloc&#34;][-1][-1]),
                                   x_label=self.x_label, x_unit=self.x_unit)
        self.codesfull = result

    @staticmethod
    def _get_letter(start, end, tol=1e-12):
        &#34;&#34;&#34;
        Determine letter based on monotonicity and signal range.

        Returns one of:
            - &#39;A&#39;: Negative to Positive (crosses zero upward)
            - &#39;Z&#39;: Positive to Negative (crosses zero downward)
            - &#39;B&#39;: Increasing Negative (concave up)
            - &#39;Y&#39;: Decreasing Negative (concave down)
            - &#39;C&#39;: Increasing Positive (concave up)
            - &#39;X&#39;: Decreasing Positive (concave down)
            - &#39;_&#39;: Flat or undefined
        &#34;&#34;&#34;
        # Optional tolerance for numerical 0
        s = start if abs(start) &gt; tol else 0.0
        e = end   if abs(end)   &gt; tol else 0.0
        if s == e:
            return &#39;_&#39;
        # Zero-crossings
        if s &lt; 0 and e &gt; 0:
            return &#39;A&#39;
        if s &gt; 0 and e &lt; 0:
            return &#39;Z&#39;
        # Entirely negative (possibly with 0 at one end)
        if s &lt;= 0 and e &lt;= 0:
            return &#39;B&#39; if e &gt; s else &#39;Y&#39;
        # Entirely positive (possibly with 0 at one end)
        if s &gt;= 0 and e &gt;= 0:
            return &#39;C&#39; if e &gt; s else &#39;X&#39;
        return &#39;_&#39;

    @staticmethod
    def _get_triangle_from_letter(letter,x0,y0,w,h):
        &#34;&#34;&#34;returns the triangle (counter-clockwise, x are incr) &#34;&#34;&#34;
        if letter == &#34;A&#34;:
            x = (x0,x0+w,x0+w)
            y = (y0,y0,y0+h)
        elif letter == &#34;B&#34;:
            x = (x0,x0+w,x0)
            y = (y0,y0+h,y0+h)
        elif letter == &#34;C&#34;:
            x = (x0,x0+w,x0+w)
            y = (y0,y0,y0+h)
        elif letter ==&#34;X&#34;:
            x = (x0,x0,x0+w)
            y = (y0,y0+h,y0+h)
        elif letter == &#34;Y&#34;:
            x = (x0,x0+w,x0+w)
            y = (y0,y0,y0+h)
        elif letter == &#34;Z&#34;:
            x = (x0,x0,x0+w)
            y = (y0,y0+h,y0+h)
        elif letter == &#34;_&#34;:
            x = (x0,x0+w,x0+w)
            y = (y0,y0,y0)
        else:
            raise ValueError(f&#34;the letter {letter} is unknown/undocumented&#34;)
        return x,y


    @property
    def _is_letter_crossing(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment crossing y=0&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_crossing_from_positive(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment crossing y=0 from y&gt;0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_crossing_from_negative(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment crossing y=0 from y&lt;0&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_increasing(self):
        &#34;&#34;&#34;Return True if the letter codes for an increasing segment&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:True,&#34;C&#34;:True,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_decreasing(self):
        &#34;&#34;&#34;Return True if the letter codes for an decreasing segment&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:True,&#34;Y&#34;:True,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_constant(self):
        &#34;&#34;&#34;Return True if the letter codes for a constant segment, y=0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:True}
    @property
    def _is_letter_starting_positive(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment starting with y&gt;0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:True,&#34;X&#34;:True,&#34;Y&#34;:False,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_starting_negative(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment crossing y=0&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:True,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:True,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_ending_positive(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment ending with y&gt;0&#34;&#34;&#34;
        return {&#34;A&#34;:True,&#34;B&#34;:False,&#34;C&#34;:True,&#34;X&#34;:True,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_ending_negative(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment ending with y&lt;0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:True,&#34;C&#34;:False,&#34;X&#34;:False,&#34;Y&#34;:True,&#34;Z&#34;:True,&#34;_&#34;:False}
    @property
    def _is_letter_starting_from_zero(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment staring from 0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:False,&#34;C&#34;:True,&#34;X&#34;:False,&#34;Y&#34;:True,&#34;Z&#34;:False,&#34;_&#34;:False}
    @property
    def _is_letter_ending_at_zero(self):
        &#34;&#34;&#34;Return True if the letter codes for a segment ending at 0&#34;&#34;&#34;
        return {&#34;A&#34;:False,&#34;B&#34;:True,&#34;C&#34;:False,&#34;X&#34;:True,&#34;Y&#34;:False,&#34;Z&#34;:False,&#34;_&#34;:False}


    def get_entropy(self, scale):
        &#34;&#34;&#34;Calculate Shannon entropy for encoded signal.&#34;&#34;&#34;
        letters = self.codes[scale][&#39;letters&#39;]
        _, counts = np.unique(list(letters), return_counts=True)
        return entropy(counts, base=2)

    def get_code(self, scale):
        &#34;&#34;&#34;Retrieve encoded data for a specific scale.&#34;&#34;&#34;
        return self.codes[scale]

    def find_sequence(self, pattern, scale):
        &#34;&#34;&#34;Find occurrences of a specific letter pattern in encoded sequence.&#34;&#34;&#34;
        sequence = self.codes[scale][&#39;letters&#39;]
        positions = []
        idx = sequence.find(pattern)
        while idx != -1:
            positions.append(idx)
            idx = sequence.find(pattern, idx + 1)
        return positions

    def reconstruct_signal(self, scale, return_signal=True):
        &#34;&#34;&#34;
        Reconstruct the signal from symbolic features (e.g., YAZB).

        Parameters
        ----------
        scale : int
            Scale to use for reconstruction.
        return_signal : bool
            If True, return a `signal` object. Else return y array.

        Returns
        -------
        signal or np.ndarray
            Reconstructed signal.
        &#34;&#34;&#34;
        coef = self.cwt_coeffs[scale]
        peaks = self.find_sequence(&#39;YAZB&#39;, scale)
        y = np.zeros_like(self.signal)

        for peak in peaks:
            pos = peak * scale
            width = scale
            height = coef[peak]
            y += height * np.exp(-((np.arange(len(y)) - pos) / (0.6006 * width)) ** 2)

        if return_signal:
            from signal import signal as Signal
            return Signal(x=self.x.copy(), y=y, name=f&#34;reconstructed_{self.name}&#34;,
                          x_label=&#34;x&#34;, y_label=&#34;reconstructed&#34;, y_unit=&#34;a.u.&#34;)
        return y

    def align_with(self, other, scale=1):
        &#34;&#34;&#34;
        Align symbolic sequences and compute mutual entropy.

        Returns:
            SimpleNamespace: with fields
                - seq1_aligned (str)
                - seq2_aligned (str)
                - aligned_signal (list of tuples)
                - mutual_entropy (float)
        &#34;&#34;&#34;
        seq1 = self.codes[scale][&#39;letters&#39;]
        seq2 = other.codes[scale][&#39;letters&#39;]
        aligner = PairwiseAligner()
        aligner.mode = &#39;global&#39;
        alignment = aligner.align(seq1, seq2)[0]
        a1 = self.reconstruct_aligned_string(seq1, alignment.aligned[0])
        a2 = self.reconstruct_aligned_string(seq2, alignment.aligned[1])
        pairs = list(zip(a1, a2))
        shared = &#39;&#39;.join(a if a == b else &#39;_&#39; for a, b in pairs)
        H = self.entropy_from_string
        return SimpleNamespace(
            seq1_aligned=a1,
            seq2_aligned=a2,
            aligned_signal=pairs,
            mutual_entropy=H(a1) + H(a2) - 2 * H(shared)
        )

    @staticmethod
    def reconstruct_aligned_string(seq, aligned):
        &#34;&#34;&#34;Fast reconstruction of aligned signals&#34;&#34;&#34;
        result, last = [], 0
        for start, end in aligned:
            result.extend([&#39;-&#39;] * (start - last))
            result.extend(seq[start:end])
            last = end
        return &#39;&#39;.join(result)

    @staticmethod
    def entropy_from_string(s):
        &#34;&#34;&#34;return the entropy of a string&#34;&#34;&#34;
        _, counts = np.unique(list(s), return_counts=True)
        return entropy(counts, base=2)

    @staticmethod
    def print_alignment(seq1, seq2, width=80):
        &#34;&#34;&#34;print aligned sequences&#34;&#34;&#34;
        for i in range(0, len(seq1), width):
            s1 = seq1[i:i+width]
            s2 = seq2[i:i+width]
            match = &#39;&#39;.join(&#39;|&#39; if a == b else &#39; &#39; for a, b in zip(s1, s2))
            print(s1)
            print(match)
            print(s2)
            print()

    def __repr__(self):
        total = sum(len(c[&#39;letters&#39;]) for c in self.codes.values()) or 1
        ratio = len(self.signal) / total
        print(f&#34;&lt;DNAsignal(length={len(self.signal)}, scales={self.scales}, &#34;
                f&#34;transforms={len(self.cwt_coeffs)}, compression_ratio={ratio:.2f}, dtype={self.dtype.__name__})&gt;&#34;,sep=&#34;\n&#34;)
        return str(self)

    def __str__(self):
        return f&#34;&lt;DNAsignal(signal_length={len(self.signal)}, filtered={&#39;Yes&#39; if self.filtered_signal is not None else &#39;No&#39;})&gt;&#34;

    @staticmethod
    def synthetic_signal(x, peaks, baseline=None):
        &#34;&#34;&#34;Generate flexible synthetic signals. (obsolete)&#34;&#34;&#34;
        y = np.zeros_like(x)
        for pos, width, height in peaks:
            y += height * np.exp(-((x - pos) / (0.6006 * width)) ** 2)
        if baseline:
            y += baseline(x)
        return y

    def plot_signals(self, scales=None):
        &#34;&#34;&#34;Plot signals.&#34;&#34;&#34;
        if scales is None:
            scales = self.scales
        plt.figure(figsize=(10, 6))
        plt.plot(self.signal, label=&#39;Original Signal&#39;, linewidth=4, color=&#34;k&#34;)
        for scale in scales:
            plt.plot(self.cwt_coeffs[scale], label=f&#39;Scale {scale}&#39;, linewidth=2, alpha=0.7)
        plt.legend()
        plt.title(&#34;Signal and Transformed Scales&#34;)
        plt.x_label(f&#34;{self.x_label} [{self.x_unit}]&#34;)
        plt.y_label(f&#34;{self.y_label} [{self.y_unit}]&#34;)
        plt.show()

    def plot_transforms(self, indices=None, **kwargs):
        &#34;&#34;&#34;
        Plot the stored CWT-transformed signals as a signal collection.

        Parameters
        ----------
        indices : list[int or str], optional
            Specific scales or names to plot.
        kwargs : passed to `signal_collection.plot`
        &#34;&#34;&#34;
        if not hasattr(self, &#34;transforms&#34;):
            raise AttributeError(&#34;No transformed signals found. Run `compute_cwt()` first.&#34;)
        self.transforms.plot(indices=indices, title=f&#34;CWT Transforms: {self.name}&#34;, **kwargs)

    def plot_codes(self, scale, ax=None, colormap=None, alpha=0.4):
        &#34;&#34;&#34;
        Plot the symbolic DNA-like encoding as colored triangle segments.

        Parameters
        ----------
        scale : int
            The scale at which the signal was encoded.
        ax : matplotlib.axes.Axes, optional
            Axis to draw on. If None, a new figure is created.
        colormap : dict, optional
            Custom mapping of letters to colors. Default uses 7 distinct colors.
        alpha : float
            Transparency for the patches. Default is 0.4.
        &#34;&#34;&#34;

        if ax is None:
            fig, ax = plt.subplots(figsize=(12, 5))
        else:
            fig = plt.gcf()
            ax = plt.gca()

        # Default color mapping
        default_colormap = {
            &#39;A&#39;: &#39;DeepPink&#39;,&#39;B&#39;: &#39;OrangeRed&#39;, &#39;C&#39;: &#39;Gold&#39;,
            &#39;X&#39;: &#39;DeepSkyBlue&#39;,&#39;Y&#39;: &#39;DodgerBlue&#39;, &#39;Z&#39;: &#39;Purple&#39;,
            &#39;_&#39;: &#39;gray&#39;
        }
        cmap = colormap or default_colormap

        # Flags
        cross_flags = self._is_letter_crossing

        # Retrieve segment data
        code_data = self.codes[scale]
        letters = code_data[&#39;letters&#39;]
        widths = code_data[&#39;widths&#39;]
        heights = code_data[&#39;heights&#39;]
        xloc = code_data[&#39;xloc&#39;]
        coef = self.cwt_coeffs[scale]
        x = self.x if hasattr(self, &#39;x&#39;) and self.x is not None else np.arange(len(coef))

        # Generate path data
        last_y = 0.0
        patchxy = []

        # Process segments with continuity enforcement
        nletters = len(letters)
        for i in range(nletters):
            letter = letters[i]
            repeatedletter_withprevious = letter if i&gt;0 else False
            repeatedletter_withnext = letter if i&lt;(nletters-1) else False
            repeated = repeatedletter_withprevious or repeatedletter_withnext
            y0 = last_y if cross_flags[letter] or repeated else 0.0
            x0, w, h = xloc[i][0], widths[i], heights[i]
            last_y = y0 + h
            x,y = self._get_triangle_from_letter(letter,x0,y0,w,h)
            triangle = [[x[0], y[0]], [x[1], y[1]], [x[2], y[2]], [x[0], y[0]]]
            patchxy.append(triangle)

        # Plot patches
        for letter,verts in zip(letters,patchxy):
            poly = Polygon(verts, closed=True, color=cmap.get(letter, &#39;black&#39;), alpha=alpha)
            ax.add_patch(poly)

        # Plot raw and transformed signals
        ax.plot(self.x, self.signal, color=&#39;black&#39;, linewidth=3, label=&#39;Original Signal&#39;)
        ax.plot(self.x, coef, color=&#39;blue&#39;, linewidth=2, label=f&#39;CWT Scale {scale}&#39;)
        ax.set_xlabel(f&#34;{self.x_label} [{self.x_unit}]&#34;)
        ax.set_ylabel(f&#34;{self.y_label} [{self.y_unit}]&#34;)
        ax.set_title(f&#34;Symbolic Segments (Scale {scale})&#34;)
        ax.legend()
        ax.set_xlim([self.x[0], self.x[-1]])
        ax.axhline(0, color=&#39;k&#39;, linewidth=0.5, linestyle=&#39;:&#39;)
        plt.tight_layout()
        plt.show()
        return fig

    @staticmethod
    def _pairwiseEntropyDistance(list_DNAsignals, scale=None,
                  engine=None, engineOpts=None,):
        &#34;&#34;&#34;
        Calculate excess-entropy pairwise distances.

        Parameters
        ----------
        list_DNAsignals : list of valid DNAsignals (mandatory)
        scale           : int (mandatory)
        engine          : {&#39;difflib&#39;, &#39;bio&#39;} or None (default)
        engineOpts      : dict, optional (alignment parameters for the selected engine)

        Returns
        -------
        D      : nxn np.array of excess entropy distances (H(A) + H(B) - 2 * H(A*B))
        names  : list of signal names
        &#34;&#34;&#34;

        if not isinstance(list_DNAsignals, list):
            raise TypeError(f&#34;list_DNAsignals must be list not a {type(list_DNAsignals).__name__}&#34;)
        for o in list_DNAsignals:
            if not isinstance(o, DNAsignal):
                raise TypeError(f&#34;all listed elements must be a DNAsignal not a {type(o).__name__}&#34;)
        if scale is None or not isinstance(scale, int):
            raise TypeError(f&#34;scale must be an int not a {type(scale).__name__}&#34;)
        if scale &lt;= 0:
            raise ValueError(&#34;scale must be positive&#34;)

        n = len(list_DNAsignals)
        D = np.zeros((n, n), dtype=np.float64)

        total_pairs = n * (n - 1) // 2
        pair_index = 0
        start_time = time()

        with tqdm(total=total_pairs, desc=&#34;Pairwise distances&#34;, unit=&#34;pair&#34;) as pbar:
            for i in range(n):
                A = list_DNAsignals[i].codesfull[scale]
                for j in range(i):
                    B = list_DNAsignals[j].codesfull[scale]
                    A.align(B, engine=engine, engineOpts=engineOpts)
                    D[i, j] = A.excess_entropy(B)
                    pair_index += 1
                    pbar.update(1)
                    # Optional: show elapsed/ETA in tqdm (already included by default)

        D += D.T
        names = [o.name for o in list_DNAsignals]
        elapsed = time() - start_time
        print(f&#34;Pairwise distances computation completed in {elapsed:.2f} seconds.&#34;)
        return DNApairwiseAnalysis(D,names,list_DNAsignals)

    @staticmethod
    def _pairwiseJaccardMotifDistance(list_DNAsignals, scale=None,
                                       pattern=&#39;YAZB&#39;, minlen=4,
                                       classification=&#39;any&#39;,  # &#39;canonical&#39;, &#39;variant&#39;, or &#39;any&#39;
                                       plot=True):
        &#34;&#34;&#34;
        Compute pairwise Jaccard distances based on motif presence across symbolic DNAstr sequences.

        Parameters
        ----------
        list_DNAsignals : list of DNAsignal
            List of signals with .codesfull at given scale.
        scale : int
            Scale index for accessing .codesfull[scale].
        pattern : str
            Motif pattern to look for (default &#39;YAZB&#39;).
        minlen : int
            Minimum length of valid motifs.
        classification : {&#39;canonical&#39;, &#39;variant&#39;, &#39;any&#39;}
            Filter for motif type.
        plot : bool
            Whether to plot motif positions for each sequence.

        Returns
        -------
        D : np.ndarray
            Symmetric pairwise Jaccard distance matrix.
        names : list of str
            List of DNAsignal names.
        &#34;&#34;&#34;
        if not isinstance(list_DNAsignals, list):
            raise TypeError(&#34;list_DNAsignals must be a list.&#34;)
        if scale is None or not isinstance(scale, int) or scale &lt;= 0:
            raise ValueError(&#34;scale must be a positive integer.&#34;)

        n = len(list_DNAsignals)
        motif_sets = []

        for i, obj in enumerate(list_DNAsignals):
            if not isinstance(obj, DNAsignal):
                raise TypeError(f&#34;Element {i} is not a DNAsignal.&#34;)
            dna = obj.codesfull[scale]
            df = dna.extract_motifs(pattern=pattern, minlen=minlen, plot=False)
            if classification == &#39;canonical&#39;:
                df = df[df[&#39;classification&#39;] == &#39;canonical&#39;]
            elif classification == &#39;variant&#39;:
                df = df[df[&#39;classification&#39;] == &#39;variant&#39;]
            # Represent a sequence as set of motif *start* positions
            motif_set = set(df[&#39;start&#39;]) if not df.empty else set()
            motif_sets.append(motif_set)

        if plot:
            # Assume all DNAstr have same length, dx, and iloc
            L = len(list_DNAsignals[0].codesfull[scale])
            dx = list_DNAsignals[0].codesfull[scale].dx
            iloc = list_DNAsignals[0].codesfull[scale].iloc
            x_start = iloc * dx if isinstance(iloc, int) else iloc[0] * dx
            x_vals = np.arange(L) * dx + x_start
            prevalence = np.zeros(L, dtype=int)

            for obj in list_DNAsignals:
                dna = obj.codesfull[scale]
                df = dna.extract_motifs(pattern=pattern, minlen=minlen, plot=False)
                if classification == &#39;canonical&#39;:
                    df = df[df[&#39;classification&#39;] == &#39;canonical&#39;]
                elif classification == &#39;variant&#39;:
                    df = df[df[&#39;classification&#39;] == &#39;variant&#39;]
                for _, row in df.iterrows():
                    start = row[&#39;start&#39;]
                    width = row[&#39;end&#39;] - row[&#39;start&#39;]  # assuming inclusive-exclusive
                    prevalence[start:start + width] += 1

            plt.figure(figsize=(12, 4))
            plt.plot(x_vals, prevalence/n, marker=&#39;o&#39;, linestyle=&#39;-&#39;, alpha=0.8)
            plt.title(f&#34;Motif prevalence at each position for pattern &#39;{pattern}&#39;&#34;)
            plt.xlabel(&#34;x position&#34;)
            plt.ylabel(&#34;Number of sequences with motif coverage&#34;)
            plt.grid(True)
            plt.tight_layout()
            plt.show()

        D = np.zeros((n, n), dtype=np.float64)
        total_pairs = n * (n - 1) // 2
        pair_index = 0
        start_time = time()

        with tqdm(total=total_pairs, desc=&#34;Pairwise Jaccard (motif)&#34;, unit=&#34;pair&#34;) as pbar:
            for i in range(n):
                A = motif_sets[i]
                for j in range(i):
                    B = motif_sets[j]
                    intersection = len(A &amp; B)
                    union = len(A | B)
                    distance = 1.0 if union == 0 else 1 - intersection / union
                    D[i, j] = distance
                    pbar.update(1)

        D += D.T
        names = [o.name for o in list_DNAsignals]
        elapsed = time() - start_time
        print(f&#34;Jaccard motif-based distance computation completed in {elapsed:.2f} seconds.&#34;)
        return DNApairwiseAnalysis(D, names, list_DNAsignals)

    @staticmethod
    def _pairwiseJensenShannonDistance(list_DNAsignals, scale=None):
        &#34;&#34;&#34;
        Calculate pairwise Jensen-Shannon distances between DNAstr codes at a given scale.

        Parameters
        ----------
        list_DNAsignals : list of DNAsignal
            List of valid DNAsignal instances.
        scale : int
            Scale index to select the code from `codesfull`.

        Returns
        -------
        DNApairwiseAnalysis
            Matrix object containing pairwise Jensen-Shannon distances.
        &#34;&#34;&#34;
        if not isinstance(list_DNAsignals, list):
            raise TypeError(&#34;list_DNAsignals must be a list&#34;)
        for o in list_DNAsignals:
            if not isinstance(o, DNAsignal):
                raise TypeError(f&#34;All elements must be DNAsignal, not {type(o).__name__}&#34;)
        if scale is None or not isinstance(scale, int):
            raise TypeError(&#34;scale must be an integer&#34;)
        if scale &lt; 0:
            raise ValueError(&#34;scale must be non-negative&#34;)

        n = len(list_DNAsignals)
        D = np.zeros((n, n), dtype=np.float64)
        total_pairs = n * (n - 1) // 2
        start_time = time()

        with tqdm(total=total_pairs, desc=&#34;Jensen-Shannon&#34;, unit=&#34;pair&#34;) as pbar:
            for i in range(n):
                A = list_DNAsignals[i].codesfull[scale]
                for j in range(i):
                    B = list_DNAsignals[j].codesfull[scale]
                    D[i, j] = A.jensen_shannon(B)
                    pbar.update(1)

        D += D.T
        names = [o.name for o in list_DNAsignals]
        elapsed = time() - start_time
        print(f&#34;Jensen-Shannon distance matrix completed in {elapsed:.2f} seconds.&#34;)
        return DNApairwiseAnalysis(D, names, list_DNAsignals)

    @staticmethod
    def _pairwiseLevenshteinDistance(list_DNAsignals, scale=None,
                                      use_alignment=False,
                                      engine=None,
                                      engineOpts=None,
                                      forced=False):
        &#34;&#34;&#34;
        Compute pairwise Levenshtein distances between codes at a given scale.

        Parameters
        ----------
        list_DNAsignals : list of DNAsignal
            List of DNAsignal objects to compare.
        scale : int
            Scale index in codesfull.
        use_alignment : bool, optional
            If True, align codes before computing distance. Default is Full.
        engine : str, optional
            Alignment engine (&#39;difflib&#39; or &#39;bio&#39;) if use_alignment is True.
        engineOpts : dict, optional
            Parameters for the alignment engine.
        forced : bool, optional
            If True, allow forced alignment even if dx mismatches.

        Returns
        -------
        DNApairwiseAnalysis
            Object holding the nxn Levenshtein distance matrix.
        &#34;&#34;&#34;
        if not isinstance(list_DNAsignals, list):
            raise TypeError(&#34;list_DNAsignals must be a list&#34;)
        for o in list_DNAsignals:
            if not isinstance(o, DNAsignal):
                raise TypeError(f&#34;All elements must be DNAsignal, not {type(o).__name__}&#34;)
        if scale is None or not isinstance(scale, int):
            raise TypeError(&#34;scale must be an integer&#34;)
        if scale &lt; 0:
            raise ValueError(&#34;scale must be non-negative&#34;)

        n = len(list_DNAsignals)
        D = np.zeros((n, n), dtype=np.float64)
        total_pairs = n * (n - 1) // 2
        start_time = time()

        with tqdm(total=total_pairs, desc=&#34;Levenshtein&#34;, unit=&#34;pair&#34;) as pbar:
            for i in range(n):
                A = list_DNAsignals[i].codesfull[scale]
                for j in range(i):
                    B = list_DNAsignals[j].codesfull[scale]
                    D[i, j] = A.levenshtein(B,
                                            use_alignment=use_alignment,
                                            engine=engine,
                                            engineOpts=engineOpts,
                                            forced=forced)
                    pbar.update(1)

        D += D.T
        names = [o.name for o in list_DNAsignals]
        elapsed = time() - start_time
        print(f&#34;Levenshtein distance matrix completed in {elapsed:.2f} seconds.&#34;)
        return DNApairwiseAnalysis(D, names, list_DNAsignals)</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="signomics.DNAsignal.apply_baseline_filter"><code class="name flex">
<span>def <span class="ident">apply_baseline_filter</span></span>(<span>signal, w=None, k=2, delta_t=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply baseline filtering using moving median and local Poisson-based thresholding.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>signal</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Input signal (expected to be non-negative or baseline-dominated).</dd>
<dt><strong><code>w</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>Window size for baseline and statistics (must be odd).
Defaults to max(11, 2% of signal length).</dd>
<dt><strong><code>k</code></strong> :&ensp;<code>float</code></dt>
<dd>Bienaymé-Tchebychev multiplier.</dd>
<dt><strong><code>delta_t</code></strong> :&ensp;<code>float</code></dt>
<dd>Sampling time step.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>filtered</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Signal with baseline removed and low-intensity noise suppressed.</dd>
</dl>
<h2 id="note">Note</h2>
<p>This method is static, use signal.apply_baseline_filter() whenever appropriate instead.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def apply_baseline_filter(signal, w=None, k=2, delta_t=1.0):
    &#34;&#34;&#34;
    Apply baseline filtering using moving median and local Poisson-based thresholding.

    Parameters
    ----------
    signal : np.ndarray
        Input signal (expected to be non-negative or baseline-dominated).
    w : int or None
        Window size for baseline and statistics (must be odd).
        Defaults to max(11, 2% of signal length).
    k : float
        Bienaymé-Tchebychev multiplier.
    delta_t : float
        Sampling time step.

    Returns
    -------
    filtered : np.ndarray
        Signal with baseline removed and low-intensity noise suppressed.

    Note
    ----
    This method is static, use signal.apply_baseline_filter() whenever appropriate instead.

    &#34;&#34;&#34;
    signal = np.asarray(signal)
    m = len(signal)

    # Determine appropriate window width
    if w is None:
        w = max(11, int(0.01 * m))
    if w % 2 == 0:
        w += 1
    if w &gt;= m:
        raise ValueError(f&#34;Window width w={w} must be smaller than signal length {m}.&#34;)

    # Step 1: remove baseline via moving median
    baseline = medfilt(signal, kernel_size=w)
    s = signal - baseline
    s[s &lt; 0] = 0  # force non-negativity

    # Step 2: moving mean and std (uniform filter = moving average)
    # signal.apply_baseline_filter() uses np.sliding_window_view() instead.
    mean = uniform_filter1d(s, size=w, mode=&#39;nearest&#39;)
    sq = uniform_filter1d(s**2, size=w, mode=&#39;nearest&#39;)
    std = np.sqrt(np.maximum(sq - mean**2, 0))

    # Step 3: Poisson λ from cv = std / mean
    with np.errstate(divide=&#39;ignore&#39;, invalid=&#39;ignore&#39;):
        cv = np.where(mean &gt; 0, std / mean, 0)
        lam = np.where(cv &gt; 0, 1 / (cv**2), 0)

    # Step 4: BT thresholding
    threshold = k * np.sqrt(10 * lam * delta_t)
    s[s &lt; threshold] = 0
    return s</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.entropy_from_string"><code class="name flex">
<span>def <span class="ident">entropy_from_string</span></span>(<span>s)</span>
</code></dt>
<dd>
<div class="desc"><p>return the entropy of a string</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def entropy_from_string(s):
    &#34;&#34;&#34;return the entropy of a string&#34;&#34;&#34;
    _, counts = np.unique(list(s), return_counts=True)
    return entropy(counts, base=2)</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.print_alignment"><code class="name flex">
<span>def <span class="ident">print_alignment</span></span>(<span>seq1, seq2, width=80)</span>
</code></dt>
<dd>
<div class="desc"><p>print aligned sequences</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def print_alignment(seq1, seq2, width=80):
    &#34;&#34;&#34;print aligned sequences&#34;&#34;&#34;
    for i in range(0, len(seq1), width):
        s1 = seq1[i:i+width]
        s2 = seq2[i:i+width]
        match = &#39;&#39;.join(&#39;|&#39; if a == b else &#39; &#39; for a, b in zip(s1, s2))
        print(s1)
        print(match)
        print(s2)
        print()</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.reconstruct_aligned_string"><code class="name flex">
<span>def <span class="ident">reconstruct_aligned_string</span></span>(<span>seq, aligned)</span>
</code></dt>
<dd>
<div class="desc"><p>Fast reconstruction of aligned signals</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def reconstruct_aligned_string(seq, aligned):
    &#34;&#34;&#34;Fast reconstruction of aligned signals&#34;&#34;&#34;
    result, last = [], 0
    for start, end in aligned:
        result.extend([&#39;-&#39;] * (start - last))
        result.extend(seq[start:end])
        last = end
    return &#39;&#39;.join(result)</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.synthetic_signal"><code class="name flex">
<span>def <span class="ident">synthetic_signal</span></span>(<span>x, peaks, baseline=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate flexible synthetic signals. (obsolete)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def synthetic_signal(x, peaks, baseline=None):
    &#34;&#34;&#34;Generate flexible synthetic signals. (obsolete)&#34;&#34;&#34;
    y = np.zeros_like(x)
    for pos, width, height in peaks:
        y += height * np.exp(-((x - pos) / (0.6006 * width)) ** 2)
    if baseline:
        y += baseline(x)
    return y</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="signomics.DNAsignal.align_with"><code class="name flex">
<span>def <span class="ident">align_with</span></span>(<span>self, other, scale=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Align symbolic sequences and compute mutual entropy.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>SimpleNamespace</code></dt>
<dd>with fields
- seq1_aligned (str)
- seq2_aligned (str)
- aligned_signal (list of tuples)
- mutual_entropy (float)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def align_with(self, other, scale=1):
    &#34;&#34;&#34;
    Align symbolic sequences and compute mutual entropy.

    Returns:
        SimpleNamespace: with fields
            - seq1_aligned (str)
            - seq2_aligned (str)
            - aligned_signal (list of tuples)
            - mutual_entropy (float)
    &#34;&#34;&#34;
    seq1 = self.codes[scale][&#39;letters&#39;]
    seq2 = other.codes[scale][&#39;letters&#39;]
    aligner = PairwiseAligner()
    aligner.mode = &#39;global&#39;
    alignment = aligner.align(seq1, seq2)[0]
    a1 = self.reconstruct_aligned_string(seq1, alignment.aligned[0])
    a2 = self.reconstruct_aligned_string(seq2, alignment.aligned[1])
    pairs = list(zip(a1, a2))
    shared = &#39;&#39;.join(a if a == b else &#39;_&#39; for a, b in pairs)
    H = self.entropy_from_string
    return SimpleNamespace(
        seq1_aligned=a1,
        seq2_aligned=a2,
        aligned_signal=pairs,
        mutual_entropy=H(a1) + H(a2) - 2 * H(shared)
    )</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.compute_cwt"><code class="name flex">
<span>def <span class="ident">compute_cwt</span></span>(<span>self, scales=None, apply_filter=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute Continuous Wavelet Transform (CWT) using the Mexican Hat wavelet.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scales</code></strong> :&ensp;<code>list, int,</code> or <code>None</code></dt>
<dd>List of scales (or a single scale) to compute. If None, default to [1, 2, 4, 8, 16].</dd>
<dt><strong><code>apply_filter</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to apply a baseline filter to the input signal before transforming.</dd>
</dl>
<h2 id="sets">Sets</h2>
<p>self.scales : list
The list of actual scales used.
self.filtered_signal : ndarray
Filtered or raw signal used for CWT.
self.cwt_coeffs : dict
Dictionary mapping each scale to its 1D coefficient array.
self.transforms : signal_collection
Collection of <code><a title="signomics.signal" href="#signomics.signal">signal</a></code> objects storing the transformed signals for each scale.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_cwt(self, scales=None, apply_filter=False):
    &#34;&#34;&#34;
    Compute Continuous Wavelet Transform (CWT) using the Mexican Hat wavelet.

    Parameters
    ----------
    scales : list, int, or None
        List of scales (or a single scale) to compute. If None, default to [1, 2, 4, 8, 16].
    apply_filter : bool
        Whether to apply a baseline filter to the input signal before transforming.

    Sets
    ----
    self.scales : list
        The list of actual scales used.
    self.filtered_signal : ndarray
        Filtered or raw signal used for CWT.
    self.cwt_coeffs : dict
        Dictionary mapping each scale to its 1D coefficient array.
    self.transforms : signal_collection
        Collection of `signal` objects storing the transformed signals for each scale.
    &#34;&#34;&#34;
    if scales is None:
        scales = [2 ** i for i in range(5)]
    if not isinstance(scales,(list,tuple)):
        scales = [scales]
    self.scales = scales
    if apply_filter:
        self.filtered_signal = self.apply_baseline_filter(self.signal,delta_t=self.sampling_dt)
    else:
        self.filtered_signal = self.signal
    self.transforms = signal_collection()
    for scale in self.scales:
        coef, _ = pywt.cwt(self.filtered_signal, [scale], &#39;mexh&#39;)
        self.cwt_coeffs[scale] = coef[0]  # Access directly via scale
        sig = signal(
            x=self.x.copy(),
            y=coef[0],
            name=f&#34;CWT_scale_{scale}&#34;,
            x_label=&#34;x&#34;,
            y_label=&#34;CWT amplitude&#34;,
            y_unit=&#34;a.u.&#34;,
            source=&#34;CWT&#34;)
        self.transforms.append(sig)</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.encode_dna"><code class="name flex">
<span>def <span class="ident">encode_dna</span></span>(<span>self, scales=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Encode each transformed signal into a symbolic DNA-like sequence of monotonic segments.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scales</code></strong> :&ensp;<code>list, int,</code> or <code>None</code></dt>
<dd>List of scales (or a single scale) to encode. If None, use self.scales.</dd>
</dl>
<p>The encoding detects strictly monotonic (or flat) segments and labels them with symbolic letters:
- A: crosses 0 upward (neg → pos)
- Z: crosses 0 downward (pos → neg)
- B: strictly increasing negative segment
- Y: strictly decreasing negative segment
- C: strictly increasing positive segment
- X: strictly decreasing positive segment
- _: flat or ambiguous segment</p>
<h2 id="sets">Sets</h2>
<p>self.codes : dict
Dictionary mapping each scale to a struct with:
- letters : str (symbolic encoding)
- widths
: list of float (x-span of each segment)
- heights : list of float (y-delta of each segment)
- iloc
: list of index-pair tuples (start, end+1)
- xloc
: list of x-span tuples (x_start, x_end)
- dx
: segment step (dx)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def encode_dna(self, scales=None):
    &#34;&#34;&#34;
    Encode each transformed signal into a symbolic DNA-like sequence of monotonic segments.

    Parameters
    ----------
    scales : list, int, or None
        List of scales (or a single scale) to encode. If None, use self.scales.

    The encoding detects strictly monotonic (or flat) segments and labels them with symbolic letters:
    - A: crosses 0 upward (neg → pos)
    - Z: crosses 0 downward (pos → neg)
    - B: strictly increasing negative segment
    - Y: strictly decreasing negative segment
    - C: strictly increasing positive segment
    - X: strictly decreasing positive segment
    - _: flat or ambiguous segment

    Sets
    ----
    self.codes : dict
        Dictionary mapping each scale to a struct with:
            - letters : str (symbolic encoding)
            - widths  : list of float (x-span of each segment)
            - heights : list of float (y-delta of each segment)
            - iloc    : list of index-pair tuples (start, end+1)
            - xloc    : list of x-span tuples (x_start, x_end)
            - dx      : segment step (dx)
    &#34;&#34;&#34;
    if scales is None:
        scales = self.scales
    if not isinstance(scales,(list,tuple)):
        scales = [scales]
    if not hasattr(self, &#39;cwt_coeffs&#39;) or not self.cwt_coeffs:
        self.compute_cwt(scales)
    dx = self.x[1]-self.x[0]
    for scale in scales:
        coef = self.cwt_coeffs[scale]
        letters, widths, heights, iloc, xloc = [], [], [], [], []
        monotonic = np.diff(coef)
        mono_sign = np.sign(monotonic)
        sign_changes = np.where(np.diff(mono_sign) != 0)[0] + 1  # +1 because diff shortens by 1
        start_idx = 0
        segment_ends = np.append(sign_changes, len(coef) - 1)
        for count, idx in enumerate(segment_ends):
            xsegment = self.x[start_idx:idx + 1]
            segment = coef[start_idx:idx + 1]
            if len(segment) &lt; 2:
                letters.append(&#39;_&#39;)
            else:
                start, end = segment[0], segment[-1]
                letter = self._get_letter(start, end)
                letters.append(letter)
            widths.append(xsegment[-1] - xsegment[0])
            heights.append(segment[-1] - segment[0])
            xloc.append((xsegment[0],xsegment[-1]))
            is_last = count == len(segment_ends) - 1
            iloc.append((start_idx, idx + 1 if is_last else idx))
            start_idx = idx #idx + 1 (segments are continguous)
        # update codes
        self.codes[scale] = {&#39;letters&#39;: &#39;&#39;.join(letters),
                             &#39;widths&#39;: widths,
                             &#39;heights&#39;: heights,
                             &#39;xloc&#39;:xloc,
                             &#39;iloc&#39;:iloc,
                             &#39;dx&#39;:dx}</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.encode_dna_full"><code class="name flex">
<span>def <span class="ident">encode_dna_full</span></span>(<span>self, scales=None, resolution='index', repeat=True, n_points=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert symbolic codes into DNA-like strings by repeating letters proportionally to their span.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scales</code></strong> :&ensp;<code>list, int,</code> or <code>None</code></dt>
<dd>List of scales (or a single scale) to convert. If None, use self.scales.</dd>
<dt><strong><code>resolution</code></strong> :&ensp;<code>{'index', 'x'}</code></dt>
<dd>Repetition mode:
- 'index': repeat letters by number of indices (j - i from iloc)
- 'x'
: interpolate letter values over physical x-axis distance (xloc)</dd>
<dt><strong><code>repeat</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, repeat or interpolate letters to form a string of desired resolution.
If False, return the symbolic sequence without repetition.</dd>
<dt><strong><code>n_points</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>Used only for resolution='x' to control the number of interpolation points.
If None, defaults to ~10 points per x-unit.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Dictionary mapping each scale to its DNA-like string.</dd>
</dl>
<h2 id="sets">Sets</h2>
<p>self.codesfull : dict
Dictionary storing the resulting full DNA-like string per scale.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def encode_dna_full(self, scales=None, resolution=&#39;index&#39;, repeat=True, n_points=None):
    &#34;&#34;&#34;
    Convert symbolic codes into DNA-like strings by repeating letters proportionally to their span.

    Parameters
    ----------
    scales : list, int, or None
        List of scales (or a single scale) to convert. If None, use self.scales.
    resolution : {&#39;index&#39;, &#39;x&#39;}
        Repetition mode:
            - &#39;index&#39;: repeat letters by number of indices (j - i from iloc)
            - &#39;x&#39;    : interpolate letter values over physical x-axis distance (xloc)
    repeat : bool
        If True, repeat or interpolate letters to form a string of desired resolution.
        If False, return the symbolic sequence without repetition.
    n_points : int or None
        Used only for resolution=&#39;x&#39; to control the number of interpolation points.
        If None, defaults to ~10 points per x-unit.

    Returns
    -------
    dict
        Dictionary mapping each scale to its DNA-like string.

    Sets
    ----
    self.codesfull : dict
        Dictionary storing the resulting full DNA-like string per scale.
    &#34;&#34;&#34;
    if scales is None:
        scales = self.scales
    elif isinstance(scales, (int, float)):
        scales = [scales]
    elif not isinstance(scales, (list, tuple)):
        raise TypeError(&#34;scales must be a list, int, or None&#34;)

    if not hasattr(self, &#39;codes&#39;) or not self.codes:
        self.encode_dna(scales)

    result = {}
    for scale in scales:
        if scale not in self.codes:
            self.encode_dna([scale])
        code = self.codes[scale]
        if not repeat:
            result[scale] = code[&#39;letters&#39;]
            continue
        if resolution == &#39;index&#39;:
            sequence = &#39;&#39;.join(
                letter * max(1, (j - i)) for letter, (i, j) in zip(code[&#39;letters&#39;], code[&#39;iloc&#39;])
            )
        elif resolution == &#39;x&#39;:
            if n_points is None:
                total_span = sum(x2 - x1 for x1, x2 in code[&#39;xloc&#39;])
                n_points = int(np.ceil(total_span * 10))  # adjustable density
            x_start = code[&#39;xloc&#39;][0][0]
            x_end = code[&#39;xloc&#39;][-1][1]
            grid = np.linspace(x_start, x_end, n_points, endpoint=True)
            centers = [(x1 + x2) / 2 for x1, x2 in code[&#39;xloc&#39;]]
            # Encode letters as integers
            unique_letters = list(OrderedDict.fromkeys(code[&#39;letters&#39;]))
            letter_to_int = {ch: i for i, ch in enumerate(unique_letters)}
            int_to_letter = {i: ch for ch, i in letter_to_int.items()}

            int_vals = [letter_to_int[ch] for ch in code[&#39;letters&#39;]]
            interp_func = interp1d(centers, int_vals, kind=&#39;nearest&#39;,
                                   bounds_error=False, fill_value=int_vals[-1])
            interpolated = np.round(interp_func(grid)).astype(int)
            sequence = &#39;&#39;.join(int_to_letter[i] for i in interpolated)
        else:
            raise ValueError(&#34;resolution must be either &#39;index&#39; or &#39;x&#39;&#34;)
        result[scale] = DNAstr(sequence,
                               dx=code[&#34;dx&#34;],
                               iloc=(code[&#34;iloc&#34;][0][0],code[&#34;iloc&#34;][-1][-1]),
                               xloc=(code[&#34;xloc&#34;][0][0],code[&#34;xloc&#34;][-1][-1]),
                               x_label=self.x_label, x_unit=self.x_unit)
    self.codesfull = result</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.find_sequence"><code class="name flex">
<span>def <span class="ident">find_sequence</span></span>(<span>self, pattern, scale)</span>
</code></dt>
<dd>
<div class="desc"><p>Find occurrences of a specific letter pattern in encoded sequence.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_sequence(self, pattern, scale):
    &#34;&#34;&#34;Find occurrences of a specific letter pattern in encoded sequence.&#34;&#34;&#34;
    sequence = self.codes[scale][&#39;letters&#39;]
    positions = []
    idx = sequence.find(pattern)
    while idx != -1:
        positions.append(idx)
        idx = sequence.find(pattern, idx + 1)
    return positions</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.get_code"><code class="name flex">
<span>def <span class="ident">get_code</span></span>(<span>self, scale)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve encoded data for a specific scale.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_code(self, scale):
    &#34;&#34;&#34;Retrieve encoded data for a specific scale.&#34;&#34;&#34;
    return self.codes[scale]</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.get_entropy"><code class="name flex">
<span>def <span class="ident">get_entropy</span></span>(<span>self, scale)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate Shannon entropy for encoded signal.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_entropy(self, scale):
    &#34;&#34;&#34;Calculate Shannon entropy for encoded signal.&#34;&#34;&#34;
    letters = self.codes[scale][&#39;letters&#39;]
    _, counts = np.unique(list(letters), return_counts=True)
    return entropy(counts, base=2)</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.has"><code class="name flex">
<span>def <span class="ident">has</span></span>(<span>self, scale)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if a DNA encoding exists for the specified scale.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scale</code></strong> :&ensp;<code>int</code></dt>
<dd>The wavelet scale to check.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if a symbolic DNAstr encoding exists at the given scale, False otherwise.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; dna.has(4)
True
&gt;&gt;&gt; dna.has(16)
False
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def has(self, scale):
    &#34;&#34;&#34;
    Check if a DNA encoding exists for the specified scale.

    Parameters
    ----------
    scale : int
        The wavelet scale to check.

    Returns
    -------
    bool
        True if a symbolic DNAstr encoding exists at the given scale, False otherwise.

    Examples
    --------
    &gt;&gt;&gt; dna.has(4)
    True
    &gt;&gt;&gt; dna.has(16)
    False
    &#34;&#34;&#34;
    return scale in self.codes</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.plot_codes"><code class="name flex">
<span>def <span class="ident">plot_codes</span></span>(<span>self, scale, ax=None, colormap=None, alpha=0.4)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the symbolic DNA-like encoding as colored triangle segments.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scale</code></strong> :&ensp;<code>int</code></dt>
<dd>The scale at which the signal was encoded.</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axes.Axes</code>, optional</dt>
<dd>Axis to draw on. If None, a new figure is created.</dd>
<dt><strong><code>colormap</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Custom mapping of letters to colors. Default uses 7 distinct colors.</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code></dt>
<dd>Transparency for the patches. Default is 0.4.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_codes(self, scale, ax=None, colormap=None, alpha=0.4):
    &#34;&#34;&#34;
    Plot the symbolic DNA-like encoding as colored triangle segments.

    Parameters
    ----------
    scale : int
        The scale at which the signal was encoded.
    ax : matplotlib.axes.Axes, optional
        Axis to draw on. If None, a new figure is created.
    colormap : dict, optional
        Custom mapping of letters to colors. Default uses 7 distinct colors.
    alpha : float
        Transparency for the patches. Default is 0.4.
    &#34;&#34;&#34;

    if ax is None:
        fig, ax = plt.subplots(figsize=(12, 5))
    else:
        fig = plt.gcf()
        ax = plt.gca()

    # Default color mapping
    default_colormap = {
        &#39;A&#39;: &#39;DeepPink&#39;,&#39;B&#39;: &#39;OrangeRed&#39;, &#39;C&#39;: &#39;Gold&#39;,
        &#39;X&#39;: &#39;DeepSkyBlue&#39;,&#39;Y&#39;: &#39;DodgerBlue&#39;, &#39;Z&#39;: &#39;Purple&#39;,
        &#39;_&#39;: &#39;gray&#39;
    }
    cmap = colormap or default_colormap

    # Flags
    cross_flags = self._is_letter_crossing

    # Retrieve segment data
    code_data = self.codes[scale]
    letters = code_data[&#39;letters&#39;]
    widths = code_data[&#39;widths&#39;]
    heights = code_data[&#39;heights&#39;]
    xloc = code_data[&#39;xloc&#39;]
    coef = self.cwt_coeffs[scale]
    x = self.x if hasattr(self, &#39;x&#39;) and self.x is not None else np.arange(len(coef))

    # Generate path data
    last_y = 0.0
    patchxy = []

    # Process segments with continuity enforcement
    nletters = len(letters)
    for i in range(nletters):
        letter = letters[i]
        repeatedletter_withprevious = letter if i&gt;0 else False
        repeatedletter_withnext = letter if i&lt;(nletters-1) else False
        repeated = repeatedletter_withprevious or repeatedletter_withnext
        y0 = last_y if cross_flags[letter] or repeated else 0.0
        x0, w, h = xloc[i][0], widths[i], heights[i]
        last_y = y0 + h
        x,y = self._get_triangle_from_letter(letter,x0,y0,w,h)
        triangle = [[x[0], y[0]], [x[1], y[1]], [x[2], y[2]], [x[0], y[0]]]
        patchxy.append(triangle)

    # Plot patches
    for letter,verts in zip(letters,patchxy):
        poly = Polygon(verts, closed=True, color=cmap.get(letter, &#39;black&#39;), alpha=alpha)
        ax.add_patch(poly)

    # Plot raw and transformed signals
    ax.plot(self.x, self.signal, color=&#39;black&#39;, linewidth=3, label=&#39;Original Signal&#39;)
    ax.plot(self.x, coef, color=&#39;blue&#39;, linewidth=2, label=f&#39;CWT Scale {scale}&#39;)
    ax.set_xlabel(f&#34;{self.x_label} [{self.x_unit}]&#34;)
    ax.set_ylabel(f&#34;{self.y_label} [{self.y_unit}]&#34;)
    ax.set_title(f&#34;Symbolic Segments (Scale {scale})&#34;)
    ax.legend()
    ax.set_xlim([self.x[0], self.x[-1]])
    ax.axhline(0, color=&#39;k&#39;, linewidth=0.5, linestyle=&#39;:&#39;)
    plt.tight_layout()
    plt.show()
    return fig</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.plot_signals"><code class="name flex">
<span>def <span class="ident">plot_signals</span></span>(<span>self, scales=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot signals.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_signals(self, scales=None):
    &#34;&#34;&#34;Plot signals.&#34;&#34;&#34;
    if scales is None:
        scales = self.scales
    plt.figure(figsize=(10, 6))
    plt.plot(self.signal, label=&#39;Original Signal&#39;, linewidth=4, color=&#34;k&#34;)
    for scale in scales:
        plt.plot(self.cwt_coeffs[scale], label=f&#39;Scale {scale}&#39;, linewidth=2, alpha=0.7)
    plt.legend()
    plt.title(&#34;Signal and Transformed Scales&#34;)
    plt.x_label(f&#34;{self.x_label} [{self.x_unit}]&#34;)
    plt.y_label(f&#34;{self.y_label} [{self.y_unit}]&#34;)
    plt.show()</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.plot_transforms"><code class="name flex">
<span>def <span class="ident">plot_transforms</span></span>(<span>self, indices=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the stored CWT-transformed signals as a signal collection.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>indices</code></strong> :&ensp;<code>list[int</code> or <code>str]</code>, optional</dt>
<dd>Specific scales or names to plot.</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>passed to </code>signal_collection.plot``</dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_transforms(self, indices=None, **kwargs):
    &#34;&#34;&#34;
    Plot the stored CWT-transformed signals as a signal collection.

    Parameters
    ----------
    indices : list[int or str], optional
        Specific scales or names to plot.
    kwargs : passed to `signal_collection.plot`
    &#34;&#34;&#34;
    if not hasattr(self, &#34;transforms&#34;):
        raise AttributeError(&#34;No transformed signals found. Run `compute_cwt()` first.&#34;)
    self.transforms.plot(indices=indices, title=f&#34;CWT Transforms: {self.name}&#34;, **kwargs)</code></pre>
</details>
</dd>
<dt id="signomics.DNAsignal.reconstruct_signal"><code class="name flex">
<span>def <span class="ident">reconstruct_signal</span></span>(<span>self, scale, return_signal=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Reconstruct the signal from symbolic features (e.g., YAZB).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>scale</code></strong> :&ensp;<code>int</code></dt>
<dd>Scale to use for reconstruction.</dd>
<dt><strong><code>return_signal</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, return a <code><a title="signomics.signal" href="#signomics.signal">signal</a></code> object. Else return y array.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="signomics.signal" href="#signomics.signal">signal</a></code> or <code>np.ndarray</code></dt>
<dd>Reconstructed signal.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reconstruct_signal(self, scale, return_signal=True):
    &#34;&#34;&#34;
    Reconstruct the signal from symbolic features (e.g., YAZB).

    Parameters
    ----------
    scale : int
        Scale to use for reconstruction.
    return_signal : bool
        If True, return a `signal` object. Else return y array.

    Returns
    -------
    signal or np.ndarray
        Reconstructed signal.
    &#34;&#34;&#34;
    coef = self.cwt_coeffs[scale]
    peaks = self.find_sequence(&#39;YAZB&#39;, scale)
    y = np.zeros_like(self.signal)

    for peak in peaks:
        pos = peak * scale
        width = scale
        height = coef[peak]
        y += height * np.exp(-((np.arange(len(y)) - pos) / (0.6006 * width)) ** 2)

    if return_signal:
        from signal import signal as Signal
        return Signal(x=self.x.copy(), y=y, name=f&#34;reconstructed_{self.name}&#34;,
                      x_label=&#34;x&#34;, y_label=&#34;reconstructed&#34;, y_unit=&#34;a.u.&#34;)
    return y</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="signomics.DNAstr"><code class="flex name class">
<span>class <span class="ident">DNAstr</span></span>
<span>(</span><span>content, dx=1.0, iloc=0, xloc=None, x_label='index', x_unit='-', engine='difflib', engineOpts=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A symbolic DNA-like sequence class supporting alignment, entropy analysis,
edit-distance metrics, and signal reconstruction from symbolic codes.</p>
<p>Extended from <code>str</code>, it is designed for symbolic transformations of signals
(e.g., wavelet-encoded GC-MS peaks or time series).</p>
<h2 id="main-features">Main Features</h2>
<ul>
<li>Supports symbolic operations for pattern recognition, entropy, alignment.</li>
<li>Encodes x-resolution (<code>dx</code>), original index (<code>iloc</code>), and physical x-range (<code>xloc</code>).</li>
<li>Aligns sequences with visual inspection and rich diffs.</li>
<li>Converts symbolic strings into synthetic numerical signals.</li>
</ul>
<h2 id="operators">Operators</h2>
<ul>
<li>: concatenate two DNAstr objects</li>
<li>: symbolic difference after alignment (mismatches only)
== : equality comparison (exact content and dx)</li>
</ul>
<h2 id="key-methods">Key Methods</h2>
<ul>
<li><strong>init</strong> / <strong>new</strong>
: Constructor with metadata (<code>dx</code>, <code>iloc</code>, <code>xloc</code>)</li>
<li>align(other)
: Align this DNAstr to another, update mask and aligned views</li>
<li>wrapped_alignment()
: Pretty terminal view of the alignment with colors and symbols</li>
<li>html_alignment()
: Rich HTML display of the alignment (Jupyter)</li>
<li>plot_alignment()
: Visualize waveform alignment with symbolic signals</li>
<li>plot_mask()
: Color block plot showing matches/mismatches/gaps</li>
<li>find(pattern, regex=False) : Search for symbolic patterns with fuzziness or regex</li>
<li>to_signal()
: Convert symbolic code into synthetic signal (NumPy)</li>
<li>vectorized()
: Convert string to integer codes</li>
<li>summary()
: Print entropy and character frequencies</li>
<li>mutation_counts
: Property: {'matches', 'mismatches', 'indels'}</li>
<li>entropy
: Property: Shannon entropy</li>
<li>mutual_entropy(other)
: Mutual entropy of two sequences</li>
<li>excess_entropy(other)
: Excess entropy H1 + H2 - 2 * H12</li>
<li>jensen_shannon(other)
: Jensen-Shannon divergence</li>
<li>jaccard(other)
: Jaccard similarity</li>
<li>alignment_stats
: Property: Match, substitution, gap counts</li>
<li>score(normalized=True) : Alignment score (fraction of matches)</li>
<li>has(other: str)
: Check if a pattern or substring exists</li>
</ul>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>dx</code></strong> :&ensp;<code>float</code></dt>
<dd>Average resolution along the x-axis.</dd>
<dt><strong><code>iloc</code></strong> :&ensp;<code>int</code> or <code>tuple</code> of <code>int</code></dt>
<dd>Positional index or index range in the source DNA string.</dd>
<dt><strong><code>xloc</code></strong> :&ensp;<code>float</code> or <code>tuple</code> of <code>float</code></dt>
<dd>Corresponding x-value(s) for the symbolic sequence.</dd>
<dt><strong><code>aligned_with</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Aligned form of self with insertions (spaces) where needed.</dd>
<dt><strong><code>other_copy</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Aligned form of the reference sequence.</dd>
<dt><strong><code>ref_hash</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>SHA256 hash of the aligned reference sequence.</dd>
<dt><strong><code>mask</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Alignment mask: '=' for matches, '*' for substitutions, ' ' for gaps.</dd>
<dt><strong><code>engine</code></strong> :&ensp;<code>str</code></dt>
<dd>Alignment engine: 'difflib' or 'bio'.</dd>
<dt><strong><code>engineOpts</code></strong> :&ensp;<code>dict</code></dt>
<dd>Options passed to the alignment engine.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; s1 = DNAstr(&quot;YYAAZZBB&quot;, dx=0.5)
&gt;&gt;&gt; s2 = DNAstr(&quot;YAABZBB&quot;, dx=0.5)
&gt;&gt;&gt; s1.align(s2)
&gt;&gt;&gt; print(s1.wrapped_alignment(40))
&gt;&gt;&gt; s1.plot_alignment()
&gt;&gt;&gt; segments = s1.find(&quot;YAZB&quot;)
&gt;&gt;&gt; segments[0].to_signal().plot()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DNAstr(str):
    &#34;&#34;&#34;
    A symbolic DNA-like sequence class supporting alignment, entropy analysis,
    edit-distance metrics, and signal reconstruction from symbolic codes.

    Extended from `str`, it is designed for symbolic transformations of signals
    (e.g., wavelet-encoded GC-MS peaks or time series).

    Main Features
    -------------
    - Supports symbolic operations for pattern recognition, entropy, alignment.
    - Encodes x-resolution (`dx`), original index (`iloc`), and physical x-range (`xloc`).
    - Aligns sequences with visual inspection and rich diffs.
    - Converts symbolic strings into synthetic numerical signals.

    Operators
    ---------
    + : concatenate two DNAstr objects
    - : symbolic difference after alignment (mismatches only)
    == : equality comparison (exact content and dx)

    Key Methods
    -----------
    - __init__ / __new__      : Constructor with metadata (`dx`, `iloc`, `xloc`)
    - align(other)            : Align this DNAstr to another, update mask and aligned views
    - wrapped_alignment()     : Pretty terminal view of the alignment with colors and symbols
    - html_alignment()        : Rich HTML display of the alignment (Jupyter)
    - plot_alignment()        : Visualize waveform alignment with symbolic signals
    - plot_mask()             : Color block plot showing matches/mismatches/gaps
    - find(pattern, regex=False) : Search for symbolic patterns with fuzziness or regex
    - to_signal()             : Convert symbolic code into synthetic signal (NumPy)
    - vectorized()            : Convert string to integer codes
    - summary()               : Print entropy and character frequencies
    - mutation_counts         : Property: {&#39;matches&#39;, &#39;mismatches&#39;, &#39;indels&#39;}
    - entropy                 : Property: Shannon entropy
    - mutual_entropy(other)   : Mutual entropy of two sequences
    - excess_entropy(other)   : Excess entropy H1 + H2 - 2 * H12
    - jensen_shannon(other)   : Jensen-Shannon divergence
    - jaccard(other)          : Jaccard similarity
    - alignment_stats         : Property: Match, substitution, gap counts
    - score(normalized=True) : Alignment score (fraction of matches)
    - has(other: str)         : Check if a pattern or substring exists

    Attributes
    ----------
    dx : float
        Average resolution along the x-axis.
    iloc : int or tuple of int
        Positional index or index range in the source DNA string.
    xloc : float or tuple of float
        Corresponding x-value(s) for the symbolic sequence.
    aligned_with : str or None
        Aligned form of self with insertions (spaces) where needed.
    other_copy : str or None
        Aligned form of the reference sequence.
    ref_hash : str or None
        SHA256 hash of the aligned reference sequence.
    mask : str or None
        Alignment mask: &#39;=&#39; for matches, &#39;*&#39; for substitutions, &#39; &#39; for gaps.
    engine : str
        Alignment engine: &#39;difflib&#39; or &#39;bio&#39;.
    engineOpts : dict
        Options passed to the alignment engine.

    Examples
    --------
    &gt;&gt;&gt; s1 = DNAstr(&#34;YYAAZZBB&#34;, dx=0.5)
    &gt;&gt;&gt; s2 = DNAstr(&#34;YAABZBB&#34;, dx=0.5)
    &gt;&gt;&gt; s1.align(s2)
    &gt;&gt;&gt; print(s1.wrapped_alignment(40))
    &gt;&gt;&gt; s1.plot_alignment()
    &gt;&gt;&gt; segments = s1.find(&#34;YAZB&#34;)
    &gt;&gt;&gt; segments[0].to_signal().plot()

    &#34;&#34;&#34;

    def __new__(cls, content, dx=1.0, iloc=0, xloc=None, x_label=&#34;index&#34;, x_unit=&#34;-&#34;,
                engine=&#34;difflib&#34;, engineOpts=None):
        &#34;&#34;&#34;
        Construct a new DNAstr object.

        Parameters
        ----------
        content : str
            The symbolic DNA-like string content.
        dx : float, optional
            Nominal resolution (default: 1.0).
        iloc : int, optional
            Integer index or start index of the sequence (default: 0).
        xloc : float, optional
            X-coordinate of the sequence origin.
        engine : {&#39;difflib&#39;, &#39;bio&#39;}, optional
            Default alignment engine to use.
        engineOpts : dict, optional
            Dictionary of alignment parameters for the selected engine.

        Returns
        -------
        DNAstr
            Initialized DNAstr instance.
        &#34;&#34;&#34;
        obj = str.__new__(cls, content)
        obj.dx = dx
        obj.iloc = iloc
        obj.xloc = xloc
        obj.x_label = x_label
        obj.x_unit = x_unit
        obj.aligned_with = None
        obj.other_copy = None
        obj.ref_aligned = None
        obj.ref_hash = None
        obj.mask = None
        if engine not in (&#34;difflib&#34;, &#34;bio&#34;):
            raise ValueError(&#39;engine must be &#34;difflib&#34; or &#34;bio&#34;&#39;)
        obj.engine = engine
        obj.engineOpts = engineOpts or {}
        obj._hash = hashlib.sha256(obj.encode()).hexdigest()
        return obj

    def __hash__(self):
        &#34;&#34;&#34;
        Return hash combining the string content and dx.

        Returns
        -------
        int
            Hash of the DNAstr object.
        &#34;&#34;&#34;
        return hash((str(self), self.dx))

    def summary(self):
        &#34;&#34;&#34;
        Summarize the DNAstr with key stats: length, unique letters, entropy, etc.

        Returns
        -------
        dict
            Dictionary containing length, letter frequency, Shannon entropy, and dx.
        &#34;&#34;&#34;
        length = len(self)
        freqs = Counter(self)
        prob = np.array(list(freqs.values())) / length
        entropy = -np.sum(prob * np.log2(prob))
        return {
            &#39;length&#39;: length,
            &#39;letters&#39;: dict(freqs),
            &#39;entropy (Shannon)&#39;: entropy,
            &#39;dx&#39;: self.dx
        }

    def vectorized(self, codebook={&#34;A&#34;:1,&#34;B&#34;:2,&#34;C&#34;:3,&#34;X&#34;:4,&#34;Y&#34;:5,&#34;Z&#34;:6,&#34;_&#34;:0}):
        &#34;&#34;&#34;
        Map the DNAstr content to an integer array using a codebook.

        Parameters
        ----------
        codebook : dict, optional
            Dictionary mapping characters to integer values.
            default = {&#34;A&#34;:1,&#34;B&#34;:2,&#34;C&#34;:3,&#34;X&#34;:4,&#34;Y&#34;:5,&#34;Z&#34;:6,&#34;_&#34;:0}
            None will generate a codebook based on current symbols only

        Returns
        -------
        np.ndarray
            Vectorized integer representation of the string.
        &#34;&#34;&#34;
        from collections import OrderedDict
        if codebook is None:
            unique_chars = list(OrderedDict.fromkeys(self))
            codebook = {c: i for i, c in enumerate(unique_chars)}
        return np.array([codebook.get(c, -1) for c in self], dtype=int)

    def __eq__(self, other):
        &#34;&#34;&#34;
        Check equality based on symbolic content and dx resolution.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr instance.

        Returns
        -------
        bool
            True if both content and dx are equal.
        &#34;&#34;&#34;
        return isinstance(other, DNAstr) and str.__eq__(self, other) and self.dx == other.dx


    def __add__(self, other):
        &#34;&#34;&#34;
        Concatenate two DNAstr instances with identical dx values.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr sequence.

        Returns
        -------
        DNAstr
            Concatenated DNAstr sequence.

        Raises
        ------
        TypeError
            If the argument is not a DNAstr.
        ValueError
            If `dx` values differ.
        &#34;&#34;&#34;
        if not isinstance(other, DNAstr):
            raise TypeError(&#34;Can only concatenate DNAstr (not &#39;{}&#39;)&#34;.format(type(other).__name__))
        if self.dx != other.dx:
            raise ValueError(&#34;dx mismatch. Use forced=True to override.&#34;)
        return DNAstr(str.__add__(self, other), dx=self.dx, iloc=self.iloc, xloc=self.xloc,
                                   x_label=self.x_label, x_unit=self.x_unit)

    def __sub__(self, other):
        &#34;&#34;&#34;
        Subtract two DNAstr sequences by aligning and removing matched regions.

        Parameters
        ----------
        other : DNAstr
            DNAstr instance to align and subtract.

        Returns
        -------
        DNAstr
            A new DNAstr containing mismatched symbols only.
        &#34;&#34;&#34;
        if not isinstance(other, DNAstr):
            raise TypeError(&#34;Can only subtract DNAstr instances&#34;)
        self.align(other)
        mismatch = &#39;&#39;.join([a for a, b in zip(self.aligned_with, self.other_copy) if a != b and b != &#39; &#39;])
        return DNAstr(mismatch, dx=self.dx, iloc=self.iloc, xloc=self.xloc,
                                   x_label=self.x_label, x_unit=self.x_unit)

    @property
    def mutation_counts(self):
        &#34;&#34;&#34;Counts of insertions, deletions/substitutions, and matches.&#34;&#34;&#34;
        m = self.mask
        return {
            &#39;matches&#39;: m.count(&#39;=&#39;),
            &#39;mismatches&#39;: m.count(&#39;*&#39;),
            &#39;indels&#39;: m.count(&#39; &#39;)
        }
    @property
    def entropy(self):
        &#34;&#34;&#34;Compute the Shannon entropy of the DNAstr sequence&#34;&#34;&#34;
        count = Counter(self)
        total = sum(count.values())
        return -sum((v / total) * np.log2(v / total) for v in count.values())

    def mutual_entropy(self, other=None):
        &#34;&#34;&#34;Compute the Shannon mutual entropy of two DNAstr sequences from their aligned segments&#34;&#34;&#34;
        if other is not None and not isinstance(other,DNAstr):
            raise TypeError(f&#34;other must be a DNAstr not a {type(self).__name__}&#34;)
        if other is None and (not hasattr(self,&#34;aligned_with&#34;) or self.aligned_with is None):
            raise ValueError(&#34;align the code with .align(other) or provide other&#34;)
        if isinstance(other,DNAstr):
            self.align(other)
        aligned = self.aligned_code
        count = Counter(aligned)
        total = sum(count.values())
        return -sum((v / total) * np.log2(v / total) for v in count.values())

    def excess_entropy(self, other):
        &#34;&#34;&#34;Compute the excess Shannon entropy of two DNAstr sequences H(A)+H(B)-2*H(AB)&#34;&#34;&#34;
        return self.entropy + other.entropy - 2 * self.mutual_entropy(other)

    def jensen_shannon(self, other, base=2):
        &#34;&#34;&#34;
        Compute the Jensen-Shannon distance between self and another DNAstr.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr instance.
        base : float, optional
            Base for the logarithm (default: 2)

        Returns
        -------
        float
            Jensen-Shannon distance.
        &#34;&#34;&#34;
        v1 = Counter(self)
        v2 = Counter(other)
        all_keys = sorted(set(v1) | set(v2))
        p = np.array([v1.get(k, 0) for k in all_keys], dtype=float)
        q = np.array([v2.get(k, 0) for k in all_keys], dtype=float)
        p /= p.sum()
        q /= q.sum()
        return jensenshannon(p, q, base=base)


    def levenshtein(self, other, use_alignment=True, engine=None, engineOpts=None, forced=False):
        &#34;&#34;&#34;
        Compute the Levenshtein distance between this DNAstr and another one.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr object to compare against.
        use_alignment : bool, default=True
            If True, uses the aligned sequences (computed if necessary).
            If False, compares the raw sequences directly.
        engine : {&#39;difflib&#39;, &#39;bio&#39;}, optional
            Alignment engine to use if alignment is needed.
        engineOpts : dict, optional
            Parameters for the selected alignment engine.
        forced : bool, default=False
            Force alignment even if dx values differ.

        Returns
        -------
        dist : int
            Levenshtein distance between the two sequences (aligned or raw).

        Examples
        --------
        A = DNAstr(&#34;YAZBZAY&#34;)
        B = DNAstr(&#34;YAZBZZY&#34;)
        A.levenshtein_distance(B, use_alignment=False)  # raw
        A.levenshtein_distance(B, use_alignment=True, engine=&#34;bio&#34;)  # aligned
        &#34;&#34;&#34;
        if not isinstance(other, DNAstr):
            raise TypeError(&#34;Argument must be a DNAstr instance&#34;)
        if use_alignment:
            self.align(other, engine=engine, engineOpts=engineOpts, forced=forced)
            s1, s2 = self.aligned_with, self.other_copy
        else:
            s1, s2 = str(self), str(other)
        return Levenshtein.distance(s1, s2)


    def jaccard(self, other):
        &#34;&#34;&#34;
        Compute the Jaccard distance between two DNAstr sequences.

        Parameters
        ----------
        other : DNAstr
            The other DNAstr sequence to compare with.

        Returns
        -------
        float
            Jaccard distance: 1 - (intersection / union) of unique letters.
        &#34;&#34;&#34;
        set_self = set(self)
        set_other = set(other)
        intersection = set_self &amp; set_other
        union = set_self | set_other
        return 1 - len(intersection) / len(union) if union else 0.0

    def align(self, other, engine=None, engineOpts=None, forced=False):
        &#34;&#34;&#34;
        Align this DNAstr sequence to another, allowing insertions/deletions to maximize matches.

        Parameters
        ----------
        other : DNAstr
            Another DNAstr object to align with.
        engine : {&#39;difflib&#39;, &#39;bio&#39;} or None
            Alignment engine to use:
                - &#39;difflib&#39;: uses difflib.SequenceMatcher (fast, approximate).
                - &#39;bio&#39;   : uses Bio.Align.PairwiseAligner (biologically inspired global alignment).
            If None, defaults to self.engine.
        engineOpts : dict, optional
            Dictionary of alignment parameters for the selected engine.
        forced : bool
            If True, allow alignment even if `dx` values differ. If False (default), a mismatch in
            `dx` will raise an error to prevent incorrect alignment of signals with different sampling.

        Returns
        -------
        aligned_self : str
            Aligned version of this sequence (with gaps inserted where needed).
        aligned_other : str
            Aligned version of the other sequence.

        Notes
        -----
        The alignment is symmetric and permanent: both sequences are aligned with
        gaps introduced (spaces) to preserve positional correspondence. A hash of
        the aligned `other` sequence is stored to detect redundant alignments.

        A match mask (`self.mask`) is generated with:
            &#39;=&#39; for exact matches,
            &#39;*&#39; for mismatches (substitutions),
            &#39; &#39; for insertions/deletions (gaps).

        The method updates:
            - self.aligned_with
            - self.other_copy
            - self.mask
            - self.ref_hash

        Example:
        --------
        S1 = DNAstr(&#34;AABBCC&#34;)
        S2 = DNAstr(&#34;AACBCC&#34;)
        S1.align(S2,&#34;difflib&#34;)
        print(S1.mask)
        print(S1.wrapped_alignment())
        ==*===
        AACBCC
        || |||
        AABBCC

        S1 = DNAstr(&#34;AABBCC&#34;)
        S2 = DNAstr(&#34;AACBCC&#34;)
        S1.align(S2,&#34;bio&#34;)
        print(S1.mask)
        print(S1.wrapped_alignment())
        ==  ==
        AAB·CC
        ||  ||
        AA·BCC

        S1 = DNAstr(&#34;AABBCCXYZZZ&#34;)
        S2 = DNAstr(&#34;AACBCCZZXXX&#34;)
        S1.align(S2,&#34;bio&#34;)
        print(S1.mask)
        print(S1.wrapped_alignment())
        == *   ==
        AABCC··ZZ
        ||     ||
        AA·B·CCZZ

        &#34;&#34;&#34;
        if not isinstance(other, DNAstr):
            raise TypeError(&#34;Alignment requires another DNAstr instance&#34;)
        if not forced and self.dx != other.dx:
            raise ValueError(&#34;dx mismatch. Use forced=True to override.&#34;)
        if hasattr(other, &#39;ref_hash&#39;) and self.ref_hash is not None and self.ref_hash == other.ref_hash:
            return self.aligned_with, self.other_copy

        engine = engine or self.engine
        engineOpts = engineOpts or self.engineOpts.get(engine, {})

        if engine == &#39;difflib&#39;:
            sm = SequenceMatcher(None, other, self)
            aligned_self, aligned_other = [], []
            for tag, i1, i2, j1, j2 in sm.get_opcodes():
                if tag == &#39;equal&#39;:
                    aligned_self.extend(self[j1:j2])
                    aligned_other.extend(other[i1:i2])
                elif tag == &#39;replace&#39;:
                    aligned_self.extend(self[j1:j2])
                    aligned_other.extend(other[i1:i2])
                elif tag == &#39;insert&#39;:
                    aligned_self.extend(self[j1:j2])
                    aligned_other.extend(&#39; &#39; * (j2 - j1))
                elif tag == &#39;delete&#39;:
                    aligned_self.extend(&#39; &#39; * (i2 - i1))
                    aligned_other.extend(other[i1:i2])

        elif engine == &#39;bio&#39;:
            aligner = PairwiseAligner()
            for k, v in engineOpts.items():
                setattr(aligner, k, v)

            alignment = aligner.align(other, self)[0]  # Best alignment
            aligned_self = []
            aligned_other = []

            # These are lists of (start, end) index tuples for each sequence
            self_blocks = alignment.aligned[1]
            other_blocks = alignment.aligned[0]

            self_pos = 0
            other_pos = 0

            for (o_start, o_end), (s_start, s_end) in zip(other_blocks, self_blocks):
                # Fill gaps in other
                if o_start &gt; other_pos:
                    gap_len = o_start - other_pos
                    aligned_other.extend(other[other_pos:o_start])
                    aligned_self.extend([&#39; &#39;] * gap_len)
                    other_pos = o_start
                # Fill gaps in self
                if s_start &gt; self_pos:
                    gap_len = s_start - self_pos
                    aligned_self.extend(self[self_pos:s_start])
                    aligned_other.extend([&#39; &#39;] * gap_len)
                    self_pos = s_start

                # Aligned regions
                aligned_self.extend(self[s_start:s_end])
                aligned_other.extend(other[o_start:o_end])
                self_pos = s_end
                other_pos = o_end

            # Tail padding
            aligned_self.extend(self[self_pos:])
            aligned_other.extend([&#39; &#39;] * (len(self) - self_pos))
            aligned_other.extend(other[other_pos:])
            aligned_self.extend([&#39; &#39;] * (len(other) - other_pos))

        else:
            raise ValueError(&#34;Unknown alignment engine: choose &#39;difflib&#39; or &#39;bio&#39;&#34;)

        self.aligned_with = &#39;&#39;.join(aligned_self)
        self.other_copy = &#39;&#39;.join(aligned_other)
        if len(self.aligned_with) != len(self.other_copy):
            raise RuntimeError(&#34;Mismatch in alignment lengths: check alignment logic.&#34;)
        self.mask = &#39;&#39;.join(&#39;=&#39; if a == b else &#39;*&#39; if b != &#39; &#39; and a != &#39; &#39; else &#39; &#39;
                            for a, b in zip(self.aligned_with, self.other_copy))
        self.ref_hash = hashlib.sha256(self.other_copy.encode()).hexdigest()
        self.engine = engine
        self.engineOpts[engine] = engineOpts
        return self.aligned_with, self.other_copy

    @property
    def alignment_stats(self):
        &#34;&#34;&#34;Retrun DNAstr alignment statistics&#34;&#34;&#34;
        if self.mask is None:
            raise ValueError(&#34;No alignment performed yet.&#34;)
        return {
            &#34;matches&#34;: self.mask.count(&#39;=&#39;),
            &#34;substitutions&#34;: self.mask.count(&#39;*&#39;),
            &#34;gaps&#34;: self.mask.count(&#39; &#39;)
        }

    @property
    def aligned_code(self):
        &#34;&#34;&#34;return aligned code&#34;&#34;&#34;
        if not hasattr(self,&#34;aligned_with&#34;) or self.aligned_with is None:
            raise ValueError(&#34;the code is not aligned&#34;)
        return re.sub(r&#39;[^A-CX-Z]&#39;, &#39;&#39;, self.aligned_with)

    def score(self, normalized=True):
        &#34;&#34;&#34;
        Return an alignment score, optionally normalized.

        Parameters
        ----------
        normalized : bool
            If True (default), return score as a fraction of total aligned positions.

        Returns
        -------
        float
            Alignment score.
        &#34;&#34;&#34;
        stats = self.alignment_stats
        score = stats[&#34;matches&#34;]
        return score / len(self.mask) if normalized else score

    @staticmethod
    def _supports_color():
        &#34;&#34;&#34;Returns True if ther terminal supports colors&#34;&#34;&#34;
        return hasattr(sys.stdout, &#34;isatty&#34;) and sys.stdout.isatty() and os.getenv(&#34;TERM&#34;) not in (None, &#34;dumb&#34;)

    def wrapped_alignment(self, width=80, colors=True):
        &#34;&#34;&#34;
        Return a line-wrapped alignment view (multi-line), optionally color-coded
        for terminal/IPython usage (Spyder, Jupyter).

        Parameters
        ----------
        width : int
            Number of characters per line in wrapped display.
        colors : bool
            If True, use ANSI codes to highlight differences. May be overridden
            if terminal does not support ANSI (e.g., Spyder).

        Returns
        -------
        str
            Wrapped, optionally colorized alignment.
        &#34;&#34;&#34;
        if self.aligned_with is None or self.other_copy is None:
            raise ValueError(&#34;Alignment has not been computed yet.&#34;)

        match_mask = self.mask
        s1 = self.other_copy
        s2 = self.aligned_with

        if colors and not DNAstr._supports_color():
            colors = False

        def colorize(c, match):
            if not colors:
                return c
            if c == &#39; &#39;:
                return &#39;\x1b[90m·\x1b[0m&#39;
            elif match == &#39;|&#39;:
                return f&#39;\x1b[92m{c}\x1b[0m&#39;
            else:
                return f&#39;\x1b[91m{c}\x1b[0m&#39;

        lines = []
        for i in range(0, len(s1), width):
            s1_block = s1[i:i+width]
            s2_block = s2[i:i+width]
            msk_block = match_mask[i:i+width]
            s1c = &#39;&#39;.join(colorize(c, m) for c, m in zip(s1_block, msk_block))
            s2c = &#39;&#39;.join(colorize(c, m) for c, m in zip(s2_block, msk_block))
            match_line = &#39;&#39;.join(&#39;|&#39; if m == &#39;=&#39; else &#39; &#39; for m in msk_block)
            lines.extend([s1c, match_line, s2c, &#39;&#39;])
        return &#39;\n&#39;.join(lines)

    def html_alignment(self):
        &#34;&#34;&#34;
        Render the alignment using HTML with color coding:
        - green: match
        - blue: gap
        - red: substitution

        Returns
        -------
        None
            Displays HTML directly in Jupyter/Notebook environments.
        &#34;&#34;&#34;
        if not self.aligned_with or not self.other_copy:
            raise ValueError(&#34;Alignment not available. Call .align() first.&#34;)
        html = &#34;&lt;pre style=&#39;font-family: monospace;&#39;&gt;&#34;
        for a, b in zip(self.other_copy, self.aligned_with):
            if a == b:
                html += f&#34;&lt;span style=&#39;color:green&#39;&gt;{b}&lt;/span&gt;&#34;
            elif a == &#39; &#39; or b == &#39; &#39;:
                html += f&#34;&lt;span style=&#39;color:blue&#39;&gt;{b}&lt;/span&gt;&#34;
            else:
                html += f&#34;&lt;span style=&#39;color:red&#39;&gt;{b}&lt;/span&gt;&#34;
        html += &#34;&lt;/pre&gt;&#34;
        display(HTML(html))

    def __repr__(self):
        &#34;&#34;&#34;
        Return a short technical representation of the DNAstr instance.

        Returns
        -------
        str
            Description of alignment status and length.
        &#34;&#34;&#34;
        base = f&#34;&lt;DNAstr: {len(self)} symbols&#34;
        if self.aligned_with:
            base += f&#34; - aligned against &lt;HASH {self.ref_hash[:8]}&gt;&gt;&#34;
        else:
            base += &#34; - not aligned&gt;&#34;
        return base

    def __str__(self):
        &#34;&#34;&#34;
        String representation.

        Returns
        -------
        str
            Original string content.
        &#34;&#34;&#34;
        #return repr(self) if self.aligned_with else str.__str__(self)
        return super().__str__()

    def find(self, pattern, regex=False):
        &#34;&#34;&#34;
        Finds all fuzzy (or regex-based) occurrences of a DNA-like sequence pattern.

        Parameters
        ----------
        pattern : str
            The symbolic sequence to search for (e.g., &#34;YAZB&#34;).
        regex : bool, optional
            If False (default), interprets pattern as symbolic and inserts &#39;.&#39; between characters.
            If True, uses the raw pattern as a regular expression.

        Returns
        -------
        list of DNAstr
            A list of DNAstr slices with attributes:
                - iloc: (start_idx, end_idx)
                - xloc: (x_start, x_end)
                - width: segment width
        &#34;&#34;&#34;
        if not regex:
            # Turn &#39;YAZB&#39; into &#39;Y+A+Z+B+?&#39;
            pattern = &#39;&#39;.join(f&#34;{c}+&#34; for c in pattern)  # Greedy
        matches = []
        for m in re.finditer(pattern, str(self)):
            start, end = m.span()
            substr = self[start:end]
            dna = DNAstr(substr,
                         dx=self.dx,
                         iloc=(start,end),
                         xloc=(self.xloc[0]+start*self.dx,self.xloc[0]+end*self.dx),
                         x_label=self.x_label, x_unit=self.x_unit)
            dna.iloc = (start, end)
            if hasattr(self, &#34;xloc&#34;) and self.xloc is not None:
                x_start = self.xloc[0] + self.dx * start
                x_end = self.xloc[0] + self.dx * end
                dna.xloc = (x_start, x_end)
            else:
                dna.xloc = (start * self.dx, end * self.dx)
            dna.width = end - start
            matches.append(dna)
        return matches


    def to_signal(self):
        &#34;&#34;&#34;
        Converts the symbolic DNA sequence into a synthetic NumPy array mimicking the original wavelet-transformed signal.

        Rules per letter:
            - &#39;A&#39;: Crosses zero upward → linear from -1 to +1, zero in the middle
            - &#39;Z&#39;: Crosses zero downward → linear from +1 to -1, zero in the middle
            - &#39;B&#39;: Increasing negative → from -1 to 0
            - &#39;Y&#39;: Decreasing negative → from 0 to -1
            - &#39;C&#39;: Increasing positive → from 0 to +1
            - &#39;X&#39;: Decreasing positive → from +1 to 0
            - &#39;_&#39;: Flat at 0

        Returns
        -------
        numpy.ndarray
            Synthetic signal array matching the symbolic encoding.
        &#34;&#34;&#34;
        s = []
        i = 0
        while i &lt; len(self):
            letter = self[i]
            j = i
            while j &lt; len(self) and self[j] == letter:
                j += 1
            width = j - i
            if width &lt; 2:
                i = j
                continue  # skip invalid segments
            if letter == &#39;A&#39;:
                seg = np.linspace(-1.0, 1.0, width)
            elif letter == &#39;Z&#39;:
                seg = np.linspace(1.0, -1.0, width)
            elif letter == &#39;B&#39;:
                seg = np.linspace(-1.0, 0, width)
            elif letter == &#39;Y&#39;:
                seg = np.linspace(0, -1.0, width)
            elif letter == &#39;C&#39;:
                seg = np.linspace(0, 1.0, width)
            elif letter == &#39;X&#39;:
                seg = np.linspace(1, 0, width)
            else:  # &#39;_&#39;
                seg = np.zeros(width)

            s.append(seg)
            i = j
        y = np.concatenate(s)
        if self.xloc is None:
            x = None
        else:
            n = len(y)
            x0 = self.xloc[0] if isinstance(self.xloc,(tuple,list)) else self.xloc
            x = np.linspace(x0,x0+self.dx*n,n,endpoint=True,dtype=type(x0))
        return signal(x=x,y=y,name=self._hash)

    def plot_mask(self):
        &#34;&#34;&#34;
        Plot a color-coded mask of the alignment between sequences.

        Returns
        -------
        matplotlib.figure.Figure
            Matplotlib figure of the alignment mask.
        &#34;&#34;&#34;
        if not self.other_copy:
            raise ValueError(&#34;Alignment required for plotting.&#34;)
        fig, ax = plt.subplots(figsize=(12, 2))
        colors = {&#39;=&#39;: &#39;green&#39;, &#39;*&#39;: &#39;red&#39;, &#39; &#39;: &#39;gray&#39;}
        for i, (a, b, m) in enumerate(zip(self.aligned_with, self.other_copy, self.mask)):
            ax.add_patch(Rectangle((i, 0), 1, 1, color=colors[m]))
        ax.set_xlim(0, len(self.aligned_with))
        ax.set_yticks([])
        ax.set_title(&#34;DNAstr Alignment Mask&#34;)
        ax.set_xlabel(&#34;Position&#34;)
        return fig

    def plot_alignment(self, dx=1.0, dy=1.0, width=20, normalize=True):
        &#34;&#34;&#34;
        Plot a block alignment view of two DNAstr sequences with color-coded segments.

        Parameters
        ----------
        dx : float
            Horizontal step between segments (defaults to 1.0).
        dy : float
            Vertical height increment for symbolic waveform visualization.
        width : int
            Number of characters per row (line wrapping).

        Returns
        -------
        matplotlib.figure.Figure
        matplotlib.axes.Axes
        &#34;&#34;&#34;
        if not self.other_copy:
            raise ValueError(&#34;Alignment required for plotting.&#34;)
        aligned_self, aligned_other, mask = self.aligned_with, self.other_copy, self.mask
        n = len(aligned_self)
        fig, ax = plt.subplots(figsize=(12, 3))

        def letter_to_height(letter, base=0):
            &#34;&#34;&#34;Simple deterministic up/down movement from symbolic codes.&#34;&#34;&#34;
            return base + {
                &#39;A&#39;: +1, &#39;B&#39;: +1, &#39;C&#39;: +1,
                &#39;X&#39;: -1, &#39;Y&#39;: -1, &#39;Z&#39;: -1,
                &#39;_&#39;: 0, &#39; &#39;: 0
            }.get(letter, 0) * dy

        x, y1, y2 = 0, -0.5, -4
        xs, ys1, ys2 = [0], [0], [y2]

        for i in range(n):
            ax.add_patch(Rectangle((x, y1), dx, dy, color=&#39;lightgreen&#39; if mask[i] == &#39;=&#39; else &#39;salmon&#39;, alpha=0.6))
            ys1.append(letter_to_height(aligned_self[i], ys1[-1]))
            ys2.append(letter_to_height(aligned_other[i], ys2[-1]))
            xs.append(x + dx)
            x += dx

        # Convert to numpy arrays and normalize
        if normalize:
            xs = np.array(xs)
            ys1 = np.array(ys1)
            ys2 = np.array(ys2)
            ymax = max(abs(ys1).max(), abs(ys2).max())
            scale = ymax if ymax&gt;1e-12 else 1.0
            ys1 = ys1 / scale
            ys2 = ys2 / scale

        ax.plot(xs, ys1, label=&#34;Self&#34;, color=&#34;DarkMagenta&#34;, linewidth=4)
        ax.plot(xs, ys2, label=&#34;Reference&#34;, color=&#34;DodgerBlue&#34;, linestyle=&#39;-&#39;, linewidth=4)

        ax.set_title(&#34;Waveform Alignment Visualization&#34;)
        ax.set_xlabel(&#34;Position&#34;)
        ax.set_ylabel(&#34;Symbolic Signal&#34;)
        ax.legend()
        ax.grid(True)
        plt.tight_layout()
        return fig, ax

    def extract_motifs(self, pattern=&#39;YAZB&#39;, minlen=4, plot=True):
        &#34;&#34;&#34;
        Extract and analyze YAZB motifs (canonical and distorted) from the symbolic sequence.

        Parameters
        ----------
        pattern : str
            Canonical motif pattern (default is &#39;YAZB&#39;).
        minlen : int
            Minimum motif length to be considered valid.
        plot : bool
            If True, generate a motif density plot using xloc or sequence index.

        Returns
        -------
        pd.DataFrame
            Table of detected motifs with start/end positions, length, and classification.
        &#34;&#34;&#34;
        sequence = str(self)
        canonical = pattern
        motif_re = re.compile(r&#39;Y+A+Z+B+&#39;)

        matches = []
        for m in motif_re.finditer(sequence):
            start, end = m.span()
            substr = m.group()
            motif_len = end - start
            canonical_match = substr == canonical
            classification = &#39;canonical&#39; if canonical_match else &#39;variant&#39;
            if motif_len &gt;= minlen:
                matches.append({
                    &#39;start&#39;: start,
                    &#39;end&#39;: end,
                    &#39;length&#39;: motif_len,
                    &#39;sequence&#39;: substr,
                    &#39;classification&#39;: classification
                })

        df = pd.DataFrame(matches)

        if plot and not df.empty:
            # Basic position handling
            if hasattr(self, &#39;xloc&#39;) and isinstance(self.xloc, (tuple, list)) and len(self.xloc) == 2:
                x0, x1 = self.xloc
                xspan = np.linspace(x0, x1, len(sequence)+1)
                df[&#39;x_start&#39;] = df[&#39;start&#39;].apply(lambda i: xspan[i])
                df[&#39;x_end&#39;] = df[&#39;end&#39;].apply(lambda i: xspan[i])
                xvals = xspan
            else:
                df[&#39;x_start&#39;] = df[&#39;start&#39;]
                df[&#39;x_end&#39;] = df[&#39;end&#39;]
                xvals = np.arange(len(sequence))

            fig, ax = plt.subplots(figsize=(12, 2.5))
            ax.plot(xvals, [1]*len(xvals), alpha=0.1)  # Background for alignment
            for _, row in df.iterrows():
                color = &#39;green&#39; if row[&#39;classification&#39;] == &#39;canonical&#39; else &#39;orange&#39;
                ax.axvspan(row[&#39;x_start&#39;], row[&#39;x_end&#39;], color=color, alpha=0.4)
            ax.set_title(f&#34;Motif Regions in `{getattr(self, &#39;_hash&#39;, &#39;DNAstr&#39;)}`&#34;)
            ax.set_yticks([])
            ax.set_xlabel(&#34;Position (xloc or index)&#34;)
            ax.set_xlim([xvals[0], xvals[-1]])
            ax.grid(True, axis=&#39;x&#39;, linestyle=&#39;--&#39;, alpha=0.3)
            plt.tight_layout()
            plt.show()
            return df,fig

        return df</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.str</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="signomics.DNAstr.aligned_code"><code class="name">var <span class="ident">aligned_code</span></code></dt>
<dd>
<div class="desc"><p>return aligned code</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def aligned_code(self):
    &#34;&#34;&#34;return aligned code&#34;&#34;&#34;
    if not hasattr(self,&#34;aligned_with&#34;) or self.aligned_with is None:
        raise ValueError(&#34;the code is not aligned&#34;)
    return re.sub(r&#39;[^A-CX-Z]&#39;, &#39;&#39;, self.aligned_with)</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.alignment_stats"><code class="name">var <span class="ident">alignment_stats</span></code></dt>
<dd>
<div class="desc"><p>Retrun DNAstr alignment statistics</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def alignment_stats(self):
    &#34;&#34;&#34;Retrun DNAstr alignment statistics&#34;&#34;&#34;
    if self.mask is None:
        raise ValueError(&#34;No alignment performed yet.&#34;)
    return {
        &#34;matches&#34;: self.mask.count(&#39;=&#39;),
        &#34;substitutions&#34;: self.mask.count(&#39;*&#39;),
        &#34;gaps&#34;: self.mask.count(&#39; &#39;)
    }</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.entropy"><code class="name">var <span class="ident">entropy</span></code></dt>
<dd>
<div class="desc"><p>Compute the Shannon entropy of the DNAstr sequence</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def entropy(self):
    &#34;&#34;&#34;Compute the Shannon entropy of the DNAstr sequence&#34;&#34;&#34;
    count = Counter(self)
    total = sum(count.values())
    return -sum((v / total) * np.log2(v / total) for v in count.values())</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.mutation_counts"><code class="name">var <span class="ident">mutation_counts</span></code></dt>
<dd>
<div class="desc"><p>Counts of insertions, deletions/substitutions, and matches.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def mutation_counts(self):
    &#34;&#34;&#34;Counts of insertions, deletions/substitutions, and matches.&#34;&#34;&#34;
    m = self.mask
    return {
        &#39;matches&#39;: m.count(&#39;=&#39;),
        &#39;mismatches&#39;: m.count(&#39;*&#39;),
        &#39;indels&#39;: m.count(&#39; &#39;)
    }</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="signomics.DNAstr.align"><code class="name flex">
<span>def <span class="ident">align</span></span>(<span>self, other, engine=None, engineOpts=None, forced=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Align this DNAstr sequence to another, allowing insertions/deletions to maximize matches.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code></dt>
<dd>Another DNAstr object to align with.</dd>
<dt><strong><code>engine</code></strong> :&ensp;<code>{'difflib', 'bio'}</code> or <code>None</code></dt>
<dd>Alignment engine to use:
- 'difflib': uses difflib.SequenceMatcher (fast, approximate).
- 'bio'
: uses Bio.Align.PairwiseAligner (biologically inspired global alignment).
If None, defaults to self.engine.</dd>
<dt><strong><code>engineOpts</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Dictionary of alignment parameters for the selected engine.</dd>
<dt><strong><code>forced</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, allow alignment even if <code>dx</code> values differ. If False (default), a mismatch in
<code>dx</code> will raise an error to prevent incorrect alignment of signals with different sampling.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>aligned_self</code></strong> :&ensp;<code>str</code></dt>
<dd>Aligned version of this sequence (with gaps inserted where needed).</dd>
<dt><strong><code>aligned_other</code></strong> :&ensp;<code>str</code></dt>
<dd>Aligned version of the other sequence.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>The alignment is symmetric and permanent: both sequences are aligned with
gaps introduced (spaces) to preserve positional correspondence. A hash of
the aligned <code>other</code> sequence is stored to detect redundant alignments.</p>
<p>A match mask (<code>self.mask</code>) is generated with:
'=' for exact matches,
'*' for mismatches (substitutions),
' ' for insertions/deletions (gaps).</p>
<p>The method updates:
- self.aligned_with
- self.other_copy
- self.mask
- self.ref_hash</p>
<h2 id="example">Example:</h2>
<p>S1 = DNAstr("AABBCC")
S2 = DNAstr("AACBCC")
S1.align(S2,"difflib")
print(S1.mask)
print(S1.wrapped_alignment())
==*===
AACBCC
|| |||
AABBCC</p>
<p>S1 = DNAstr("AABBCC")
S2 = DNAstr("AACBCC")
S1.align(S2,"bio")
print(S1.mask)
print(S1.wrapped_alignment())
==
==
AAB·CC
||
||
AA·BCC</p>
<p>S1 = DNAstr("AABBCCXYZZZ")
S2 = DNAstr("AACBCCZZXXX")
S1.align(S2,"bio")
print(S1.mask)
print(S1.wrapped_alignment())
== *
==
AABCC··ZZ
||
||
AA·B·CCZZ</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def align(self, other, engine=None, engineOpts=None, forced=False):
    &#34;&#34;&#34;
    Align this DNAstr sequence to another, allowing insertions/deletions to maximize matches.

    Parameters
    ----------
    other : DNAstr
        Another DNAstr object to align with.
    engine : {&#39;difflib&#39;, &#39;bio&#39;} or None
        Alignment engine to use:
            - &#39;difflib&#39;: uses difflib.SequenceMatcher (fast, approximate).
            - &#39;bio&#39;   : uses Bio.Align.PairwiseAligner (biologically inspired global alignment).
        If None, defaults to self.engine.
    engineOpts : dict, optional
        Dictionary of alignment parameters for the selected engine.
    forced : bool
        If True, allow alignment even if `dx` values differ. If False (default), a mismatch in
        `dx` will raise an error to prevent incorrect alignment of signals with different sampling.

    Returns
    -------
    aligned_self : str
        Aligned version of this sequence (with gaps inserted where needed).
    aligned_other : str
        Aligned version of the other sequence.

    Notes
    -----
    The alignment is symmetric and permanent: both sequences are aligned with
    gaps introduced (spaces) to preserve positional correspondence. A hash of
    the aligned `other` sequence is stored to detect redundant alignments.

    A match mask (`self.mask`) is generated with:
        &#39;=&#39; for exact matches,
        &#39;*&#39; for mismatches (substitutions),
        &#39; &#39; for insertions/deletions (gaps).

    The method updates:
        - self.aligned_with
        - self.other_copy
        - self.mask
        - self.ref_hash

    Example:
    --------
    S1 = DNAstr(&#34;AABBCC&#34;)
    S2 = DNAstr(&#34;AACBCC&#34;)
    S1.align(S2,&#34;difflib&#34;)
    print(S1.mask)
    print(S1.wrapped_alignment())
    ==*===
    AACBCC
    || |||
    AABBCC

    S1 = DNAstr(&#34;AABBCC&#34;)
    S2 = DNAstr(&#34;AACBCC&#34;)
    S1.align(S2,&#34;bio&#34;)
    print(S1.mask)
    print(S1.wrapped_alignment())
    ==  ==
    AAB·CC
    ||  ||
    AA·BCC

    S1 = DNAstr(&#34;AABBCCXYZZZ&#34;)
    S2 = DNAstr(&#34;AACBCCZZXXX&#34;)
    S1.align(S2,&#34;bio&#34;)
    print(S1.mask)
    print(S1.wrapped_alignment())
    == *   ==
    AABCC··ZZ
    ||     ||
    AA·B·CCZZ

    &#34;&#34;&#34;
    if not isinstance(other, DNAstr):
        raise TypeError(&#34;Alignment requires another DNAstr instance&#34;)
    if not forced and self.dx != other.dx:
        raise ValueError(&#34;dx mismatch. Use forced=True to override.&#34;)
    if hasattr(other, &#39;ref_hash&#39;) and self.ref_hash is not None and self.ref_hash == other.ref_hash:
        return self.aligned_with, self.other_copy

    engine = engine or self.engine
    engineOpts = engineOpts or self.engineOpts.get(engine, {})

    if engine == &#39;difflib&#39;:
        sm = SequenceMatcher(None, other, self)
        aligned_self, aligned_other = [], []
        for tag, i1, i2, j1, j2 in sm.get_opcodes():
            if tag == &#39;equal&#39;:
                aligned_self.extend(self[j1:j2])
                aligned_other.extend(other[i1:i2])
            elif tag == &#39;replace&#39;:
                aligned_self.extend(self[j1:j2])
                aligned_other.extend(other[i1:i2])
            elif tag == &#39;insert&#39;:
                aligned_self.extend(self[j1:j2])
                aligned_other.extend(&#39; &#39; * (j2 - j1))
            elif tag == &#39;delete&#39;:
                aligned_self.extend(&#39; &#39; * (i2 - i1))
                aligned_other.extend(other[i1:i2])

    elif engine == &#39;bio&#39;:
        aligner = PairwiseAligner()
        for k, v in engineOpts.items():
            setattr(aligner, k, v)

        alignment = aligner.align(other, self)[0]  # Best alignment
        aligned_self = []
        aligned_other = []

        # These are lists of (start, end) index tuples for each sequence
        self_blocks = alignment.aligned[1]
        other_blocks = alignment.aligned[0]

        self_pos = 0
        other_pos = 0

        for (o_start, o_end), (s_start, s_end) in zip(other_blocks, self_blocks):
            # Fill gaps in other
            if o_start &gt; other_pos:
                gap_len = o_start - other_pos
                aligned_other.extend(other[other_pos:o_start])
                aligned_self.extend([&#39; &#39;] * gap_len)
                other_pos = o_start
            # Fill gaps in self
            if s_start &gt; self_pos:
                gap_len = s_start - self_pos
                aligned_self.extend(self[self_pos:s_start])
                aligned_other.extend([&#39; &#39;] * gap_len)
                self_pos = s_start

            # Aligned regions
            aligned_self.extend(self[s_start:s_end])
            aligned_other.extend(other[o_start:o_end])
            self_pos = s_end
            other_pos = o_end

        # Tail padding
        aligned_self.extend(self[self_pos:])
        aligned_other.extend([&#39; &#39;] * (len(self) - self_pos))
        aligned_other.extend(other[other_pos:])
        aligned_self.extend([&#39; &#39;] * (len(other) - other_pos))

    else:
        raise ValueError(&#34;Unknown alignment engine: choose &#39;difflib&#39; or &#39;bio&#39;&#34;)

    self.aligned_with = &#39;&#39;.join(aligned_self)
    self.other_copy = &#39;&#39;.join(aligned_other)
    if len(self.aligned_with) != len(self.other_copy):
        raise RuntimeError(&#34;Mismatch in alignment lengths: check alignment logic.&#34;)
    self.mask = &#39;&#39;.join(&#39;=&#39; if a == b else &#39;*&#39; if b != &#39; &#39; and a != &#39; &#39; else &#39; &#39;
                        for a, b in zip(self.aligned_with, self.other_copy))
    self.ref_hash = hashlib.sha256(self.other_copy.encode()).hexdigest()
    self.engine = engine
    self.engineOpts[engine] = engineOpts
    return self.aligned_with, self.other_copy</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.excess_entropy"><code class="name flex">
<span>def <span class="ident">excess_entropy</span></span>(<span>self, other)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the excess Shannon entropy of two DNAstr sequences H(A)+H(B)-2*H(AB)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def excess_entropy(self, other):
    &#34;&#34;&#34;Compute the excess Shannon entropy of two DNAstr sequences H(A)+H(B)-2*H(AB)&#34;&#34;&#34;
    return self.entropy + other.entropy - 2 * self.mutual_entropy(other)</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.extract_motifs"><code class="name flex">
<span>def <span class="ident">extract_motifs</span></span>(<span>self, pattern='YAZB', minlen=4, plot=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Extract and analyze YAZB motifs (canonical and distorted) from the symbolic sequence.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pattern</code></strong> :&ensp;<code>str</code></dt>
<dd>Canonical motif pattern (default is 'YAZB').</dd>
<dt><strong><code>minlen</code></strong> :&ensp;<code>int</code></dt>
<dd>Minimum motif length to be considered valid.</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, generate a motif density plot using xloc or sequence index.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>Table of detected motifs with start/end positions, length, and classification.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_motifs(self, pattern=&#39;YAZB&#39;, minlen=4, plot=True):
    &#34;&#34;&#34;
    Extract and analyze YAZB motifs (canonical and distorted) from the symbolic sequence.

    Parameters
    ----------
    pattern : str
        Canonical motif pattern (default is &#39;YAZB&#39;).
    minlen : int
        Minimum motif length to be considered valid.
    plot : bool
        If True, generate a motif density plot using xloc or sequence index.

    Returns
    -------
    pd.DataFrame
        Table of detected motifs with start/end positions, length, and classification.
    &#34;&#34;&#34;
    sequence = str(self)
    canonical = pattern
    motif_re = re.compile(r&#39;Y+A+Z+B+&#39;)

    matches = []
    for m in motif_re.finditer(sequence):
        start, end = m.span()
        substr = m.group()
        motif_len = end - start
        canonical_match = substr == canonical
        classification = &#39;canonical&#39; if canonical_match else &#39;variant&#39;
        if motif_len &gt;= minlen:
            matches.append({
                &#39;start&#39;: start,
                &#39;end&#39;: end,
                &#39;length&#39;: motif_len,
                &#39;sequence&#39;: substr,
                &#39;classification&#39;: classification
            })

    df = pd.DataFrame(matches)

    if plot and not df.empty:
        # Basic position handling
        if hasattr(self, &#39;xloc&#39;) and isinstance(self.xloc, (tuple, list)) and len(self.xloc) == 2:
            x0, x1 = self.xloc
            xspan = np.linspace(x0, x1, len(sequence)+1)
            df[&#39;x_start&#39;] = df[&#39;start&#39;].apply(lambda i: xspan[i])
            df[&#39;x_end&#39;] = df[&#39;end&#39;].apply(lambda i: xspan[i])
            xvals = xspan
        else:
            df[&#39;x_start&#39;] = df[&#39;start&#39;]
            df[&#39;x_end&#39;] = df[&#39;end&#39;]
            xvals = np.arange(len(sequence))

        fig, ax = plt.subplots(figsize=(12, 2.5))
        ax.plot(xvals, [1]*len(xvals), alpha=0.1)  # Background for alignment
        for _, row in df.iterrows():
            color = &#39;green&#39; if row[&#39;classification&#39;] == &#39;canonical&#39; else &#39;orange&#39;
            ax.axvspan(row[&#39;x_start&#39;], row[&#39;x_end&#39;], color=color, alpha=0.4)
        ax.set_title(f&#34;Motif Regions in `{getattr(self, &#39;_hash&#39;, &#39;DNAstr&#39;)}`&#34;)
        ax.set_yticks([])
        ax.set_xlabel(&#34;Position (xloc or index)&#34;)
        ax.set_xlim([xvals[0], xvals[-1]])
        ax.grid(True, axis=&#39;x&#39;, linestyle=&#39;--&#39;, alpha=0.3)
        plt.tight_layout()
        plt.show()
        return df,fig

    return df</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.find"><code class="name flex">
<span>def <span class="ident">find</span></span>(<span>self, pattern, regex=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds all fuzzy (or regex-based) occurrences of a DNA-like sequence pattern.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>pattern</code></strong> :&ensp;<code>str</code></dt>
<dd>The symbolic sequence to search for (e.g., "YAZB").</dd>
<dt><strong><code>regex</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If False (default), interprets pattern as symbolic and inserts '.' between characters.
If True, uses the raw pattern as a regular expression.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code></dt>
<dd>A list of DNAstr slices with attributes:
- iloc: (start_idx, end_idx)
- xloc: (x_start, x_end)
- width: segment width</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find(self, pattern, regex=False):
    &#34;&#34;&#34;
    Finds all fuzzy (or regex-based) occurrences of a DNA-like sequence pattern.

    Parameters
    ----------
    pattern : str
        The symbolic sequence to search for (e.g., &#34;YAZB&#34;).
    regex : bool, optional
        If False (default), interprets pattern as symbolic and inserts &#39;.&#39; between characters.
        If True, uses the raw pattern as a regular expression.

    Returns
    -------
    list of DNAstr
        A list of DNAstr slices with attributes:
            - iloc: (start_idx, end_idx)
            - xloc: (x_start, x_end)
            - width: segment width
    &#34;&#34;&#34;
    if not regex:
        # Turn &#39;YAZB&#39; into &#39;Y+A+Z+B+?&#39;
        pattern = &#39;&#39;.join(f&#34;{c}+&#34; for c in pattern)  # Greedy
    matches = []
    for m in re.finditer(pattern, str(self)):
        start, end = m.span()
        substr = self[start:end]
        dna = DNAstr(substr,
                     dx=self.dx,
                     iloc=(start,end),
                     xloc=(self.xloc[0]+start*self.dx,self.xloc[0]+end*self.dx),
                     x_label=self.x_label, x_unit=self.x_unit)
        dna.iloc = (start, end)
        if hasattr(self, &#34;xloc&#34;) and self.xloc is not None:
            x_start = self.xloc[0] + self.dx * start
            x_end = self.xloc[0] + self.dx * end
            dna.xloc = (x_start, x_end)
        else:
            dna.xloc = (start * self.dx, end * self.dx)
        dna.width = end - start
        matches.append(dna)
    return matches</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.html_alignment"><code class="name flex">
<span>def <span class="ident">html_alignment</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Render the alignment using HTML with color coding:
- green: match
- blue: gap
- red: substitution</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>Displays HTML directly in Jupyter/Notebook environments.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def html_alignment(self):
    &#34;&#34;&#34;
    Render the alignment using HTML with color coding:
    - green: match
    - blue: gap
    - red: substitution

    Returns
    -------
    None
        Displays HTML directly in Jupyter/Notebook environments.
    &#34;&#34;&#34;
    if not self.aligned_with or not self.other_copy:
        raise ValueError(&#34;Alignment not available. Call .align() first.&#34;)
    html = &#34;&lt;pre style=&#39;font-family: monospace;&#39;&gt;&#34;
    for a, b in zip(self.other_copy, self.aligned_with):
        if a == b:
            html += f&#34;&lt;span style=&#39;color:green&#39;&gt;{b}&lt;/span&gt;&#34;
        elif a == &#39; &#39; or b == &#39; &#39;:
            html += f&#34;&lt;span style=&#39;color:blue&#39;&gt;{b}&lt;/span&gt;&#34;
        else:
            html += f&#34;&lt;span style=&#39;color:red&#39;&gt;{b}&lt;/span&gt;&#34;
    html += &#34;&lt;/pre&gt;&#34;
    display(HTML(html))</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.jaccard"><code class="name flex">
<span>def <span class="ident">jaccard</span></span>(<span>self, other)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the Jaccard distance between two DNAstr sequences.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code></dt>
<dd>The other DNAstr sequence to compare with.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>Jaccard distance: 1 - (intersection / union) of unique letters.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def jaccard(self, other):
    &#34;&#34;&#34;
    Compute the Jaccard distance between two DNAstr sequences.

    Parameters
    ----------
    other : DNAstr
        The other DNAstr sequence to compare with.

    Returns
    -------
    float
        Jaccard distance: 1 - (intersection / union) of unique letters.
    &#34;&#34;&#34;
    set_self = set(self)
    set_other = set(other)
    intersection = set_self &amp; set_other
    union = set_self | set_other
    return 1 - len(intersection) / len(union) if union else 0.0</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.jensen_shannon"><code class="name flex">
<span>def <span class="ident">jensen_shannon</span></span>(<span>self, other, base=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the Jensen-Shannon distance between self and another DNAstr.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code></dt>
<dd>Another DNAstr instance.</dd>
<dt><strong><code>base</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Base for the logarithm (default: 2)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>Jensen-Shannon distance.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def jensen_shannon(self, other, base=2):
    &#34;&#34;&#34;
    Compute the Jensen-Shannon distance between self and another DNAstr.

    Parameters
    ----------
    other : DNAstr
        Another DNAstr instance.
    base : float, optional
        Base for the logarithm (default: 2)

    Returns
    -------
    float
        Jensen-Shannon distance.
    &#34;&#34;&#34;
    v1 = Counter(self)
    v2 = Counter(other)
    all_keys = sorted(set(v1) | set(v2))
    p = np.array([v1.get(k, 0) for k in all_keys], dtype=float)
    q = np.array([v2.get(k, 0) for k in all_keys], dtype=float)
    p /= p.sum()
    q /= q.sum()
    return jensenshannon(p, q, base=base)</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.levenshtein"><code class="name flex">
<span>def <span class="ident">levenshtein</span></span>(<span>self, other, use_alignment=True, engine=None, engineOpts=None, forced=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the Levenshtein distance between this DNAstr and another one.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>other</code></strong> :&ensp;<code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code></dt>
<dd>Another DNAstr object to compare against.</dd>
<dt><strong><code>use_alignment</code></strong> :&ensp;<code>bool</code>, default=<code>True</code></dt>
<dd>If True, uses the aligned sequences (computed if necessary).
If False, compares the raw sequences directly.</dd>
<dt><strong><code>engine</code></strong> :&ensp;<code>{'difflib', 'bio'}</code>, optional</dt>
<dd>Alignment engine to use if alignment is needed.</dd>
<dt><strong><code>engineOpts</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Parameters for the selected alignment engine.</dd>
<dt><strong><code>forced</code></strong> :&ensp;<code>bool</code>, default=<code>False</code></dt>
<dd>Force alignment even if dx values differ.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dist</code></strong> :&ensp;<code>int</code></dt>
<dd>Levenshtein distance between the two sequences (aligned or raw).</dd>
</dl>
<h2 id="examples">Examples</h2>
<p>A = DNAstr("YAZBZAY")
B = DNAstr("YAZBZZY")
A.levenshtein_distance(B, use_alignment=False)
# raw
A.levenshtein_distance(B, use_alignment=True, engine="bio")
# aligned</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def levenshtein(self, other, use_alignment=True, engine=None, engineOpts=None, forced=False):
    &#34;&#34;&#34;
    Compute the Levenshtein distance between this DNAstr and another one.

    Parameters
    ----------
    other : DNAstr
        Another DNAstr object to compare against.
    use_alignment : bool, default=True
        If True, uses the aligned sequences (computed if necessary).
        If False, compares the raw sequences directly.
    engine : {&#39;difflib&#39;, &#39;bio&#39;}, optional
        Alignment engine to use if alignment is needed.
    engineOpts : dict, optional
        Parameters for the selected alignment engine.
    forced : bool, default=False
        Force alignment even if dx values differ.

    Returns
    -------
    dist : int
        Levenshtein distance between the two sequences (aligned or raw).

    Examples
    --------
    A = DNAstr(&#34;YAZBZAY&#34;)
    B = DNAstr(&#34;YAZBZZY&#34;)
    A.levenshtein_distance(B, use_alignment=False)  # raw
    A.levenshtein_distance(B, use_alignment=True, engine=&#34;bio&#34;)  # aligned
    &#34;&#34;&#34;
    if not isinstance(other, DNAstr):
        raise TypeError(&#34;Argument must be a DNAstr instance&#34;)
    if use_alignment:
        self.align(other, engine=engine, engineOpts=engineOpts, forced=forced)
        s1, s2 = self.aligned_with, self.other_copy
    else:
        s1, s2 = str(self), str(other)
    return Levenshtein.distance(s1, s2)</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.mutual_entropy"><code class="name flex">
<span>def <span class="ident">mutual_entropy</span></span>(<span>self, other=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the Shannon mutual entropy of two DNAstr sequences from their aligned segments</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mutual_entropy(self, other=None):
    &#34;&#34;&#34;Compute the Shannon mutual entropy of two DNAstr sequences from their aligned segments&#34;&#34;&#34;
    if other is not None and not isinstance(other,DNAstr):
        raise TypeError(f&#34;other must be a DNAstr not a {type(self).__name__}&#34;)
    if other is None and (not hasattr(self,&#34;aligned_with&#34;) or self.aligned_with is None):
        raise ValueError(&#34;align the code with .align(other) or provide other&#34;)
    if isinstance(other,DNAstr):
        self.align(other)
    aligned = self.aligned_code
    count = Counter(aligned)
    total = sum(count.values())
    return -sum((v / total) * np.log2(v / total) for v in count.values())</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.plot_alignment"><code class="name flex">
<span>def <span class="ident">plot_alignment</span></span>(<span>self, dx=1.0, dy=1.0, width=20, normalize=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot a block alignment view of two DNAstr sequences with color-coded segments.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dx</code></strong> :&ensp;<code>float</code></dt>
<dd>Horizontal step between segments (defaults to 1.0).</dd>
<dt><strong><code>dy</code></strong> :&ensp;<code>float</code></dt>
<dd>Vertical height increment for symbolic waveform visualization.</dd>
<dt><strong><code>width</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of characters per row (line wrapping).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>matplotlib.figure.Figure</code></dt>
<dd>&nbsp;</dd>
<dt><code>matplotlib.axes.Axes</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_alignment(self, dx=1.0, dy=1.0, width=20, normalize=True):
    &#34;&#34;&#34;
    Plot a block alignment view of two DNAstr sequences with color-coded segments.

    Parameters
    ----------
    dx : float
        Horizontal step between segments (defaults to 1.0).
    dy : float
        Vertical height increment for symbolic waveform visualization.
    width : int
        Number of characters per row (line wrapping).

    Returns
    -------
    matplotlib.figure.Figure
    matplotlib.axes.Axes
    &#34;&#34;&#34;
    if not self.other_copy:
        raise ValueError(&#34;Alignment required for plotting.&#34;)
    aligned_self, aligned_other, mask = self.aligned_with, self.other_copy, self.mask
    n = len(aligned_self)
    fig, ax = plt.subplots(figsize=(12, 3))

    def letter_to_height(letter, base=0):
        &#34;&#34;&#34;Simple deterministic up/down movement from symbolic codes.&#34;&#34;&#34;
        return base + {
            &#39;A&#39;: +1, &#39;B&#39;: +1, &#39;C&#39;: +1,
            &#39;X&#39;: -1, &#39;Y&#39;: -1, &#39;Z&#39;: -1,
            &#39;_&#39;: 0, &#39; &#39;: 0
        }.get(letter, 0) * dy

    x, y1, y2 = 0, -0.5, -4
    xs, ys1, ys2 = [0], [0], [y2]

    for i in range(n):
        ax.add_patch(Rectangle((x, y1), dx, dy, color=&#39;lightgreen&#39; if mask[i] == &#39;=&#39; else &#39;salmon&#39;, alpha=0.6))
        ys1.append(letter_to_height(aligned_self[i], ys1[-1]))
        ys2.append(letter_to_height(aligned_other[i], ys2[-1]))
        xs.append(x + dx)
        x += dx

    # Convert to numpy arrays and normalize
    if normalize:
        xs = np.array(xs)
        ys1 = np.array(ys1)
        ys2 = np.array(ys2)
        ymax = max(abs(ys1).max(), abs(ys2).max())
        scale = ymax if ymax&gt;1e-12 else 1.0
        ys1 = ys1 / scale
        ys2 = ys2 / scale

    ax.plot(xs, ys1, label=&#34;Self&#34;, color=&#34;DarkMagenta&#34;, linewidth=4)
    ax.plot(xs, ys2, label=&#34;Reference&#34;, color=&#34;DodgerBlue&#34;, linestyle=&#39;-&#39;, linewidth=4)

    ax.set_title(&#34;Waveform Alignment Visualization&#34;)
    ax.set_xlabel(&#34;Position&#34;)
    ax.set_ylabel(&#34;Symbolic Signal&#34;)
    ax.legend()
    ax.grid(True)
    plt.tight_layout()
    return fig, ax</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.plot_mask"><code class="name flex">
<span>def <span class="ident">plot_mask</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot a color-coded mask of the alignment between sequences.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>matplotlib.figure.Figure</code></dt>
<dd>Matplotlib figure of the alignment mask.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_mask(self):
    &#34;&#34;&#34;
    Plot a color-coded mask of the alignment between sequences.

    Returns
    -------
    matplotlib.figure.Figure
        Matplotlib figure of the alignment mask.
    &#34;&#34;&#34;
    if not self.other_copy:
        raise ValueError(&#34;Alignment required for plotting.&#34;)
    fig, ax = plt.subplots(figsize=(12, 2))
    colors = {&#39;=&#39;: &#39;green&#39;, &#39;*&#39;: &#39;red&#39;, &#39; &#39;: &#39;gray&#39;}
    for i, (a, b, m) in enumerate(zip(self.aligned_with, self.other_copy, self.mask)):
        ax.add_patch(Rectangle((i, 0), 1, 1, color=colors[m]))
    ax.set_xlim(0, len(self.aligned_with))
    ax.set_yticks([])
    ax.set_title(&#34;DNAstr Alignment Mask&#34;)
    ax.set_xlabel(&#34;Position&#34;)
    return fig</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.score"><code class="name flex">
<span>def <span class="ident">score</span></span>(<span>self, normalized=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return an alignment score, optionally normalized.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>normalized</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True (default), return score as a fraction of total aligned positions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>Alignment score.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def score(self, normalized=True):
    &#34;&#34;&#34;
    Return an alignment score, optionally normalized.

    Parameters
    ----------
    normalized : bool
        If True (default), return score as a fraction of total aligned positions.

    Returns
    -------
    float
        Alignment score.
    &#34;&#34;&#34;
    stats = self.alignment_stats
    score = stats[&#34;matches&#34;]
    return score / len(self.mask) if normalized else score</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.summary"><code class="name flex">
<span>def <span class="ident">summary</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Summarize the DNAstr with key stats: length, unique letters, entropy, etc.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Dictionary containing length, letter frequency, Shannon entropy, and dx.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def summary(self):
    &#34;&#34;&#34;
    Summarize the DNAstr with key stats: length, unique letters, entropy, etc.

    Returns
    -------
    dict
        Dictionary containing length, letter frequency, Shannon entropy, and dx.
    &#34;&#34;&#34;
    length = len(self)
    freqs = Counter(self)
    prob = np.array(list(freqs.values())) / length
    entropy = -np.sum(prob * np.log2(prob))
    return {
        &#39;length&#39;: length,
        &#39;letters&#39;: dict(freqs),
        &#39;entropy (Shannon)&#39;: entropy,
        &#39;dx&#39;: self.dx
    }</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.to_signal"><code class="name flex">
<span>def <span class="ident">to_signal</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts the symbolic DNA sequence into a synthetic NumPy array mimicking the original wavelet-transformed signal.</p>
<p>Rules per letter:
- 'A': Crosses zero upward → linear from -1 to +1, zero in the middle
- 'Z': Crosses zero downward → linear from +1 to -1, zero in the middle
- 'B': Increasing negative → from -1 to 0
- 'Y': Decreasing negative → from 0 to -1
- 'C': Increasing positive → from 0 to +1
- 'X': Decreasing positive → from +1 to 0
- '_': Flat at 0</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy.ndarray</code></dt>
<dd>Synthetic signal array matching the symbolic encoding.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_signal(self):
    &#34;&#34;&#34;
    Converts the symbolic DNA sequence into a synthetic NumPy array mimicking the original wavelet-transformed signal.

    Rules per letter:
        - &#39;A&#39;: Crosses zero upward → linear from -1 to +1, zero in the middle
        - &#39;Z&#39;: Crosses zero downward → linear from +1 to -1, zero in the middle
        - &#39;B&#39;: Increasing negative → from -1 to 0
        - &#39;Y&#39;: Decreasing negative → from 0 to -1
        - &#39;C&#39;: Increasing positive → from 0 to +1
        - &#39;X&#39;: Decreasing positive → from +1 to 0
        - &#39;_&#39;: Flat at 0

    Returns
    -------
    numpy.ndarray
        Synthetic signal array matching the symbolic encoding.
    &#34;&#34;&#34;
    s = []
    i = 0
    while i &lt; len(self):
        letter = self[i]
        j = i
        while j &lt; len(self) and self[j] == letter:
            j += 1
        width = j - i
        if width &lt; 2:
            i = j
            continue  # skip invalid segments
        if letter == &#39;A&#39;:
            seg = np.linspace(-1.0, 1.0, width)
        elif letter == &#39;Z&#39;:
            seg = np.linspace(1.0, -1.0, width)
        elif letter == &#39;B&#39;:
            seg = np.linspace(-1.0, 0, width)
        elif letter == &#39;Y&#39;:
            seg = np.linspace(0, -1.0, width)
        elif letter == &#39;C&#39;:
            seg = np.linspace(0, 1.0, width)
        elif letter == &#39;X&#39;:
            seg = np.linspace(1, 0, width)
        else:  # &#39;_&#39;
            seg = np.zeros(width)

        s.append(seg)
        i = j
    y = np.concatenate(s)
    if self.xloc is None:
        x = None
    else:
        n = len(y)
        x0 = self.xloc[0] if isinstance(self.xloc,(tuple,list)) else self.xloc
        x = np.linspace(x0,x0+self.dx*n,n,endpoint=True,dtype=type(x0))
    return signal(x=x,y=y,name=self._hash)</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.vectorized"><code class="name flex">
<span>def <span class="ident">vectorized</span></span>(<span>self, codebook={'A': 1, 'B': 2, 'C': 3, 'X': 4, 'Y': 5, 'Z': 6, '_': 0})</span>
</code></dt>
<dd>
<div class="desc"><p>Map the DNAstr content to an integer array using a codebook.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>codebook</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Dictionary mapping characters to integer values.
default = {"A":1,"B":2,"C":3,"X":4,"Y":5,"Z":6,"_":0}
None will generate a codebook based on current symbols only</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Vectorized integer representation of the string.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vectorized(self, codebook={&#34;A&#34;:1,&#34;B&#34;:2,&#34;C&#34;:3,&#34;X&#34;:4,&#34;Y&#34;:5,&#34;Z&#34;:6,&#34;_&#34;:0}):
    &#34;&#34;&#34;
    Map the DNAstr content to an integer array using a codebook.

    Parameters
    ----------
    codebook : dict, optional
        Dictionary mapping characters to integer values.
        default = {&#34;A&#34;:1,&#34;B&#34;:2,&#34;C&#34;:3,&#34;X&#34;:4,&#34;Y&#34;:5,&#34;Z&#34;:6,&#34;_&#34;:0}
        None will generate a codebook based on current symbols only

    Returns
    -------
    np.ndarray
        Vectorized integer representation of the string.
    &#34;&#34;&#34;
    from collections import OrderedDict
    if codebook is None:
        unique_chars = list(OrderedDict.fromkeys(self))
        codebook = {c: i for i, c in enumerate(unique_chars)}
    return np.array([codebook.get(c, -1) for c in self], dtype=int)</code></pre>
</details>
</dd>
<dt id="signomics.DNAstr.wrapped_alignment"><code class="name flex">
<span>def <span class="ident">wrapped_alignment</span></span>(<span>self, width=80, colors=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a line-wrapped alignment view (multi-line), optionally color-coded
for terminal/IPython usage (Spyder, Jupyter).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>width</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of characters per line in wrapped display.</dd>
<dt><strong><code>colors</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, use ANSI codes to highlight differences. May be overridden
if terminal does not support ANSI (e.g., Spyder).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Wrapped, optionally colorized alignment.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wrapped_alignment(self, width=80, colors=True):
    &#34;&#34;&#34;
    Return a line-wrapped alignment view (multi-line), optionally color-coded
    for terminal/IPython usage (Spyder, Jupyter).

    Parameters
    ----------
    width : int
        Number of characters per line in wrapped display.
    colors : bool
        If True, use ANSI codes to highlight differences. May be overridden
        if terminal does not support ANSI (e.g., Spyder).

    Returns
    -------
    str
        Wrapped, optionally colorized alignment.
    &#34;&#34;&#34;
    if self.aligned_with is None or self.other_copy is None:
        raise ValueError(&#34;Alignment has not been computed yet.&#34;)

    match_mask = self.mask
    s1 = self.other_copy
    s2 = self.aligned_with

    if colors and not DNAstr._supports_color():
        colors = False

    def colorize(c, match):
        if not colors:
            return c
        if c == &#39; &#39;:
            return &#39;\x1b[90m·\x1b[0m&#39;
        elif match == &#39;|&#39;:
            return f&#39;\x1b[92m{c}\x1b[0m&#39;
        else:
            return f&#39;\x1b[91m{c}\x1b[0m&#39;

    lines = []
    for i in range(0, len(s1), width):
        s1_block = s1[i:i+width]
        s2_block = s2[i:i+width]
        msk_block = match_mask[i:i+width]
        s1c = &#39;&#39;.join(colorize(c, m) for c, m in zip(s1_block, msk_block))
        s2c = &#39;&#39;.join(colorize(c, m) for c, m in zip(s2_block, msk_block))
        match_line = &#39;&#39;.join(&#39;|&#39; if m == &#39;=&#39; else &#39; &#39; for m in msk_block)
        lines.extend([s1c, match_line, s2c, &#39;&#39;])
    return &#39;\n&#39;.join(lines)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="signomics.generator"><code class="flex name class">
<span>class <span class="ident">generator</span></span>
<span>(</span><span>kind='gauss')</span>
</code></dt>
<dd>
<div class="desc"><p>define a peak generator gauss/lorentz/triangle</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class generator:
    def __init__(self, kind=&#34;gauss&#34;):
        &#34;&#34;&#34;define a peak generator gauss/lorentz/triangle&#34;&#34;&#34;
        self.kind = kind.lower()

    def __call__(self, x, x0, w, h):
        if self.kind.startswith(&#34;gauss&#34;): #simplified Gaussian kernel
            # area: 0.6006*sqrt(pi)*w*h
            # standard deviation: 0.6006/sqrt(2)*w
            return h * np.exp(-((x - x0) / (0.6006 * w)) ** 2)
        elif self.kind.startswith(&#34;lorentz&#34;):
            return  h * 1/(1+((x-x0) / (0.5*w)) ** 2)
        elif self.kind.startswith(&#34;triang&#34;):
            d = np.abs(x - x0)
            return h * np.maximum(1 - d / (0.6006 * w), 0)
        else:
            raise ValueError(f&#34;Unknown generator kind: {self.kind}&#34;)

    def __repr__(self):
        return f&#34;&lt;generator kind=&#39;{self.kind}&#39;&gt;&#34;</code></pre>
</details>
</dd>
<dt id="signomics.peaks"><code class="flex name class">
<span>class <span class="ident">peaks</span></span>
<span>(</span><span>data=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A class for managing a collection of peak definitions used in synthetic signal generation.</p>
<p>Each peak is represented as a dictionary with the following fields:
- 'name' (str): unique identifier (autogenerated if not provided)
- 'x' (float): center position (e.g., time, wavenumber, index)
- 'w' (float): width (related to FWHM)
- 'h' (float): peak height
- 'type' (str): generator type (e.g., 'gauss', 'lorentz', 'triangle')</p>
<p>Supports:
- Flexible addition and broadcasting of peak parameters
- Named or indexed access to individual or multiple peaks
- Overloaded operators for peak translation and scaling
- Utility methods: update, sort, rename, remove_duplicates, copy
- Conversion to signal object via <code>.to_signal()</code>
- Informative <strong>str</strong> and <strong>repr</strong> output</p>
<p>This class is used to build reproducible and structured test cases for symbolic encoding (e.g., sig2dna).</p>
<p>Initialize a peak collection.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>list</code> of <code>dict, list</code> of <code><a title="signomics.peaks" href="#signomics.peaks">peaks</a>,</code> or <code>None</code></dt>
<dd>
<ul>
<li>If None: create an empty peaks object.</li>
<li>If list of dict: must contain at least 'x', 'w', 'h'; 'name' and 'type' are optional.</li>
<li>If list of peaks: flattens into a single collection.</li>
</ul>
<p>If provided, must be a list of dictionaries with the keys:
- 'name' : str (optional; auto-generated if missing or duplicated)
- 'x'
: float (center position)
- 'w'
: float (width)
- 'h'
: float (height)
- 'type' : str (e.g., 'gauss')</p>
</dd>
</dl>
<p>If data is None, initializes an empty peaks object.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class peaks:
    &#34;&#34;&#34;
    A class for managing a collection of peak definitions used in synthetic signal generation.

    Each peak is represented as a dictionary with the following fields:
    - &#39;name&#39; (str): unique identifier (autogenerated if not provided)
    - &#39;x&#39; (float): center position (e.g., time, wavenumber, index)
    - &#39;w&#39; (float): width (related to FWHM)
    - &#39;h&#39; (float): peak height
    - &#39;type&#39; (str): generator type (e.g., &#39;gauss&#39;, &#39;lorentz&#39;, &#39;triangle&#39;)

    Supports:
    - Flexible addition and broadcasting of peak parameters
    - Named or indexed access to individual or multiple peaks
    - Overloaded operators for peak translation and scaling
    - Utility methods: update, sort, rename, remove_duplicates, copy
    - Conversion to signal object via `.to_signal()`
    - Informative __str__ and __repr__ output

    This class is used to build reproducible and structured test cases for symbolic encoding (e.g., sig2dna).
    &#34;&#34;&#34;

    def __init__(self, data=None):
        &#34;&#34;&#34;
        Initialize a peak collection.

        Parameters
        ----------
        data : list of dict, list of peaks, or None
            - If None: create an empty peaks object.
            - If list of dict: must contain at least &#39;x&#39;, &#39;w&#39;, &#39;h&#39;; &#39;name&#39; and &#39;type&#39; are optional.
            - If list of peaks: flattens into a single collection.

            If provided, must be a list of dictionaries with the keys:
            - &#39;name&#39; : str (optional; auto-generated if missing or duplicated)
            - &#39;x&#39;    : float (center position)
            - &#39;w&#39;    : float (width)
            - &#39;h&#39;    : float (height)
            - &#39;type&#39; : str (e.g., &#39;gauss&#39;)

        If data is None, initializes an empty peaks object.
        &#34;&#34;&#34;
        self._peaks = []
        self._names = set()
        if data:
            flat_list = []
            if all(isinstance(p, peaks) for p in data):
                # Merge from list of peaks instances
                for p_obj in data:
                    flat_list.extend(p_obj._peaks)
            else:
                flat_list = data
            for p in flat_list:
                name = p.get(&#34;name&#34;, f&#34;P{len(self._peaks)}&#34;)
                while name in self._names:
                    base = name or f&#34;P{len(self._peaks)}&#34;
                    suffix = 0
                    while True:
                        unique_name = f&#34;{base}_{suffix}&#34; if suffix &gt; 0 else base
                        if unique_name not in self._names:
                            break
                        suffix += 1
                    name = unique_name
                peak = {
                    &#34;name&#34;: name,
                    &#34;x&#34;: float(p[&#34;x&#34;]),
                    &#34;w&#34;: float(p[&#34;w&#34;]),
                    &#34;h&#34;: float(p[&#34;h&#34;]),
                    &#34;type&#34;: p.get(&#34;type&#34;, &#34;gauss&#34;)
                }
                self._peaks.append(peak)
                self._names.add(name)
                self.sort()

    def update(self, data):
        &#34;&#34;&#34;
        Update or insert peaks from a list of dictionaries.

        Parameters
        ----------
        data : list of dict
            Each dict must include at least &#39;x&#39;, &#39;w&#39;, &#39;h&#39;.
            If &#39;name&#39; matches an existing peak, it will be updated.
            If &#39;name&#39; is new or missing, the peak is appended.
        &#34;&#34;&#34;
        for p in data:
            name = p.get(&#34;name&#34;, None)
            peak = {
                &#34;name&#34;: name,
                &#34;x&#34;: float(p[&#34;x&#34;]),
                &#34;w&#34;: float(p[&#34;w&#34;]),
                &#34;h&#34;: float(p[&#34;h&#34;]),
                &#34;type&#34;: p.get(&#34;type&#34;, &#34;gauss&#34;)
            }

            if name and name in self._names:
                for i, existing in enumerate(self._peaks):
                    if existing[&#34;name&#34;] == name:
                        self._peaks[i].update(peak)
                        break
            else:
                peak[&#34;name&#34;] = name or f&#34;P{len(self._peaks)}&#34;
                while peak[&#34;name&#34;] in self._names:
                    peak[&#34;name&#34;] += &#34;_&#34;
                self._peaks.append(peak)
                self._names.add(peak[&#34;name&#34;])
        return self

    def add(self, x, w=1.0, h=1.0, name=None, type=&#34;gauss&#34;):
        &#34;&#34;&#34;
        Add one or multiple peaks to the collection.

        Parameters
        ----------
        x : float or array-like
            Center positions of the peaks.
        w : float or array-like
            Width(s) of the peaks (broadcastable).
        h : float or array-like
            Height(s) of the peaks (broadcastable).
        name : str or list of str or None
            Peak name(s); auto-generated if None or duplicate.
        type : str
            Generator type, e.g., &#39;gauss&#39;, &#39;lorentz&#39;, etc.
        &#34;&#34;&#34;
        x = np.atleast_1d(x)
        w = np.full_like(x, w) if np.isscalar(w) else np.asarray(w)
        h = np.full_like(x, h) if np.isscalar(h) else np.asarray(h)
        names = name if isinstance(name, (list, tuple)) else [name] * len(x)

        for i, (xi, wi, hi, ni) in enumerate(zip(x, w, h, names)):
            base = ni or f&#34;P{len(self._peaks)}&#34;
            suffix = 0
            while True:
                candidate = f&#34;{base}_{suffix}&#34; if suffix &gt; 0 else base
                if candidate not in self._names:
                    break
                suffix += 1
            ni = candidate

            self._peaks.append({
                &#34;name&#34;: ni,
                &#34;x&#34;: float(xi),
                &#34;w&#34;: float(wi),
                &#34;h&#34;: float(hi),
                &#34;type&#34;: type
            })
            self._names.add(ni)

    def __getitem__(self, key):
        if isinstance(key, str):
            next((p for p in self._peaks if p[&#39;name&#39;] == key), None)
        elif isinstance(key, int):
            return self._peaks[key]
        elif isinstance(key, (list, tuple)):
            return [self[k] for k in key]
        elif isinstance(key, slice):
            return self._peaks[key]
        else:
            raise KeyError(&#34;Unsupported index type&#34;)

    def __delitem__(self, key):
        if isinstance(key, str):
            self._peaks = [p for p in self._peaks if p[&#39;name&#39;] != key]
            self._names.discard(key)
        elif isinstance(key, int):
            self._names.discard(self._peaks[key][&#39;name&#39;])
            del self._peaks[key]
        elif isinstance(key, (list, tuple)):
            for k in key:
                self.__delitem__(k)
        elif isinstance(key, slice):
            for p in self._peaks[key]:
                self._names.discard(p[&#39;name&#39;])
            del self._peaks[key]

    def __add__(self, shift):
        p = peaks()
        for peak in self._peaks:
            new_peak = peak.copy()
            new_peak[&#39;x&#39;] += shift if np.isscalar(shift) else shift.pop(0)
            p._peaks.append(new_peak)
            p._names.add(new_peak[&#39;name&#39;])
        return p

    def __mul__(self, factor):
        p = peaks()
        for peak in self._peaks:
            new_peak = peak.copy()
            if isinstance(factor, tuple):
                new_peak[&#39;w&#39;] *= factor[0]
                new_peak[&#39;h&#39;] *= factor[1]
            else:
                f = factor if np.isscalar(factor) else factor.pop(0)
                new_peak[&#39;w&#39;] *= f
                new_peak[&#39;h&#39;] *= f
            p._peaks.append(new_peak)
            p._names.add(new_peak[&#39;name&#39;])
        return p

    def __truediv__(self, factor):
        inv = (1/factor[0], 1/factor[1]) if isinstance(factor, tuple) else 1/factor
        return self * inv

    def rename(self, prefix=&#34;P&#34;):
        self._names.clear()
        for i, peak in enumerate(self._peaks):
            peak[&#39;name&#39;] = f&#34;{prefix}{i}&#34;
            self._names.add(peak[&#39;name&#39;])

    def remove_duplicates(self):
        seen = set()
        unique_peaks = []
        for peak in self._peaks:
            key = (peak[&#39;x&#39;], peak[&#39;w&#39;], peak[&#39;h&#39;], peak[&#39;type&#39;])
            if key not in seen:
                seen.add(key)
                unique_peaks.append(peak)
        self._peaks = unique_peaks
        self._names = {p[&#39;name&#39;] for p in self._peaks}

    def __len__(self):
        return len(self._peaks)

    def __repr__(self):
        if not self._peaks:
            return str(self)

        # Compute max name width
        name_width = max(len(p[&#39;name&#39;]) for p in self._peaks)
        type_width = max(len(p[&#39;type&#39;]) for p in self._peaks)

        # Format header (optional)
        header = f&#34;{&#39;name&#39;:&lt;{name_width}}  {&#39;x&#39;:&gt;8}  {&#39;w&#39;:&gt;8}  {&#39;h&#39;:&gt;8}  {&#39;type&#39;:&lt;{type_width}}&#34;
        lines = [header, &#34;-&#34; * len(header)]

        # Format each peak
        for p in self._peaks:
            lines.append(
                f&#34;{p[&#39;name&#39;]:&lt;{name_width}}  &#34;
                f&#34;{p[&#39;x&#39;]:&gt;8.2f}  {p[&#39;w&#39;]:&gt;8.2f}  {p[&#39;h&#39;]:&gt;8.2f}  {p[&#39;type&#39;]:&lt;{type_width}}&#34;
            )

        return &#34;\n&#34;.join(lines)

    def __str__(self):
        if not self._peaks:
            return &#34;&lt;peaks instance with 0 peaks&gt;&#34;
        xmin = min(p[&#39;x&#39;] for p in self._peaks)
        xmax = max(p[&#39;x&#39;] for p in self._peaks)
        return f&#34;&lt;peaks instance with {len(self._peaks)} peaks&gt; spanned from x={xmin:.2f} to x={xmax:.2f}&#34;

    def names(self):
        &#34;&#34;&#34;Return the list of names&#34;&#34;&#34;
        return [p[&#39;name&#39;] for p in self._peaks]

    def as_dict(self):
        &#34;&#34;&#34;Return the list of peaks as dict&#34;&#34;&#34;
        return self._peaks.copy()

    def to_signal(self, index=None, name=None, generator_map=None, x=None, x0=0.0, n=1000):
        &#34;&#34;&#34;Generate a signal from a peaks object. Optionally restrict to a subset.&#34;&#34;&#34;
        selected = self._peaks
        if index is not None:
            if isinstance(index, (str, int)):
                index = [index]
            selected = [self[k] for k in index]
        return signal.from_peaks(selected, x=x, name=name or &#34;from_peaks&#34;, generator_map=generator_map, x0=x0, n=n)

    def copy(self):
        &#34;&#34;&#34;Return a deep-copy of the peaks&#34;&#34;&#34;
        new = peaks()
        new._peaks = deepcopy(self._peaks)
        return new

    def sort(self, order=&#34;asc&#34;):
        &#34;&#34;&#34;
        Sort peaks in-place based on their center positions (x values).

        Parameters
        ----------
        order : str
            Sorting direction. Use:
                - &#34;asc&#34; for ascending (default)
                - &#34;desc&#34; for descending
        &#34;&#34;&#34;
        reverse = {&#34;asc&#34;: False, &#34;desc&#34;: True}.get(order)
        if reverse is None:
            raise ValueError(&#34;order must be &#39;asc&#39; or &#39;desc&#39;&#34;)

        self._peaks.sort(key=lambda p: p[&#39;x&#39;], reverse=reverse)
        return self</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="signomics.peaks.add"><code class="name flex">
<span>def <span class="ident">add</span></span>(<span>self, x, w=1.0, h=1.0, name=None, type='gauss')</span>
</code></dt>
<dd>
<div class="desc"><p>Add one or multiple peaks to the collection.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>float</code> or <code>array-like</code></dt>
<dd>Center positions of the peaks.</dd>
<dt><strong><code>w</code></strong> :&ensp;<code>float</code> or <code>array-like</code></dt>
<dd>Width(s) of the peaks (broadcastable).</dd>
<dt><strong><code>h</code></strong> :&ensp;<code>float</code> or <code>array-like</code></dt>
<dd>Height(s) of the peaks (broadcastable).</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code> or <code>list</code> of <code>str</code> or <code>None</code></dt>
<dd>Peak name(s); auto-generated if None or duplicate.</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>str</code></dt>
<dd>Generator type, e.g., 'gauss', 'lorentz', etc.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add(self, x, w=1.0, h=1.0, name=None, type=&#34;gauss&#34;):
    &#34;&#34;&#34;
    Add one or multiple peaks to the collection.

    Parameters
    ----------
    x : float or array-like
        Center positions of the peaks.
    w : float or array-like
        Width(s) of the peaks (broadcastable).
    h : float or array-like
        Height(s) of the peaks (broadcastable).
    name : str or list of str or None
        Peak name(s); auto-generated if None or duplicate.
    type : str
        Generator type, e.g., &#39;gauss&#39;, &#39;lorentz&#39;, etc.
    &#34;&#34;&#34;
    x = np.atleast_1d(x)
    w = np.full_like(x, w) if np.isscalar(w) else np.asarray(w)
    h = np.full_like(x, h) if np.isscalar(h) else np.asarray(h)
    names = name if isinstance(name, (list, tuple)) else [name] * len(x)

    for i, (xi, wi, hi, ni) in enumerate(zip(x, w, h, names)):
        base = ni or f&#34;P{len(self._peaks)}&#34;
        suffix = 0
        while True:
            candidate = f&#34;{base}_{suffix}&#34; if suffix &gt; 0 else base
            if candidate not in self._names:
                break
            suffix += 1
        ni = candidate

        self._peaks.append({
            &#34;name&#34;: ni,
            &#34;x&#34;: float(xi),
            &#34;w&#34;: float(wi),
            &#34;h&#34;: float(hi),
            &#34;type&#34;: type
        })
        self._names.add(ni)</code></pre>
</details>
</dd>
<dt id="signomics.peaks.as_dict"><code class="name flex">
<span>def <span class="ident">as_dict</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the list of peaks as dict</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def as_dict(self):
    &#34;&#34;&#34;Return the list of peaks as dict&#34;&#34;&#34;
    return self._peaks.copy()</code></pre>
</details>
</dd>
<dt id="signomics.peaks.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a deep-copy of the peaks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self):
    &#34;&#34;&#34;Return a deep-copy of the peaks&#34;&#34;&#34;
    new = peaks()
    new._peaks = deepcopy(self._peaks)
    return new</code></pre>
</details>
</dd>
<dt id="signomics.peaks.names"><code class="name flex">
<span>def <span class="ident">names</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the list of names</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def names(self):
    &#34;&#34;&#34;Return the list of names&#34;&#34;&#34;
    return [p[&#39;name&#39;] for p in self._peaks]</code></pre>
</details>
</dd>
<dt id="signomics.peaks.remove_duplicates"><code class="name flex">
<span>def <span class="ident">remove_duplicates</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_duplicates(self):
    seen = set()
    unique_peaks = []
    for peak in self._peaks:
        key = (peak[&#39;x&#39;], peak[&#39;w&#39;], peak[&#39;h&#39;], peak[&#39;type&#39;])
        if key not in seen:
            seen.add(key)
            unique_peaks.append(peak)
    self._peaks = unique_peaks
    self._names = {p[&#39;name&#39;] for p in self._peaks}</code></pre>
</details>
</dd>
<dt id="signomics.peaks.rename"><code class="name flex">
<span>def <span class="ident">rename</span></span>(<span>self, prefix='P')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rename(self, prefix=&#34;P&#34;):
    self._names.clear()
    for i, peak in enumerate(self._peaks):
        peak[&#39;name&#39;] = f&#34;{prefix}{i}&#34;
        self._names.add(peak[&#39;name&#39;])</code></pre>
</details>
</dd>
<dt id="signomics.peaks.sort"><code class="name flex">
<span>def <span class="ident">sort</span></span>(<span>self, order='asc')</span>
</code></dt>
<dd>
<div class="desc"><p>Sort peaks in-place based on their center positions (x values).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>order</code></strong> :&ensp;<code>str</code></dt>
<dd>Sorting direction. Use:
- "asc" for ascending (default)
- "desc" for descending</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort(self, order=&#34;asc&#34;):
    &#34;&#34;&#34;
    Sort peaks in-place based on their center positions (x values).

    Parameters
    ----------
    order : str
        Sorting direction. Use:
            - &#34;asc&#34; for ascending (default)
            - &#34;desc&#34; for descending
    &#34;&#34;&#34;
    reverse = {&#34;asc&#34;: False, &#34;desc&#34;: True}.get(order)
    if reverse is None:
        raise ValueError(&#34;order must be &#39;asc&#39; or &#39;desc&#39;&#34;)

    self._peaks.sort(key=lambda p: p[&#39;x&#39;], reverse=reverse)
    return self</code></pre>
</details>
</dd>
<dt id="signomics.peaks.to_signal"><code class="name flex">
<span>def <span class="ident">to_signal</span></span>(<span>self, index=None, name=None, generator_map=None, x=None, x0=0.0, n=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a signal from a peaks object. Optionally restrict to a subset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_signal(self, index=None, name=None, generator_map=None, x=None, x0=0.0, n=1000):
    &#34;&#34;&#34;Generate a signal from a peaks object. Optionally restrict to a subset.&#34;&#34;&#34;
    selected = self._peaks
    if index is not None:
        if isinstance(index, (str, int)):
            index = [index]
        selected = [self[k] for k in index]
    return signal.from_peaks(selected, x=x, name=name or &#34;from_peaks&#34;, generator_map=generator_map, x0=x0, n=n)</code></pre>
</details>
</dd>
<dt id="signomics.peaks.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, data)</span>
</code></dt>
<dd>
<div class="desc"><p>Update or insert peaks from a list of dictionaries.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>Each dict must include at least 'x', 'w', 'h'.
If 'name' matches an existing peak, it will be updated.
If 'name' is new or missing, the peak is appended.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(self, data):
    &#34;&#34;&#34;
    Update or insert peaks from a list of dictionaries.

    Parameters
    ----------
    data : list of dict
        Each dict must include at least &#39;x&#39;, &#39;w&#39;, &#39;h&#39;.
        If &#39;name&#39; matches an existing peak, it will be updated.
        If &#39;name&#39; is new or missing, the peak is appended.
    &#34;&#34;&#34;
    for p in data:
        name = p.get(&#34;name&#34;, None)
        peak = {
            &#34;name&#34;: name,
            &#34;x&#34;: float(p[&#34;x&#34;]),
            &#34;w&#34;: float(p[&#34;w&#34;]),
            &#34;h&#34;: float(p[&#34;h&#34;]),
            &#34;type&#34;: p.get(&#34;type&#34;, &#34;gauss&#34;)
        }

        if name and name in self._names:
            for i, existing in enumerate(self._peaks):
                if existing[&#34;name&#34;] == name:
                    self._peaks[i].update(peak)
                    break
        else:
            peak[&#34;name&#34;] = name or f&#34;P{len(self._peaks)}&#34;
            while peak[&#34;name&#34;] in self._names:
                peak[&#34;name&#34;] += &#34;_&#34;
            self._peaks.append(peak)
            self._names.add(peak[&#34;name&#34;])
    return self</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="signomics.signal"><code class="flex name class">
<span>class <span class="ident">signal</span></span>
<span>(</span><span>x=None, y=None, name='signal', type='generic', x_label='index', x_unit='-', y_label='intensity', y_unit='a.u.', metadata=None, source='array', user=None, date=None, host=None, cwd=None, version=None, color=None, linewidth=2, linestyle='-', message=None, fullhistory=True)</span>
</code></dt>
<dd>
<div class="desc"><p>signal: A self-documented 1D analytical signal container for reproducible scientific workflows.</p>
<p>This class is designed for lab-grade signal processing and traceable data storage.
It represents a discrete 1D signal (e.g., chromatogram, spectrum, transient) with full metadata,
support for symbolic transformation, numerical operations, plotting, and structured saving/loading.</p>
<p>Key features include:
- Portable metadata (user, time, host, cwd, version)
- Domain-aware plots and operations
- Reproducible signal serialization in JSON or compressed format
- Full traceability of all transformation events
- Optional recursive backup of prior states</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Sampling domain (e.g., time, wavelength, chemical shift).</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Signal values aligned with x.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Label for plots and file storage (used as default filename).</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>str</code></dt>
<dd>Optional tag (e.g., 'GC-MS', 'FTIR', 'NMR', 'synthetic').</dd>
<dt><strong><code>x_label</code></strong> :&ensp;<code>str</code></dt>
<dd>Label for the x-axis (e.g., 'wavenumber').</dd>
<dt><strong><code>x_unit</code></strong> :&ensp;<code>str</code></dt>
<dd>Unit of the x-axis (e.g., 'cm⁻¹').</dd>
<dt><strong><code>source</code></strong> :&ensp;<code>str</code></dt>
<dd>Origin label ('array', 'peaks', 'noise', 'imported'&hellip;).</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>Includes user, date, host, cwd, version — filled automatically unless overridden.</dd>
<dt>color (str or [rgb]), linestyle (str), linewidth (str)</dt>
<dt><strong><code>_previous</code></strong> :&ensp;<code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>deep-copy of current object</dd>
<dt><strong><code>_history</code></strong> :&ensp;<code>dict</code></dt>
<dd>"user@host:timestamp | uidkey" :{"action":str, "details": str}</dd>
</dl>
<h2 id="key-methods">Key Methods</h2>
<ul>
<li>from_peaks(&hellip;)
: Construct signal from a <code><a title="signomics.peaks" href="#signomics.peaks">peaks</a></code> object</li>
<li>add_noise(&hellip;)
: Return noisy variant (Poisson, Gaussian, ramp or constant bias)</li>
<li>align_with(&hellip;)
: Align this signal with another (same x domain)</li>
<li>copy()
: Deep copy</li>
<li>save(&hellip;)
: Save as JSON or .gz (optional CSV export)</li>
<li>load(&hellip;)
: Load from saved file</li>
<li>plot(&hellip;)
: Plot the signal with axis labels</li>
<li>backup(&hellip;)
: Backup current signal (deep-copy stored in _previous)</li>
<li>restore(&hellip;)
: Restore the previous state of the signal</li>
<li>apply_poisson_baseline_filter(&hellip;) : Apply a Poisson-based filter</li>
<li>enable_fullhistory
: enable full history</li>
<li>disable_fullhistory
: disable full history</li>
<li>_toDNA(signal)
: DNAsignal</li>
</ul>
<h2 id="overloaded-operators">Overloaded Operators</h2>
<ul>
<li>+, -, *, /
: Operates on signals or scalars, aligns if needed</li>
<li>+=, -=, *=, /=
: In-place functional versions (returns new signal)</li>
</ul>
<h2 id="low-level-methods">Low-level Methods</h2>
<ul>
<li>_current_stamp()
: stamp for events (static method)</li>
<li>_copystatic()
: deep-copy of signal only (use copy for a full copy) (static method)</li>
<li>_events()
: register a processing step</li>
<li>_to_serializable
: Convert the signal into a dictionary suitable for JSON export</li>
<li>_from_serizalizable
: convert a dict (e.g., from JSON import) to signal</li>
</ul>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; s = signal(x, y, name=&quot;sample&quot;, type=&quot;FTIR&quot;, x_label=&quot;wavenumber&quot;, x_unit=&quot;cm⁻¹&quot;)
&gt;&gt;&gt; s.add_noise(&quot;gaussian&quot;, 0.05).plot()
&gt;&gt;&gt; s.save()  # saves to ./sample.json.gz
&gt;&gt;&gt; s2 = signal.load(&quot;sample.json.gz&quot;)
</code></pre>
<p>Initialize a signal instance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>array-like</code>, optional</dt>
<dd>Sampling domain (e.g., time, wavelength, chemical shift).</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>array-like</code>, optional</dt>
<dd>Signal values aligned with x.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Label for plots and file storage (used as default filename).</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Optional tag (e.g., 'GC-MS', 'FTIR', 'NMR', 'synthetic').</dd>
<dt><strong><code>x_label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Label for the x-axis (e.g., 'wavenumber').</dd>
<dt><strong><code>x_unit</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Unit of the x-axis (e.g., 'cm⁻¹').</dd>
<dt><strong><code>y_label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Label for the y-axis (e.g., 'intensity').</dd>
<dt><strong><code>y_unit</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Unit of the y-axis (e.g., 'a.u.').</dd>
<dt><strong><code>source</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Origin label ('array', 'peaks', 'noise', 'imported'&hellip;).</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Full metadata dictionary. If None, fields below are auto-filled.</dd>
<dt><strong><code>user</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Username (defaults to current user).</dd>
<dt><strong><code>date</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>ISO timestamp of creation.</dd>
<dt><strong><code>host</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Hostname of the machine.</dd>
<dt><strong><code>cwd</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Current working directory at creation time.</dd>
<dt><strong><code>version</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Software version (defaults to global <strong>version</strong>).</dd>
<dt>color (default=None), linestyle (default="-"), linewidth (default=2): optional</dt>
<dt>Plot styling.</dt>
<dt><strong><code>message</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>message to record</dd>
<dt><strong><code>fullhistory</code></strong> :&ensp;<code>bool</code>, optional <code>(default=True)</code></dt>
<dd>flag to enable full history</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class signal:
    &#34;&#34;&#34;
    signal: A self-documented 1D analytical signal container for reproducible scientific workflows.

    This class is designed for lab-grade signal processing and traceable data storage.
    It represents a discrete 1D signal (e.g., chromatogram, spectrum, transient) with full metadata,
    support for symbolic transformation, numerical operations, plotting, and structured saving/loading.

    Key features include:
    - Portable metadata (user, time, host, cwd, version)
    - Domain-aware plots and operations
    - Reproducible signal serialization in JSON or compressed format
    - Full traceability of all transformation events
    - Optional recursive backup of prior states

    Attributes
    ----------
    x : np.ndarray
        Sampling domain (e.g., time, wavelength, chemical shift).
    y : np.ndarray
        Signal values aligned with x.
    name : str
        Label for plots and file storage (used as default filename).
    type : str
        Optional tag (e.g., &#39;GC-MS&#39;, &#39;FTIR&#39;, &#39;NMR&#39;, &#39;synthetic&#39;).
    x_label : str
        Label for the x-axis (e.g., &#39;wavenumber&#39;).
    x_unit : str
        Unit of the x-axis (e.g., &#39;cm⁻¹&#39;).
    source : str
        Origin label (&#39;array&#39;, &#39;peaks&#39;, &#39;noise&#39;, &#39;imported&#39;...).
    metadata : dict
        Includes user, date, host, cwd, version — filled automatically unless overridden.
    color (str or [rgb]), linestyle (str), linewidth (str)
    _previous: signal
        deep-copy of current object
    _history: dict
        &#34;user@host:timestamp | uidkey&#34; :{&#34;action&#34;:str, &#34;details&#34;: str}

    Key Methods
    -----------
    - from_peaks(...)         : Construct signal from a `peaks` object
    - add_noise(...)          : Return noisy variant (Poisson, Gaussian, ramp or constant bias)
    - align_with(...)         : Align this signal with another (same x domain)
    - copy()                  : Deep copy
    - save(...)               : Save as JSON or .gz (optional CSV export)
    - load(...)               : Load from saved file
    - plot(...)               : Plot the signal with axis labels
    - backup(...)             : Backup current signal (deep-copy stored in _previous)
    - restore(...)            : Restore the previous state of the signal
    - apply_poisson_baseline_filter(...) : Apply a Poisson-based filter
    - enable_fullhistory      : enable full history
    - disable_fullhistory     : disable full history
    - _toDNA(signal)          : DNAsignal

    Overloaded Operators
    --------------------
    - +, -, *, /              : Operates on signals or scalars, aligns if needed
    - +=, -=, *=, /=          : In-place functional versions (returns new signal)

    Low-level Methods
    -----------------
    - _current_stamp()        : stamp for events (static method)
    - _copystatic()           : deep-copy of signal only (use copy for a full copy) (static method)
    - _events()               : register a processing step
    - _to_serializable        : Convert the signal into a dictionary suitable for JSON export
    - _from_serizalizable     : convert a dict (e.g., from JSON import) to signal

    Example
    -------
    &gt;&gt;&gt; s = signal(x, y, name=&#34;sample&#34;, type=&#34;FTIR&#34;, x_label=&#34;wavenumber&#34;, x_unit=&#34;cm⁻¹&#34;)
    &gt;&gt;&gt; s.add_noise(&#34;gaussian&#34;, 0.05).plot()
    &gt;&gt;&gt; s.save()  # saves to ./sample.json.gz
    &gt;&gt;&gt; s2 = signal.load(&#34;sample.json.gz&#34;)
    &#34;&#34;&#34;

    def __init__(self, x=None, y=None,
                 name=&#34;signal&#34;,
                 type=&#34;generic&#34;,
                 x_label=&#34;index&#34;,x_unit=&#34;-&#34;,
                 y_label=&#34;intensity&#34;,y_unit=&#34;a.u.&#34;,
                 metadata=None,
                 source=&#34;array&#34;,
                 user=None, date=None, host=None, cwd=None, version=None,
                 color=None,linewidth=2,linestyle=&#39;-&#39;,message=None,fullhistory=True,):
        &#34;&#34;&#34;
        Initialize a signal instance.

        Parameters
        ----------
        x : array-like, optional
            Sampling domain (e.g., time, wavelength, chemical shift).
        y : array-like, optional
            Signal values aligned with x.
        name : str, optional
            Label for plots and file storage (used as default filename).
        type : str, optional
            Optional tag (e.g., &#39;GC-MS&#39;, &#39;FTIR&#39;, &#39;NMR&#39;, &#39;synthetic&#39;).
        x_label : str, optional
            Label for the x-axis (e.g., &#39;wavenumber&#39;).
        x_unit : str, optional
            Unit of the x-axis (e.g., &#39;cm⁻¹&#39;).
        y_label : str, optional
            Label for the y-axis (e.g., &#39;intensity&#39;).
        y_unit : str, optional
            Unit of the y-axis (e.g., &#39;a.u.&#39;).
        source : str, optional
            Origin label (&#39;array&#39;, &#39;peaks&#39;, &#39;noise&#39;, &#39;imported&#39;...).
        metadata : dict, optional
            Full metadata dictionary. If None, fields below are auto-filled.
        user : str, optional
            Username (defaults to current user).
        date : str, optional
            ISO timestamp of creation.
        host : str, optional
            Hostname of the machine.
        cwd : str, optional
            Current working directory at creation time.
        version : str, optional
            Software version (defaults to global __version__).
        color (default=None), linestyle (default=&#34;-&#34;), linewidth (default=2): optional
            Plot styling.
        message : str, optional
            message to record
        fullhistory : bool, optional (default=True)
            flag to enable full history
        &#34;&#34;&#34;

        self.x = np.asarray(x) if x is not None else None
        self.y = np.asarray(y) if y is not None else None
        self.name = name
        self.type = type
        self.x_label = x_label
        self.x_unit = x_unit
        self.y_label = y_label
        self.y_unit = y_unit
        self.source = source
        self.metadata = metadata or {
            &#34;user&#34;: user or getpass.getuser(),
            &#34;date&#34;: date or datetime.datetime.now().isoformat(),
            &#34;host&#34;: host or socket.gethostname(),
            &#34;cwd&#34;: cwd or os.getcwd(),
            &#34;version&#34;: version or globals().get(&#34;__version__&#34;, &#34;undefined&#34;),
            &#34;other&#34;: &#34;&#34;
        }
        self.color = color
        self.linestyle = linestyle
        self.linewidth = linewidth
        self._previous = None
        self._history = {}
        self._fullhistory = fullhistory  # Do not serialize this field
        self._events(&#34;init&#34;, {&#34;from&#34;: self.source, &#34;message&#34;: message})

    @property
    def n(self):
        &#34;&#34;&#34;Return the length of the signal and None if it is None&#34;&#34;&#34;
        return len(self.y) if self.y is not None else None

    @staticmethod
    def _current_stamp():
        timestamp = datetime.datetime.now().isoformat(timespec=&#34;seconds&#34;)
        userhost = f&#34;{getpass.getuser()}@{socket.gethostname()}&#34;
        idstamp = uuid.uuid4().hex[:6]
        return f&#34;{timestamp}:{userhost} | {idstamp}&#34;

    @staticmethod
    def _copystatic(s):
        &#34;&#34;&#34;Static copy of a signal (x and y only)&#34;&#34;&#34;
        return s.__class__(x=s.x.copy(), y=s.y.copy(), name=s.name + &#34;_backup&#34;)

    def _events(self, action, details=None):
        &#34;&#34;&#34;
        Register a traceable action in the signal&#39;s history.

        Each event is stored with a unique timestamp-based key and includes:
        - user@host
        - timestamp
        - action (string)
        - details (optional dictionary)

        Parameters
        ----------
        action : str
            Description of the event (e.g., &#39;baseline_filter&#39;, &#39;restore&#39;).
        details : dict, optional
            Additional parameters relevant to the action.
        &#34;&#34;&#34;
        if not hasattr(self, &#34;_history&#34;) or not isinstance(self._history, dict):
            self._history = {}
        key = signal._current_stamp()
        if not hasattr(self, &#34;_history&#34;):
            self._history = {}
        self._history[key] = {&#34;action&#34;: action,&#34;details&#34;: details}

    def backup(self,fullhistory=None,message=None):
        &#34;&#34;&#34;Backup current state in _previous&#34;&#34;&#34;
        previous = self.copy()
        fullhistory = self._fullhistory if fullhistory is None else fullhistory
        if not fullhistory:
            previous._previous = None
        self._previous = previous
        self._events(&#34;backup&#34;, {&#34;from&#34;: self._fullhistory,&#39;message&#39;: message})

    def restore(self):
        &#34;&#34;&#34;Restore the previous signal version if available&#34;&#34;&#34;
        if hasattr(self, &#34;_previous&#34;) and isinstance(self._previous, signal):
            restored = self._previous.copy()
            for attr in [&#39;x&#39;, &#39;y&#39;, &#39;name&#39;, &#39;type&#39;, &#39;x_label&#39;, &#39;x_unit&#39;,
                         &#39;y_label&#39;, &#39;y_unit&#39;, &#39;color&#39;, &#39;linestyle&#39;,
                         &#39;linewidth&#39;, &#39;source&#39;, &#39;metadata&#39;, &#39;_previous&#39;, &#39;_history&#39;]:
                setattr(self, attr, getattr(restored, attr))
            self._events(&#34;restore&#34;, {&#34;from&#34;: restored.name})
        else:
            raise AttributeError(&#34;No previous signal to restore&#34;)

    def enable_fullhistory(self):
        &#34;&#34;&#34;Enable full history tracking&#34;&#34;&#34;
        self._events(&#34;enable full history&#34;, {&#34;from&#34;: &#34;enable_fullhistory&#34;})
        set._fullhistory = True

    def disable_fullhistory(self):
        &#34;&#34;&#34;Disable full history tracking&#34;&#34;&#34;
        set._fullhistory = True
        self._previous = False
        self._events(&#34;disable full history&#34;, {&#34;from&#34;: &#34;disable_fullhistory&#34;})

    @classmethod
    def from_peaks(cls, peaks_obj, x=None, generator_map=None, name=&#34;from_peaks&#34;, x0=None, n=1000):
        &#34;&#34;&#34;
        Generate a signal from a set of peaks.

        Parameters
        ----------
        peaks_obj : peaks
            A list-like object containing peak definitions.
        x : array-like, float, or None
            If None: compute x domain from peaks.
            If scalar: interpreted as xmax; linspace from x0 to xmax.
            If array: use as x directly.
        generator_map : dict or None
            Optional map of peak type → generator instance (default is Gaussian).
        name : str
            Name of the signal instance.
        x0 : float or None
            Left bound of the domain (used only if x is None or scalar).
            If None: inferred from peaks.
        n : int
            Number of points in the generated x array.

        Returns
        -------
        signal
            A new signal instance generated from the peaks.

        Example
        -------
        p = peaks()
        p.add(x=[400, 800, 1600], w=30, h=[1.0, 0.6, 0.9], type=&#34;gauss&#34;)
        s = signal.from_peaks(p, x0=300, n=2048)
        s.plot()
        &#34;&#34;&#34;
        if x is None:
            xmin = min(p[&#39;x&#39;] - 3 * p[&#39;w&#39;] for p in peaks_obj)
            xmax = max(p[&#39;x&#39;] + 3 * p[&#39;w&#39;] for p in peaks_obj)
            if x0 is not None:
                xmin = x0
            x = np.linspace(xmin, xmax, n)
        elif np.isscalar(x):
            xmin = x0 if x0 is not None else min(p[&#39;x&#39;] - 3 * p[&#39;w&#39;] for p in peaks_obj)
            x = np.linspace(xmin, float(x), n)
        else:
            x = np.asarray(x)

        y = np.zeros_like(x)
        generator_map = generator_map or {}
        for p in peaks_obj:
            g = generator_map.get(p[&#39;type&#39;], generator(p[&#39;type&#39;]))
            y += g(x, p[&#39;x&#39;], p[&#39;w&#39;], p[&#39;h&#39;])
        s = cls(x, y, name=name)
        s.source = &#34;peaks&#34;
        return s

    def sample(self, x_new):
        &#34;&#34;&#34;Interpolate values from x&#34;&#34;&#34;
        return np.interp(x_new, self.x, self.y)

    def plot(self, ax=None, label=None, color=None, linestyle=None, linewidth=None,
             fontsize=12, newfig=False):
        &#34;&#34;&#34;
        Plot the signal using matplotlib, applying either internal style settings
        or overrides provided at call time.

        Parameters
        ----------
        ax : matplotlib.axes.Axes, optional
            Axis to plot on. If None, uses current axis or new figure if newfig=True.
        label : str, optional
            Legend label. Defaults to self.name.
        color : str or None
            Line color. If None, uses default matplotlib cycling.
        linestyle : str or None
            Line style (e.g., &#39;-&#39;, &#39;--&#39;). If None, uses self.linestyle.
        linewidth : float or None
            Line width. If None, uses self.linewidth.
        fontsize : int or str
            Font size for axis labels and legend. Can use values like &#39;small&#39;, &#39;large&#39;.
        newfig : bool
            If True, creates a new figure before plotting.

        Returns
        -------
        matplotlib.figure.Figure
        matplotlib.axes.Axes
        &#34;&#34;&#34;
        # Convert font size keywords to numeric
        fontsize_map = {
            &#34;xx-small&#34;: 6, &#34;x-small&#34;: 8, &#34;small&#34;: 10,
            &#34;medium&#34;: 12, &#34;large&#34;: 14, &#34;x-large&#34;: 16, &#34;xx-large&#34;: 18
        }
        if isinstance(fontsize, str):
            fontsize = fontsize_map.get(fontsize.lower(), 12)

        if newfig:
            fig = plt.figure()
        else:
            fig = plt.gcf()

        ax = ax or plt.gca()

        # Final style resolution
        label = label if label is not None else self.name
        color = color if color is not None else self.color
        linestyle = linestyle if linestyle is not None else self.linestyle
        linewidth = linewidth if linewidth is not None else self.linewidth

        # Plot
        if self.x is None:
            ax.plot(self.y, label=label, color=color,
                    linestyle=linestyle, linewidth=linewidth)
        else:
            ax.plot(self.x, self.y, label=label, color=color,
                    linestyle=linestyle, linewidth=linewidth)

        # Axes labeling and legend
        if self.x_label and self.x_unit:
            ax.set_xlabel(f&#34;{self.x_label} [{self.x_unit}]&#34;, fontsize=fontsize)
        elif self.x_label:
            ax.set_xlabel(self.x_label, fontsize=fontsize)

        if self.y_label and self.y_unit:
            ax.set_ylabel(f&#34;{self.y_label} [{self.y_unit}]&#34;, fontsize=fontsize)
        elif self.y_label:
            ax.set_ylabel(self.y_label, fontsize=fontsize)

        if label:
            ax.legend(fontsize=fontsize)

        return fig, ax


    def __repr__(self):
        def fmt_str(s, maxlen=60):
            s = str(s)
            if len(s) &lt;= maxlen:
                return s
            return f&#34;{s[:maxlen//2 - 2]}...{s[-maxlen//2 + 1:]}&#34;
        meta = self.metadata
        span = (f&#34;{self.x[0]:.2f}&#34;, f&#34;{self.x[-1]:.2f}&#34;) if self.x is not None else (&#34;?&#34;, &#34;?&#34;)
        size = len(self.x) if self.x is not None else self.n
        field_width = 10
        lines = [
            f&#34;&lt;signal &#39;{self.name}&#39; [{self.type}]&gt;&#34;,
            f&#34;{&#39;domain:&#39;.ljust(field_width)} {self.x_label} [{self.x_unit}], span: {span[0]} → {span[1]}, points: {size}&#34;,
            f&#34;{&#39;source:&#39;.ljust(field_width)} {self.source}&#34;,
            f&#34;{&#39;created:&#39;.ljust(field_width)} {fmt_str(meta.get(&#39;date&#39;, &#39;?&#39;))}&#34;,
            f&#34;{&#39;user:&#39;.ljust(field_width)} {meta.get(&#39;user&#39;, &#39;?&#39;)}@{meta.get(&#39;host&#39;, &#39;?&#39;)}&#34;,
            f&#34;{&#39;cwd:&#39;.ljust(field_width)} {fmt_str(meta.get(&#39;cwd&#39;, &#39;?&#39;))}&#34;,
            f&#34;{&#39;version:&#39;.ljust(field_width)} {meta.get(&#39;version&#39;, &#39;?&#39;)}&#34;
        ]
        print(&#34;\n&#34;.join(lines))
        return str(self)

    def __str__(self):
        if self.y is None:
            return f&#34;&lt;empty {self.type}-signal - source=&#39;{self.source}&#39;&gt;&#34;
        else:
            return f&#34;&lt;{self.name}:{self.type}-signal of length={self.n} source=&#39;{self.source}&#39;&gt;&#34;

    def align_with(self, other, mode=&#39;union&#39;, n=1000):
        &#34;&#34;&#34;
        Align two signals to a common x grid with interpolation and padding.

        Parameters:
            other (signal): the other signal to align with
            mode (str): &#39;union&#39; (default) or &#39;intersection&#39;
            n (int): number of points for the new grid

        Returns:
            tuple: (self_interp, other_interp) as new signal instances
        &#34;&#34;&#34;
        if not isinstance(other, signal):
            raise TypeError(&#34;Can only align with another signal.&#34;)

        # Determine new x-axis
        if mode == &#39;union&#39;:
            x_min = min(self.x[0], other.x[0])
            x_max = max(self.x[-1], other.x[-1])
        elif mode == &#39;intersection&#39;:
            x_min = max(self.x[0], other.x[0])
            x_max = min(self.x[-1], other.x[-1])
            if x_min &gt;= x_max:
                raise ValueError(&#34;No overlapping x-range for &#39;intersection&#39; mode.&#34;)
        else:
            raise ValueError(&#34;mode must be &#39;union&#39; or &#39;intersection&#39;&#34;)

        x_new = np.linspace(x_min, x_max, n)

        # Interpolate and zero outside original domain
        def interp_with_padding(sig):
            y_new = np.interp(x_new, sig.x, sig.y, left=0, right=0)
            return signal(x_new, y_new, name=sig.name, source=sig.source)

        return interp_with_padding(self), interp_with_padding(other)

    def add_noise(self, kind=&#34;gaussian&#34;, scale=1.0, bias=None):
        &#34;&#34;&#34;Return a new signal with noise and/or bias added.&#34;&#34;&#34;
        new_y = self.y.copy()

        # --- Apply bias ---
        if bias is not None:
            if isinstance(bias, (int, float)):
                new_y += bias
            elif isinstance(bias, np.ndarray):
                if bias.shape != self.x.shape:
                    raise ValueError(&#34;Bias array must match x domain.&#34;)
                new_y += bias
            elif bias == &#34;ramp&#34;:
                ramp = np.linspace(0, 1, len(self.x))
                new_y += ramp
            elif isinstance(bias, signal):
                interp_bias = np.interp(self.x, bias.x, bias.y)
                new_y += interp_bias
            else:
                raise TypeError(&#34;Invalid bias type.&#34;)

        # --- Apply noise ---
        rng = np.random.default_rng()
        if kind == &#34;gaussian&#34;:
            new_y += rng.normal(loc=0.0, scale=scale, size=self.y.shape)
        elif kind == &#34;poisson&#34;:
            if np.any(new_y &lt; 0):
                raise ValueError(&#34;Poisson noise requires non-negative values.&#34;)
            new_y = rng.poisson(lam=new_y * scale) / scale
        else:
            raise ValueError(&#34;Unknown noise type.&#34;)

        return signal(self.x.copy(), new_y, name=self.name + &#34;+noise&#34;, source=self.source + &#34;+noise&#34;)

    def copy(self):
        &#34;&#34;&#34;Deep copy of the signal, excluding full history control flag&#34;&#34;&#34;
        new = signal(
            x=self.x.copy() if self.x is not None else None,
            y=self.y.copy() if self.y is not None else None,
            name=self.name,
            type=self.type,
            x_label=self.x_label,
            x_unit=self.x_unit,
            y_label=self.y_label,
            y_unit=self.y_unit,
            metadata=self.metadata.copy(),
            source=self.source,
            color=self.color,
            linewidth=self.linewidth,
            linestyle=self.linestyle,
            fullhistory=self._fullhistory
        )
        new._history = self._history.copy()
        if self._fullhistory and self._previous is not None:
            new._previous = self._previous.copy()
        else:
            new._previous = None
        return new

    def _binary_op(self, other, op):
        &#34;&#34;&#34;Binary operation on signals&#34;&#34;&#34;
        if isinstance(other, (int, float)):
            return signal(self.x.copy(), op(self.y, other), name=self.name, source=self.source)

        if isinstance(other, signal):
            s1, s2 = self.align_with(other)
            return signal(s1.x, op(s1.y, s2.y), name=f&#34;({s1.name}){op.__name__}({s2.name})&#34;)

        raise TypeError(f&#34;Unsupported operand type(s) for {op.__name__}: &#39;signal&#39; and &#39;{type(other).__name__}&#39;&#34;)

    def __add__(self, other): return self._binary_op(other, operator.add)
    def __sub__(self, other): return self._binary_op(other, operator.sub)
    def __mul__(self, other): return self._binary_op(other, operator.mul)
    def __truediv__(self, other): return self._binary_op(other, operator.truediv)
    def __iadd__(self, other): return self._binary_op(other, operator.add)
    def __isub__(self, other): return self._binary_op(other, operator.sub)
    def __imul__(self, other): return self._binary_op(other, operator.mul)
    def __itruediv__(self, other): return self._binary_op(other, operator.truediv)

    def _to_serializable(self):
        &#34;&#34;&#34;Convert the signal into a dictionary suitable for JSON export.&#34;&#34;&#34;
        return {
            &#34;x&#34;: self.x.tolist() if self.x is not None else None,
            &#34;y&#34;: self.y.tolist() if self.y is not None else None,
            &#34;name&#34;: self.name,
            &#34;type&#34;: self.type,
            &#34;x_label&#34;: self.x_label,
            &#34;x_unit&#34;: self.x_unit,
            &#34;y_label&#34;: self.y_label,
            &#34;y_unit&#34;: self.y_unit,
            &#34;source&#34;: self.source,
            &#34;metadata&#34;: self.metadata,
            &#34;color&#34;: self.color,
            &#34;linestyle&#34;: self.linestyle,
            &#34;linewidth&#34;: self.linewidth,
            &#34;_history&#34;: self._history,
            &#34;_previous&#34;: self._previous.to_serializable() if self._fullhistory and self._previous else None
        }

    @staticmethod
    def _from_serializable(data,message=None):
        &#34;&#34;&#34;Convert a serialized dict to a signal&#34;&#34;&#34;
        s = signal(
            x=np.array(data[&#34;x&#34;]) if data[&#34;x&#34;] is not None else None,
            y=np.array(data[&#34;y&#34;]) if data[&#34;y&#34;] is not None else None,
            name=data.get(&#34;name&#34;, &#34;signal&#34;),
            type=data.get(&#34;type&#34;, &#34;generic&#34;),
            x_label=data.get(&#34;x_label&#34;, &#34;index&#34;),
            x_unit=data.get(&#34;x_unit&#34;, &#34;-&#34;),
            y_label=data.get(&#34;y_label&#34;, &#34;intensity&#34;),
            y_unit=data.get(&#34;y_unit&#34;, &#34;a.u.&#34;),
            metadata=data.get(&#34;metadata&#34;, {}),
            source=data.get(&#34;source&#34;, &#34;array&#34;),
            color=data.get(&#34;color&#34;, None),
            linestyle=data.get(&#34;linestyle&#34;, &#34;-&#34;),
            linewidth=data.get(&#34;linewidth&#34;, 2),
            fullhistory=True,  # Set default on load
            message = message
        )
        s._history = data.get(&#34;_history&#34;, {})
        prev = data.get(&#34;_previous&#34;, None)
        s._previous = signal._from_serializable(prev) if prev else None
        return s

    def save(self, filepath=None, zip=True, export_csv=False):
        &#34;&#34;&#34;
        Save signal to JSON (optionally compressed) and optionally CSV.

        Parameters
        ----------
        filepath : str or Path or None
            If None, builds path from metadata[&#39;cwd&#39;] and self.name + &#39;.json[.gz]&#39;.
            If a directory, appends name + &#39;.json[.gz]&#39;.
            If a file, uses as is.
        zip : bool
            Whether to compress the JSON file using gzip. Default: True.
        export_csv : bool
            If True, also save a .csv file (x,y) alongside the JSON.
        &#34;&#34;&#34;
        # Resolve filepath
        if filepath is None:
            filepath = os.path.join(self.metadata[&#34;cwd&#34;], f&#34;{self.name}.json.gz&#34; if zip else f&#34;{self.name}.json&#34;)
        elif os.path.isdir(filepath):
            filepath = os.path.join(filepath, f&#34;{self.name}.json.gz&#34; if zip else f&#34;{self.name}.json&#34;)
        filepath = Path(filepath)
        data = self._to_serializable()
        if zip or str(filepath).endswith(&#34;.gz&#34;):
            with gzip.open(filepath, &#34;wt&#34;, encoding=&#34;utf-8&#34;) as f:
                json.dump(data, f, indent=2)
        else:
            with open(filepath, &#34;w&#34;, encoding=&#34;utf-8&#34;) as f:
                json.dump(data, f, indent=2)

        # Optionally export to CSV
        if export_csv and self.x is not None and self.y is not None:
            csv_path = filepath.with_suffix(&#34;.csv&#34;)
            with open(csv_path, &#34;w&#34;, encoding=&#34;utf-8&#34;) as f:
                f.write(&#34;x,y\n&#34;)
                for xi, yi in zip(self.x, self.y):
                    f.write(f&#34;{xi},{yi}\n&#34;)

    @staticmethod
    def load(filepath):
        &#34;&#34;&#34;
        Load a signal from a JSON or gzipped JSON file, including recursive _previous.

        Parameters
        ----------
        filepath : str or Path
            Path to the JSON or .gz file

        Returns
        -------
        signal
            A fully reconstructed signal object
        &#34;&#34;&#34;
        filepath = Path(filepath)
        if filepath.suffix == &#34;.gz&#34;:
            with gzip.open(filepath, &#34;rt&#34;, encoding=&#34;utf-8&#34;) as f:
                data = json.load(f)
        else:
            with open(filepath, &#34;r&#34;, encoding=&#34;utf-8&#34;) as f:
                data = json.load(f)
        return signal._from_serializable(data,message=f&#34;loaded from {filepath}&#34;)

    def apply_poisson_baseline_filter(self, window_ratio=0.02, gain=1.0, proba=0.9):
        &#34;&#34;&#34;
        Apply a baseline filter assuming Poisson-dominated statistics with adjustable gain
        and a rejection threshold based on the Bienaymé-Tchebychev inequality.

        The signal is filtered by removing values likely caused by statistical noise
        (false peaks) using a per-point threshold defined from local statistics:

        - Local mean: $$ \mu_t = \frac{1}{w} \sum_{i \in W(t)} y_i $$
        - Local std dev: $$ \sigma_t = \sqrt{\mu_t \cdot \text{gain}} $$
        - Coefficient of variation: $$ \text{cv}_t = \frac{\sigma_t}{\mu_t} $$
        - Estimated local intensity (lambda): $$ \lambda_t = \frac{1}{\text{cv}_t^2} $$
        - Bienaymé-Tchebychev threshold: $$ \text{threshold}_t = \frac{1}{\sqrt{1 - p}} \cdot \sqrt{10 \lambda_t \cdot \Delta t} $$

        Parameters
        ----------
        window_ratio : float, default=0.02
            Ratio of signal length used as window size (must yield odd integer ≥ 11).
        gain : float, default=1.0
            Linear amplification factor applied to simulate signal counts.
        proba : float, default=0.9
            Minimum probability to consider a signal point significant. Must be in (0, 1).

        Returns
        -------
        signal
            The current signal instance (self), with updated `y`.

        Raises
        ------
        ValueError
            If the window size is too small for reliable statistics.
        &#34;&#34;&#34;
        import numpy as np

        y = self.y
        n = len(y)

        # --- Window size ---
        w = int(window_ratio * n)
        if w &lt; 11:
            raise ValueError(f&#34;Window too small ({w} &lt; 11); increase signal length or window_ratio.&#34;)
        if w % 2 == 0:
            w += 1

        # --- Sliding window views ---
        padded = np.pad(y, w//2, mode=&#39;reflect&#39;)
        windows = sliding_window_view(padded, w)  # shape: (n, w)
        # --- Robust local statistics ---
        local_mean = np.mean(windows, axis=1)
        local_std = np.std(windows, axis=1)
        # Prevent division by zero
        eps = 1e-12
        cv = np.where(local_mean &gt; eps, local_std / local_mean, np.inf)
        # Estimate lambda from CV (avoid inf/NaN)
        lam = np.where(cv &gt; 0, 1 / (cv ** 2), 0)
        # Bienaymé-Tchebychev threshold with gain
        delta_t = self.sampling_dt if hasattr(self, &#34;sampling_dt&#34;) else 1.0
        k = 1 / np.sqrt(1 - proba)
        threshold = k * np.sqrt(lam * delta_t * gain)

        # --- Backup and History ---
        self.backup()
        event = f&#34;apply_poisson_baseline_filter(window={w}, proba={proba:.2f}, gain={gain})&#34;
        self._events(&#34;filter&#34;, {&#34;from&#34;: event})

        # --- Apply filter ---
        self.y = np.where(self.y &gt; threshold, self.y, 0.0)
        return self


    def _toDNA(self,encode=True,scales=[1,3,4,8,16,32]):
        &#34;&#34;&#34;
        Return a DNA encoded signal

        Parameters
            encode : bool (default=True)
            scales : list (default=[1,3,4,8,16,32])
        &#34;&#34;&#34;
        return DNAsignal(self,encode=encode)</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="signomics.signal.from_peaks"><code class="name flex">
<span>def <span class="ident">from_peaks</span></span>(<span>peaks_obj, x=None, generator_map=None, name='from_peaks', x0=None, n=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a signal from a set of peaks.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>peaks_obj</code></strong> :&ensp;<code><a title="signomics.peaks" href="#signomics.peaks">peaks</a></code></dt>
<dd>A list-like object containing peak definitions.</dd>
<dt><strong><code>x</code></strong> :&ensp;<code>array-like, float,</code> or <code>None</code></dt>
<dd>If None: compute x domain from peaks.
If scalar: interpreted as xmax; linspace from x0 to xmax.
If array: use as x directly.</dd>
<dt><strong><code>generator_map</code></strong> :&ensp;<code>dict</code> or <code>None</code></dt>
<dd>Optional map of peak type → generator instance (default is Gaussian).</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the signal instance.</dd>
<dt><strong><code>x0</code></strong> :&ensp;<code>float</code> or <code>None</code></dt>
<dd>Left bound of the domain (used only if x is None or scalar).
If None: inferred from peaks.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of points in the generated x array.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>A new signal instance generated from the peaks.</dd>
</dl>
<h2 id="example">Example</h2>
<p>p = peaks()
p.add(x=[400, 800, 1600], w=30, h=[1.0, 0.6, 0.9], type="gauss")
s = signal.from_peaks(p, x0=300, n=2048)
s.plot()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_peaks(cls, peaks_obj, x=None, generator_map=None, name=&#34;from_peaks&#34;, x0=None, n=1000):
    &#34;&#34;&#34;
    Generate a signal from a set of peaks.

    Parameters
    ----------
    peaks_obj : peaks
        A list-like object containing peak definitions.
    x : array-like, float, or None
        If None: compute x domain from peaks.
        If scalar: interpreted as xmax; linspace from x0 to xmax.
        If array: use as x directly.
    generator_map : dict or None
        Optional map of peak type → generator instance (default is Gaussian).
    name : str
        Name of the signal instance.
    x0 : float or None
        Left bound of the domain (used only if x is None or scalar).
        If None: inferred from peaks.
    n : int
        Number of points in the generated x array.

    Returns
    -------
    signal
        A new signal instance generated from the peaks.

    Example
    -------
    p = peaks()
    p.add(x=[400, 800, 1600], w=30, h=[1.0, 0.6, 0.9], type=&#34;gauss&#34;)
    s = signal.from_peaks(p, x0=300, n=2048)
    s.plot()
    &#34;&#34;&#34;
    if x is None:
        xmin = min(p[&#39;x&#39;] - 3 * p[&#39;w&#39;] for p in peaks_obj)
        xmax = max(p[&#39;x&#39;] + 3 * p[&#39;w&#39;] for p in peaks_obj)
        if x0 is not None:
            xmin = x0
        x = np.linspace(xmin, xmax, n)
    elif np.isscalar(x):
        xmin = x0 if x0 is not None else min(p[&#39;x&#39;] - 3 * p[&#39;w&#39;] for p in peaks_obj)
        x = np.linspace(xmin, float(x), n)
    else:
        x = np.asarray(x)

    y = np.zeros_like(x)
    generator_map = generator_map or {}
    for p in peaks_obj:
        g = generator_map.get(p[&#39;type&#39;], generator(p[&#39;type&#39;]))
        y += g(x, p[&#39;x&#39;], p[&#39;w&#39;], p[&#39;h&#39;])
    s = cls(x, y, name=name)
    s.source = &#34;peaks&#34;
    return s</code></pre>
</details>
</dd>
<dt id="signomics.signal.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a signal from a JSON or gzipped JSON file, including recursive _previous.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code></dt>
<dd>Path to the JSON or .gz file</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>A fully reconstructed signal object</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def load(filepath):
    &#34;&#34;&#34;
    Load a signal from a JSON or gzipped JSON file, including recursive _previous.

    Parameters
    ----------
    filepath : str or Path
        Path to the JSON or .gz file

    Returns
    -------
    signal
        A fully reconstructed signal object
    &#34;&#34;&#34;
    filepath = Path(filepath)
    if filepath.suffix == &#34;.gz&#34;:
        with gzip.open(filepath, &#34;rt&#34;, encoding=&#34;utf-8&#34;) as f:
            data = json.load(f)
    else:
        with open(filepath, &#34;r&#34;, encoding=&#34;utf-8&#34;) as f:
            data = json.load(f)
    return signal._from_serializable(data,message=f&#34;loaded from {filepath}&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="signomics.signal.n"><code class="name">var <span class="ident">n</span></code></dt>
<dd>
<div class="desc"><p>Return the length of the signal and None if it is None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def n(self):
    &#34;&#34;&#34;Return the length of the signal and None if it is None&#34;&#34;&#34;
    return len(self.y) if self.y is not None else None</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="signomics.signal.add_noise"><code class="name flex">
<span>def <span class="ident">add_noise</span></span>(<span>self, kind='gaussian', scale=1.0, bias=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a new signal with noise and/or bias added.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_noise(self, kind=&#34;gaussian&#34;, scale=1.0, bias=None):
    &#34;&#34;&#34;Return a new signal with noise and/or bias added.&#34;&#34;&#34;
    new_y = self.y.copy()

    # --- Apply bias ---
    if bias is not None:
        if isinstance(bias, (int, float)):
            new_y += bias
        elif isinstance(bias, np.ndarray):
            if bias.shape != self.x.shape:
                raise ValueError(&#34;Bias array must match x domain.&#34;)
            new_y += bias
        elif bias == &#34;ramp&#34;:
            ramp = np.linspace(0, 1, len(self.x))
            new_y += ramp
        elif isinstance(bias, signal):
            interp_bias = np.interp(self.x, bias.x, bias.y)
            new_y += interp_bias
        else:
            raise TypeError(&#34;Invalid bias type.&#34;)

    # --- Apply noise ---
    rng = np.random.default_rng()
    if kind == &#34;gaussian&#34;:
        new_y += rng.normal(loc=0.0, scale=scale, size=self.y.shape)
    elif kind == &#34;poisson&#34;:
        if np.any(new_y &lt; 0):
            raise ValueError(&#34;Poisson noise requires non-negative values.&#34;)
        new_y = rng.poisson(lam=new_y * scale) / scale
    else:
        raise ValueError(&#34;Unknown noise type.&#34;)

    return signal(self.x.copy(), new_y, name=self.name + &#34;+noise&#34;, source=self.source + &#34;+noise&#34;)</code></pre>
</details>
</dd>
<dt id="signomics.signal.align_with"><code class="name flex">
<span>def <span class="ident">align_with</span></span>(<span>self, other, mode='union', n=1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Align two signals to a common x grid with interpolation and padding.</p>
<h2 id="parameters">Parameters</h2>
<p>other (signal): the other signal to align with
mode (str): 'union' (default) or 'intersection'
n (int): number of points for the new grid</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>(self_interp, other_interp) as new signal instances</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def align_with(self, other, mode=&#39;union&#39;, n=1000):
    &#34;&#34;&#34;
    Align two signals to a common x grid with interpolation and padding.

    Parameters:
        other (signal): the other signal to align with
        mode (str): &#39;union&#39; (default) or &#39;intersection&#39;
        n (int): number of points for the new grid

    Returns:
        tuple: (self_interp, other_interp) as new signal instances
    &#34;&#34;&#34;
    if not isinstance(other, signal):
        raise TypeError(&#34;Can only align with another signal.&#34;)

    # Determine new x-axis
    if mode == &#39;union&#39;:
        x_min = min(self.x[0], other.x[0])
        x_max = max(self.x[-1], other.x[-1])
    elif mode == &#39;intersection&#39;:
        x_min = max(self.x[0], other.x[0])
        x_max = min(self.x[-1], other.x[-1])
        if x_min &gt;= x_max:
            raise ValueError(&#34;No overlapping x-range for &#39;intersection&#39; mode.&#34;)
    else:
        raise ValueError(&#34;mode must be &#39;union&#39; or &#39;intersection&#39;&#34;)

    x_new = np.linspace(x_min, x_max, n)

    # Interpolate and zero outside original domain
    def interp_with_padding(sig):
        y_new = np.interp(x_new, sig.x, sig.y, left=0, right=0)
        return signal(x_new, y_new, name=sig.name, source=sig.source)

    return interp_with_padding(self), interp_with_padding(other)</code></pre>
</details>
</dd>
<dt id="signomics.signal.apply_poisson_baseline_filter"><code class="name flex">
<span>def <span class="ident">apply_poisson_baseline_filter</span></span>(<span>self, window_ratio=0.02, gain=1.0, proba=0.9)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply a baseline filter assuming Poisson-dominated statistics with adjustable gain
and a rejection threshold based on the Bienaymé-Tchebychev inequality.</p>
<p>The signal is filtered by removing values likely caused by statistical noise
(false peaks) using a per-point threshold defined from local statistics:</p>
<ul>
<li>Local mean: $$ \mu_t =
rac{1}{w} \sum_{i \in W(t)} y_i $$</li>
<li>Local std dev: $$ \sigma_t = \sqrt{\mu_t \cdot
ext{gain}} $$</li>
<li>Coefficient of variation: $$
ext{cv}_t =
rac{\sigma_t}{\mu_t} $$</li>
<li>Estimated local intensity (lambda): $$ \lambda_t =
rac{1}{
ext{cv}_t^2} $$</li>
<li>Bienaymé-Tchebychev threshold: $$
ext{threshold}_t =
rac{1}{\sqrt{1 - p}} \cdot \sqrt{10 \lambda_t \cdot \Delta t} $$</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>window_ratio</code></strong> :&ensp;<code>float</code>, default=<code>0.02</code></dt>
<dd>Ratio of signal length used as window size (must yield odd integer ≥ 11).</dd>
<dt><strong><code>gain</code></strong> :&ensp;<code>float</code>, default=<code>1.0</code></dt>
<dd>Linear amplification factor applied to simulate signal counts.</dd>
<dt><strong><code>proba</code></strong> :&ensp;<code>float</code>, default=<code>0.9</code></dt>
<dd>Minimum probability to consider a signal point significant. Must be in (0, 1).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>The current signal instance (self), with updated <code>y</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the window size is too small for reliable statistics.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_poisson_baseline_filter(self, window_ratio=0.02, gain=1.0, proba=0.9):
    &#34;&#34;&#34;
    Apply a baseline filter assuming Poisson-dominated statistics with adjustable gain
    and a rejection threshold based on the Bienaymé-Tchebychev inequality.

    The signal is filtered by removing values likely caused by statistical noise
    (false peaks) using a per-point threshold defined from local statistics:

    - Local mean: $$ \mu_t = \frac{1}{w} \sum_{i \in W(t)} y_i $$
    - Local std dev: $$ \sigma_t = \sqrt{\mu_t \cdot \text{gain}} $$
    - Coefficient of variation: $$ \text{cv}_t = \frac{\sigma_t}{\mu_t} $$
    - Estimated local intensity (lambda): $$ \lambda_t = \frac{1}{\text{cv}_t^2} $$
    - Bienaymé-Tchebychev threshold: $$ \text{threshold}_t = \frac{1}{\sqrt{1 - p}} \cdot \sqrt{10 \lambda_t \cdot \Delta t} $$

    Parameters
    ----------
    window_ratio : float, default=0.02
        Ratio of signal length used as window size (must yield odd integer ≥ 11).
    gain : float, default=1.0
        Linear amplification factor applied to simulate signal counts.
    proba : float, default=0.9
        Minimum probability to consider a signal point significant. Must be in (0, 1).

    Returns
    -------
    signal
        The current signal instance (self), with updated `y`.

    Raises
    ------
    ValueError
        If the window size is too small for reliable statistics.
    &#34;&#34;&#34;
    import numpy as np

    y = self.y
    n = len(y)

    # --- Window size ---
    w = int(window_ratio * n)
    if w &lt; 11:
        raise ValueError(f&#34;Window too small ({w} &lt; 11); increase signal length or window_ratio.&#34;)
    if w % 2 == 0:
        w += 1

    # --- Sliding window views ---
    padded = np.pad(y, w//2, mode=&#39;reflect&#39;)
    windows = sliding_window_view(padded, w)  # shape: (n, w)
    # --- Robust local statistics ---
    local_mean = np.mean(windows, axis=1)
    local_std = np.std(windows, axis=1)
    # Prevent division by zero
    eps = 1e-12
    cv = np.where(local_mean &gt; eps, local_std / local_mean, np.inf)
    # Estimate lambda from CV (avoid inf/NaN)
    lam = np.where(cv &gt; 0, 1 / (cv ** 2), 0)
    # Bienaymé-Tchebychev threshold with gain
    delta_t = self.sampling_dt if hasattr(self, &#34;sampling_dt&#34;) else 1.0
    k = 1 / np.sqrt(1 - proba)
    threshold = k * np.sqrt(lam * delta_t * gain)

    # --- Backup and History ---
    self.backup()
    event = f&#34;apply_poisson_baseline_filter(window={w}, proba={proba:.2f}, gain={gain})&#34;
    self._events(&#34;filter&#34;, {&#34;from&#34;: event})

    # --- Apply filter ---
    self.y = np.where(self.y &gt; threshold, self.y, 0.0)
    return self</code></pre>
</details>
</dd>
<dt id="signomics.signal.backup"><code class="name flex">
<span>def <span class="ident">backup</span></span>(<span>self, fullhistory=None, message=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Backup current state in _previous</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def backup(self,fullhistory=None,message=None):
    &#34;&#34;&#34;Backup current state in _previous&#34;&#34;&#34;
    previous = self.copy()
    fullhistory = self._fullhistory if fullhistory is None else fullhistory
    if not fullhistory:
        previous._previous = None
    self._previous = previous
    self._events(&#34;backup&#34;, {&#34;from&#34;: self._fullhistory,&#39;message&#39;: message})</code></pre>
</details>
</dd>
<dt id="signomics.signal.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Deep copy of the signal, excluding full history control flag</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self):
    &#34;&#34;&#34;Deep copy of the signal, excluding full history control flag&#34;&#34;&#34;
    new = signal(
        x=self.x.copy() if self.x is not None else None,
        y=self.y.copy() if self.y is not None else None,
        name=self.name,
        type=self.type,
        x_label=self.x_label,
        x_unit=self.x_unit,
        y_label=self.y_label,
        y_unit=self.y_unit,
        metadata=self.metadata.copy(),
        source=self.source,
        color=self.color,
        linewidth=self.linewidth,
        linestyle=self.linestyle,
        fullhistory=self._fullhistory
    )
    new._history = self._history.copy()
    if self._fullhistory and self._previous is not None:
        new._previous = self._previous.copy()
    else:
        new._previous = None
    return new</code></pre>
</details>
</dd>
<dt id="signomics.signal.disable_fullhistory"><code class="name flex">
<span>def <span class="ident">disable_fullhistory</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Disable full history tracking</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def disable_fullhistory(self):
    &#34;&#34;&#34;Disable full history tracking&#34;&#34;&#34;
    set._fullhistory = True
    self._previous = False
    self._events(&#34;disable full history&#34;, {&#34;from&#34;: &#34;disable_fullhistory&#34;})</code></pre>
</details>
</dd>
<dt id="signomics.signal.enable_fullhistory"><code class="name flex">
<span>def <span class="ident">enable_fullhistory</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Enable full history tracking</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def enable_fullhistory(self):
    &#34;&#34;&#34;Enable full history tracking&#34;&#34;&#34;
    self._events(&#34;enable full history&#34;, {&#34;from&#34;: &#34;enable_fullhistory&#34;})
    set._fullhistory = True</code></pre>
</details>
</dd>
<dt id="signomics.signal.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, ax=None, label=None, color=None, linestyle=None, linewidth=None, fontsize=12, newfig=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the signal using matplotlib, applying either internal style settings
or overrides provided at call time.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib.axes.Axes</code>, optional</dt>
<dd>Axis to plot on. If None, uses current axis or new figure if newfig=True.</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Legend label. Defaults to self.name.</dd>
<dt><strong><code>color</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Line color. If None, uses default matplotlib cycling.</dd>
<dt><strong><code>linestyle</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>Line style (e.g., '-', '&ndash;'). If None, uses self.linestyle.</dd>
<dt><strong><code>linewidth</code></strong> :&ensp;<code>float</code> or <code>None</code></dt>
<dd>Line width. If None, uses self.linewidth.</dd>
<dt><strong><code>fontsize</code></strong> :&ensp;<code>int</code> or <code>str</code></dt>
<dd>Font size for axis labels and legend. Can use values like 'small', 'large'.</dd>
<dt><strong><code>newfig</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, creates a new figure before plotting.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>matplotlib.figure.Figure</code></dt>
<dd>&nbsp;</dd>
<dt><code>matplotlib.axes.Axes</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, ax=None, label=None, color=None, linestyle=None, linewidth=None,
         fontsize=12, newfig=False):
    &#34;&#34;&#34;
    Plot the signal using matplotlib, applying either internal style settings
    or overrides provided at call time.

    Parameters
    ----------
    ax : matplotlib.axes.Axes, optional
        Axis to plot on. If None, uses current axis or new figure if newfig=True.
    label : str, optional
        Legend label. Defaults to self.name.
    color : str or None
        Line color. If None, uses default matplotlib cycling.
    linestyle : str or None
        Line style (e.g., &#39;-&#39;, &#39;--&#39;). If None, uses self.linestyle.
    linewidth : float or None
        Line width. If None, uses self.linewidth.
    fontsize : int or str
        Font size for axis labels and legend. Can use values like &#39;small&#39;, &#39;large&#39;.
    newfig : bool
        If True, creates a new figure before plotting.

    Returns
    -------
    matplotlib.figure.Figure
    matplotlib.axes.Axes
    &#34;&#34;&#34;
    # Convert font size keywords to numeric
    fontsize_map = {
        &#34;xx-small&#34;: 6, &#34;x-small&#34;: 8, &#34;small&#34;: 10,
        &#34;medium&#34;: 12, &#34;large&#34;: 14, &#34;x-large&#34;: 16, &#34;xx-large&#34;: 18
    }
    if isinstance(fontsize, str):
        fontsize = fontsize_map.get(fontsize.lower(), 12)

    if newfig:
        fig = plt.figure()
    else:
        fig = plt.gcf()

    ax = ax or plt.gca()

    # Final style resolution
    label = label if label is not None else self.name
    color = color if color is not None else self.color
    linestyle = linestyle if linestyle is not None else self.linestyle
    linewidth = linewidth if linewidth is not None else self.linewidth

    # Plot
    if self.x is None:
        ax.plot(self.y, label=label, color=color,
                linestyle=linestyle, linewidth=linewidth)
    else:
        ax.plot(self.x, self.y, label=label, color=color,
                linestyle=linestyle, linewidth=linewidth)

    # Axes labeling and legend
    if self.x_label and self.x_unit:
        ax.set_xlabel(f&#34;{self.x_label} [{self.x_unit}]&#34;, fontsize=fontsize)
    elif self.x_label:
        ax.set_xlabel(self.x_label, fontsize=fontsize)

    if self.y_label and self.y_unit:
        ax.set_ylabel(f&#34;{self.y_label} [{self.y_unit}]&#34;, fontsize=fontsize)
    elif self.y_label:
        ax.set_ylabel(self.y_label, fontsize=fontsize)

    if label:
        ax.legend(fontsize=fontsize)

    return fig, ax</code></pre>
</details>
</dd>
<dt id="signomics.signal.restore"><code class="name flex">
<span>def <span class="ident">restore</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Restore the previous signal version if available</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def restore(self):
    &#34;&#34;&#34;Restore the previous signal version if available&#34;&#34;&#34;
    if hasattr(self, &#34;_previous&#34;) and isinstance(self._previous, signal):
        restored = self._previous.copy()
        for attr in [&#39;x&#39;, &#39;y&#39;, &#39;name&#39;, &#39;type&#39;, &#39;x_label&#39;, &#39;x_unit&#39;,
                     &#39;y_label&#39;, &#39;y_unit&#39;, &#39;color&#39;, &#39;linestyle&#39;,
                     &#39;linewidth&#39;, &#39;source&#39;, &#39;metadata&#39;, &#39;_previous&#39;, &#39;_history&#39;]:
            setattr(self, attr, getattr(restored, attr))
        self._events(&#34;restore&#34;, {&#34;from&#34;: restored.name})
    else:
        raise AttributeError(&#34;No previous signal to restore&#34;)</code></pre>
</details>
</dd>
<dt id="signomics.signal.sample"><code class="name flex">
<span>def <span class="ident">sample</span></span>(<span>self, x_new)</span>
</code></dt>
<dd>
<div class="desc"><p>Interpolate values from x</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample(self, x_new):
    &#34;&#34;&#34;Interpolate values from x&#34;&#34;&#34;
    return np.interp(x_new, self.x, self.y)</code></pre>
</details>
</dd>
<dt id="signomics.signal.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filepath=None, zip=True, export_csv=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Save signal to JSON (optionally compressed) and optionally CSV.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code> or <code>Path</code> or <code>None</code></dt>
<dd>If None, builds path from metadata['cwd'] and self.name + '.json[.gz]'.
If a directory, appends name + '.json[.gz]'.
If a file, uses as is.</dd>
<dt><strong><code>zip</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to compress the JSON file using gzip. Default: True.</dd>
<dt><strong><code>export_csv</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, also save a .csv file (x,y) alongside the JSON.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, filepath=None, zip=True, export_csv=False):
    &#34;&#34;&#34;
    Save signal to JSON (optionally compressed) and optionally CSV.

    Parameters
    ----------
    filepath : str or Path or None
        If None, builds path from metadata[&#39;cwd&#39;] and self.name + &#39;.json[.gz]&#39;.
        If a directory, appends name + &#39;.json[.gz]&#39;.
        If a file, uses as is.
    zip : bool
        Whether to compress the JSON file using gzip. Default: True.
    export_csv : bool
        If True, also save a .csv file (x,y) alongside the JSON.
    &#34;&#34;&#34;
    # Resolve filepath
    if filepath is None:
        filepath = os.path.join(self.metadata[&#34;cwd&#34;], f&#34;{self.name}.json.gz&#34; if zip else f&#34;{self.name}.json&#34;)
    elif os.path.isdir(filepath):
        filepath = os.path.join(filepath, f&#34;{self.name}.json.gz&#34; if zip else f&#34;{self.name}.json&#34;)
    filepath = Path(filepath)
    data = self._to_serializable()
    if zip or str(filepath).endswith(&#34;.gz&#34;):
        with gzip.open(filepath, &#34;wt&#34;, encoding=&#34;utf-8&#34;) as f:
            json.dump(data, f, indent=2)
    else:
        with open(filepath, &#34;w&#34;, encoding=&#34;utf-8&#34;) as f:
            json.dump(data, f, indent=2)

    # Optionally export to CSV
    if export_csv and self.x is not None and self.y is not None:
        csv_path = filepath.with_suffix(&#34;.csv&#34;)
        with open(csv_path, &#34;w&#34;, encoding=&#34;utf-8&#34;) as f:
            f.write(&#34;x,y\n&#34;)
            for xi, yi in zip(self.x, self.y):
                f.write(f&#34;{xi},{yi}\n&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="signomics.signal_collection"><code class="flex name class">
<span>class <span class="ident">signal_collection</span></span>
<span>(</span><span>*signals, n=1024, mode='union', name=None, force=True)</span>
</code></dt>
<dd>
<div class="desc"><p>A container class for multiple <code><a title="signomics.signal" href="#signomics.signal">signal</a></code> instances that ensures alignment on a shared x-grid.</p>
<p>The collection is used to manage, compare, combine, or visualize multiple signals (e.g., from
replicates, experiments, synthetic scenarios). Signals are interpolated and padded on insertion
so all have the same shape and domain. Arithmetic, matrix extraction, and overlay plots are supported.</p>
<h2 id="parameters">Parameters:</h2>
<p>*signals : signal
One or more signal instances to include (they are copied and aligned).
n : int
Number of sampling points in the aligned x grid (default: 1000).
mode : str
Alignment mode: 'union' or 'intersection' of x-ranges.</p>
<h2 id="core-attributes">Core Attributes:</h2>
<p>mode : str
Alignment strategy used ("union" or "intersection").
n : int
Number of x-points used in alignment (default=1024).</p>
<h2 id="key-methods">Key Methods:</h2>
<ul>
<li>append(signal)
→ add and align a new signal</li>
<li>to_matrix()
→ convert signals to a 2D array (n_signals x n_points)</li>
<li>mean(coeffs=None)
→ weighted or unweighted mean</li>
<li>sum(coeffs=None)
→ weighted or unweighted sum</li>
<li>plot(&hellip;)
→ overlay signals with optional mean/sum</li>
<li>copy
→ all signals stored are deep copies</li>
<li>generate_synthetic
→ signal collection composed of random peaks.</li>
<li><strong>getitem</strong>(&hellip;)
→ slice, list, or name-based access to signals</li>
<li><strong>repr</strong> / <strong>str</strong>
→ report contents with span and names</li>
<li>_toDNA(signal_collection)
→ list of DNAsignals</li>
</ul>
<h2 id="access-patterns">Access Patterns:</h2>
<ul>
<li>sc[0:3]
→ subcollection by slice</li>
<li>sc[[0, 2]]
→ subcollection by list of indices</li>
<li>sc["name"]
→ return a copy of signal with that name</li>
<li>sc["A", "B"]
→ return a subcollection with those names</li>
</ul>
<h2 id="examples">Examples:</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; sc = signal_collection(s1, s2, s3)
&gt;&gt;&gt; sc.plot(show_mean=True)
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; sc[0:2]         # sub-collection (copy)
&gt;&gt;&gt; sc[&quot;peak1&quot;]     # get copy of signal named 'peak1'
&gt;&gt;&gt; mat = sc.to_matrix()
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; sc.mean().plot()
&gt;&gt;&gt; sc.sum(coeffs=[0.4, 0.6]).plot()
</code></pre>
<p>Initialize collection with aligned signals of the same type.</p>
<h2 id="parameters_1">Parameters</h2>
<dl>
<dt><strong><code>*signals</code></strong> :&ensp;<code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>Signal instances to include.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int (default=1000)</code></dt>
<dd>Number of points on the common x grid.</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>str (default="union")</code></dt>
<dd>'union' or 'intersection' for domain alignment.</dd>
<dt><strong><code>force</code></strong> :&ensp;<code>bool (default=True)</code></dt>
<dd>If False, require all signals to have the same type.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class signal_collection(list):
    &#34;&#34;&#34;
    A container class for multiple `signal` instances that ensures alignment on a shared x-grid.

    The collection is used to manage, compare, combine, or visualize multiple signals (e.g., from
    replicates, experiments, synthetic scenarios). Signals are interpolated and padded on insertion
    so all have the same shape and domain. Arithmetic, matrix extraction, and overlay plots are supported.

    Parameters:
    -----------
    *signals : signal
        One or more signal instances to include (they are copied and aligned).
    n : int
        Number of sampling points in the aligned x grid (default: 1000).
    mode : str
        Alignment mode: &#39;union&#39; or &#39;intersection&#39; of x-ranges.

    Core Attributes:
    ----------------
    mode : str
        Alignment strategy used (&#34;union&#34; or &#34;intersection&#34;).
    n : int
        Number of x-points used in alignment (default=1024).

    Key Methods:
    ------------
    - append(signal)              → add and align a new signal
    - to_matrix()                 → convert signals to a 2D array (n_signals x n_points)
    - mean(coeffs=None)           → weighted or unweighted mean
    - sum(coeffs=None)            → weighted or unweighted sum
    - plot(...)                   → overlay signals with optional mean/sum
    - copy                        → all signals stored are deep copies
    - generate_synthetic          → signal collection composed of random peaks.
    - __getitem__(...)            → slice, list, or name-based access to signals
    - __repr__ / __str__          → report contents with span and names
    - _toDNA(signal_collection)   → list of DNAsignals

    Access Patterns:
    ----------------
    - sc[0:3]           → subcollection by slice
    - sc[[0, 2]]        → subcollection by list of indices
    - sc[&#34;name&#34;]        → return a copy of signal with that name
    - sc[&#34;A&#34;, &#34;B&#34;]      → return a subcollection with those names

    Examples:
    ---------
    &gt;&gt;&gt; sc = signal_collection(s1, s2, s3)
    &gt;&gt;&gt; sc.plot(show_mean=True)

    &gt;&gt;&gt; sc[0:2]         # sub-collection (copy)
    &gt;&gt;&gt; sc[&#34;peak1&#34;]     # get copy of signal named &#39;peak1&#39;
    &gt;&gt;&gt; mat = sc.to_matrix()

    &gt;&gt;&gt; sc.mean().plot()
    &gt;&gt;&gt; sc.sum(coeffs=[0.4, 0.6]).plot()
    &#34;&#34;&#34;

    def __init__(self, *signals, n=1024, mode=&#39;union&#39;, name=None, force=True):
        &#34;&#34;&#34;
        Initialize collection with aligned signals of the same type.

        Parameters
        ----------
        *signals : signal
            Signal instances to include.
        n : int (default=1000)
            Number of points on the common x grid.
        mode : str (default=&#34;union&#34;)
            &#39;union&#39; or &#39;intersection&#39; for domain alignment.
        force : bool (default=True)
            If False, require all signals to have the same type.
        &#34;&#34;&#34;
        nsignals = len(signals)
        self.name = f&#34;Collection of {nsignals} signals&#34; if name is None else name
        self.mode = mode
        self.n = n
        if not force and nsignals &gt; 1:
            types = {s.type for s in signals}
            if len(types) &gt; 1:
                raise ValueError(f&#34;Incompatible signal types: {types}. Use force=True to override.&#34;)
        s_copy = [s.copy() for s in signals]
        for s in s_copy:
            if s.x is None:
                s.x = np.linspace(0,s.n-1,s.n,endpoint=True,dtype=np.uint32)
        aligned = self._align_all(s_copy)
        super().__init__(aligned)
        self._plotted_once = False # flag to track plotting

    def append(self, new_signal):
        &#34;&#34;&#34;Append and align the new signal to the existing collection.&#34;&#34;&#34;
        aligned = self._align_all(self + [new_signal.copy()])
        self.clear()
        self.extend(aligned)

    def __getitem__(self, key):
        &#34;&#34;&#34;
            sc[&#34;my_signal&#34;]                  # returns a copy of the signal named &#34;my_signal&#34;
            sc[&#34;A&#34;, &#34;B&#34;, &#34;C&#34;]                # returns a sub-collection with those names
            sc[0:2] or sc[[0, 2]]            # still works for index-based access
        &#34;&#34;&#34;
        if isinstance(key, slice):
            return signal_collection(*(s.copy() for s in super().__getitem__(key)))
        elif isinstance(key, list):
            return signal_collection(*(self[k].copy() for k in key))
        elif isinstance(key, tuple):
            return signal_collection(*(s.copy() for s in self if s.name in key))
        elif isinstance(key, str):
            for s in self:
                if s.name == key:
                    return s.copy()
            raise KeyError(f&#34;No signal named &#39;{key}&#39; in collection.&#34;)
        else:
            return super().__getitem__(key)


    def __setitem__(self, key, value):
        if not isinstance(value, signal):
            raise TypeError(&#34;Only signal instances can be assigned.&#34;)
        aligned = self._align_all(self[:key] + [value.copy()] + self[key+1:])
        super().__setitem__(key, aligned[key])

    def __delitem__(self, key):
        if isinstance(key, list):
            # delete in reverse to preserve indices
            for k in sorted(key, reverse=True):
                super().__delitem__(k)
        else:
            super().__delitem__(key)

    def _align_all(self, signals):
        if not signals:
            return []
        # Determine common grid
        x_min = min(s.x[0] for s in signals)
        x_max = max(s.x[-1] for s in signals)
        x_common = np.linspace(x_min, x_max, self.n)
        # Interpolate all to shared grid
        aligned = [signal(x_common, np.interp(x_common, s.x, s.y, left=0, right=0),
                          name=s.name, source=s.source) for s in signals]
        return aligned

    def __str__(self):
        return f&#34;&lt;signal_collection with {len(self)} aligned signals&gt;&#34;

    def __repr__(self):
        lines = [f&#34;[{i}] &#39;{s.name}&#39; span=({s.x[0]:.2f}, {s.x[-1]:.2f})&#34; for i, s in enumerate(self)]
        print(&#34;&lt;signal_collection&gt;\n&#34; + &#34;\n&#34;.join(lines))
        return str(self)

    def to_matrix(self):
        &#34;&#34;&#34;Return a 2D array (n_signals x n_points) of aligned signal values.&#34;&#34;&#34;
        return np.vstack([s.y for s in self])

    def sum(self, indices_or_names=None, coeffs=None):
        &#34;&#34;&#34;
        Sum selected signals, optionally weighted by coeffs.

        Parameters
        ----------
        indices_or_names : list[int or str], optional
            If provided, selects a subset by index or name.
        coeffs : list[float], optional
            Weights matching the number of selected signals.

        Returns
        -------
        signal
            Summed signal.
        &#34;&#34;&#34;
        if indices_or_names is None:
            selected = self
        else:
            selected = []
            for k in indices_or_names:
                if isinstance(k, int):
                    selected.append(self[k])
                elif isinstance(k, str):
                    found = next((s for s in self if s.name == k), None)
                    if found is None:
                        raise KeyError(f&#34;Signal name &#39;{k}&#39; not found.&#34;)
                    selected.append(found)
                else:
                    raise TypeError(&#34;indices_or_names must contain ints or strs.&#34;)

        matrix = np.vstack([s.y for s in selected])
        if coeffs is not None:
            coeffs = np.asarray(coeffs)
            if coeffs.shape[0] != len(selected):
                raise ValueError(&#34;Length of coeffs must match number of selected signals.&#34;)
            result = np.dot(coeffs, matrix)
        else:
            result = np.sum(matrix, axis=0)

        return signal(selected[0].x.copy(), result, name=&#34;sum&#34;, source=&#34;signal_collection&#34;)

    def mean(self, indices_or_names=None, coeffs=None):
        &#34;&#34;&#34;
        Mean of selected signals, optionally weighted.

        Parameters
        ----------
        indices_or_names : list[int or str], optional
            Signal names or indices to include.
        coeffs : list[float], optional
            Weights for selected signals.

        Returns
        -------
        signal
            Averaged signal.
        &#34;&#34;&#34;
        if coeffs is not None:
            total_weight = np.sum(coeffs)
        else:
            total_weight = len(indices_or_names) if indices_or_names else len(self)

        s = self.sum(indices_or_names=indices_or_names, coeffs=coeffs)
        return signal(s.x.copy(), s.y / total_weight, name=&#34;mean&#34;, source=&#34;signal_collection&#34;)

    def plot(self, indices=None, labels=True, title=None, newfig=None, ax=None,
             show_mean=False, show_sum=False, coeffs=None, fontsize=12, colormap=None):
        &#34;&#34;&#34;
        Plot selected signals with style attributes and optional overlays.

        Parameters
        ----------
        indices : list[int] or list[str], optional
            Signals to plot by index or name.
        labels : bool
            Whether to show signal labels.
        title : str
            Plot title.
        newfig : bool or None
            If True, always open a new figure.
            If False, use current axes.
            If None, open new figure only the first time this collection is plotted.
        ax : matplotlib axis, optional
            Axis to draw on.
        show_mean : bool
            Overlay mean curve.
        show_sum : bool
            Overlay sum curve.
        coeffs : list[float], optional
            Optional weights for mean/sum.
        fontsize : int or str
            Font size for labels and legend.
        colormap : list[str], optional
            List of colors to cycle through when signal.color is None.

        Returns
        -------
        matplotlib.figure.Figure
        &#34;&#34;&#34;
        if not self:
            return
        # Select signals to plot
        if indices is None:
            selected = self
        else:
            if isinstance(indices[0], str):
                selected = [s for s in self if s.name in indices]
            else:
                selected = [self[i] for i in indices]
        # Circular color iterator
        if colormap is None:
            colormap = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key().get(&#39;color&#39;, [])
        color_cycle = (colormap * ((len(selected) // len(colormap)) + 1)) if colormap else [None] * len(selected)
        # Determine whether to create new figure
        if newfig is None:
            newfig = not self._plotted_once
        if newfig:
            fig = plt.figure()
        else:
            fig = plt.gcf()
        self._plotted_once = True
        ax = ax or plt.gca()
        for i, s in enumerate(selected):
            c = s.color if s.color is not None else color_cycle[i]
            s.plot(ax=ax, label=s.name if labels else None,
                   color=c, linestyle=s.linestyle, linewidth=s.linewidth, fontsize=fontsize)
        # Overlay mean and sum
        if show_mean:
            self.mean(coeffs).plot(ax=ax, label=&#34;mean&#34;, color=&#34;black&#34;, linewidth=2, fontsize=fontsize)
        if show_sum:
            self.sum(coeffs).plot(ax=ax, label=&#34;sum&#34;, color=&#34;red&#34;, linestyle=&#34;--&#34;, linewidth=2, fontsize=fontsize)

        title = self.name if title is None else title
        title = &#34;Signal Collection&#34; if title is None else title
        ax.set_title(title, fontsize=fontsize)
        ax.tick_params(labelsize=fontsize)
        if labels:
            ax.legend(fontsize=fontsize)
        plt.show()
        return fig

    @classmethod
    def generate_synthetic(cls,
                           n_signals=5,
                           n_peaks=5,
                           kind_distribution=&#34;uniform&#34;,  # or &#34;random&#34;
                           kinds=(&#34;gauss&#34;, &#34;lorentz&#34;, &#34;triangle&#34;),
                           x_range=(0, 1000),
                           n_points=1024,
                           avoid_overlap=True,
                           width_range=(20, 60),
                           height_range=(0.5, 1.0),
                           normalize=True,
                           noise=None,    # e.g. {&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.05}
                           bias=None,     # can be scalar, &#34;ramp&#34;, or signal instance
                           name_prefix=&#34;synthetic&#34;,
                           seed=None):
        &#34;&#34;&#34;
        Generate a synthetic signal collection composed of random peaks.

        Parameters
        ----------
        n_signals : int
            Number of synthetic signals to generate.
        n_peaks : int
            Number of peaks per signal.
        kind_distribution : str
            &#39;uniform&#39; → use all peak kinds equally; &#39;random&#39; → random draw from kinds.
        kinds : tuple[str]
            Generator types to choose from (&#39;gauss&#39;, &#39;lorentz&#39;, &#39;triangle&#39;).
        x_range : tuple[float, float]
            Start and end of x-domain.
        n_points : int
            Number of sampling points for each signal (default: 1024).
        avoid_overlap : bool
            Prevent peaks from overlapping by checking spacing vs. width.
        width_range : tuple[float, float]
            Range of widths for the peaks.
        height_range : tuple[float, float]
            Range of peak heights.
        normalize : bool
            Normalize each signal so the highest peak has intensity 1.
        noise : dict or None
            Optional noise model, e.g. {&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.01}.
        bias : float, str, np.ndarray, or signal
            Optional signal bias: can be a constant, &#39;ramp&#39;, or signal.
        name_prefix : str
            Base name for each generated signal.
        seed : int or None
            Random seed for reproducibility.

        Returns
        -------
        signal_collection
            A collection of generated signals.

        Examples
        ---------
        # 1. Default random peaks, Gaussian + ramp bias
        sc = signal_collection.generate_synthetic(
            n_signals=5,
            n_peaks=6,
            kinds=(&#34;gauss&#34;, &#34;lorentz&#34;, &#34;triangle&#34;),
            noise={&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.02},
            bias=&#34;ramp&#34;,
            name_prefix=&#34;test&#34;
        )
        sc.plot(show_mean=True, fontsize=&#34;large&#34;)

        # 2. High-res signal, fixed width and height
        sc2 = signal_collection.generate_synthetic(
            n_signals=3,
            n_peaks=8,
            kinds=(&#34;gauss&#34;,),
            width_range=(30, 30),
            height_range=(1.0, 1.0),
            x_range=(0, 500),
            n_points=2048,
            normalize=False,
            seed=123
        )
        sc2.plot(fontsize=14)

        # 3. Poisson noise, no overlap, save output
        sc3 = signal_collection.generate_synthetic(
            n_signals=2,
            n_peaks=5,
            noise={&#34;kind&#34;: &#34;poisson&#34;, &#34;scale&#34;: 2.0},
            name_prefix=&#34;poisson_example&#34;
        )
        for s in sc3:
            s.save(export_csv=True)
        &#34;&#34;&#34;
        rng = np.random.default_rng(seed)
        xmin, xmax = x_range
        x = np.linspace(xmin, xmax, n_points)
        all_peak_centers = []
        all_peak_widths = []
        signals = []

        for i in range(n_signals):
            p = peaks()
            attempts = 0
            while len(p) &lt; n_peaks and attempts &lt; 100 * n_peaks:
                w = rng.uniform(*width_range)
                h = rng.uniform(*height_range)
                x0 = rng.uniform(xmin + 3 * w, xmax - 3 * w)

                # Check for global overlap
                if avoid_overlap:
                    if any(abs(x0 - xj) &lt; 3 * max(w, wj) for xj, wj in zip(all_peak_centers, all_peak_widths)):
                        attempts += 1
                        continue

                if kind_distribution == &#34;uniform&#34;:
                    kind = kinds[len(p) % len(kinds)]
                else:
                    kind = rng.choice(kinds)

                p.add(x=x0, w=w, h=h, type=kind)
                all_peak_centers.append(x0)
                all_peak_widths.append(w)
                attempts += 1

            # warning if the number of peaks is lower than expected
            if len(p) &lt; n_peaks:
                warnings.warn(f&#34;Signal {i+1}: only placed {len(p)} of {n_peaks} peaks due to overlap constraints.&#34;)

            # Generate signal
            generator_map = {k: generator(k) for k in kinds}
            s = signal.from_peaks(p, x=x, generator_map=generator_map, name=f&#34;{name_prefix}_{i+1}&#34;)
            s.y_label = &#34;intensity&#34;
            s.y_unit = &#34;a.u.&#34;

            # Normalize
            if normalize:
                ymax = np.max(np.abs(s.y))
                if ymax &gt; 0:
                    s.y /= ymax

            # Add noise or bias
            if noise:
                s = s.add_noise(**noise, bias=bias)
            elif bias is not None:
                s = s.add_noise(kind=&#34;gaussian&#34;, scale=0.0, bias=bias)  # bias only

            s._source_peaks = p
            signals.append(s)

        return cls(*signals, n=n_points, mode=&#39;union&#39;, force=True), [s._source_peaks for s in signals]

    @classmethod
    def generate_mixtures(cls,
                          n_mixtures=10,             # int
                          max_peaks = 16,            # int,
                          peaks_per_mixture = (3,8), # tuple[int, int],
                          amplitude_range = (0.5,2), # tuple[float, float],
                          flatten = &#39;mean&#39;,          # literal[&#39;sum&#39;, &#39;mean&#39;]
                          # parameters
                          n_signals=1,
                          n_peaks=1,
                          kinds=(&#34;gauss&#34;,),
                          width_range=(0.5, 3),
                          height_range=(1.0, 5.0),
                          x_range=(0, 500),
                          n_points=1024,
                          normalize=False,
                          seed=None,
                          **kwargs):
        &#34;&#34;&#34;
        Generate synthetic mixtures of signals by combining a subset of base peaks.

        Parameters
        ----------
        n_mixtures : int
            Number of synthetic mixtures to generate.

        max_peaks : int
            Maximum number of base signals (from which peaks are taken).

        peaks_per_mixture : tuple of (int, int)
            Range (min, max) for the number of peaks to combine in each mixture.
            Cannot exceed `max_peaks`.

        amplitude_range : tuple of (float, float)
            Random scaling range applied to peak amplitudes in each mixture.

        flatten : {&#39;sum&#39;, &#39;mean&#39;}, default=&#39;mean&#39;
            How to combine the signals for each mixture.

        **kwargs : dict
            All other keyword arguments passed to `generate_synthetic`.

        Returns
        -------
        result_collection : signal_collection
            A collection of synthetic mixed signals.

        all_peaks : list of dict
            All individual peaks originally generated.

        used_peak_ids : list of list of str
            For each mixture, the list of peak names used.

        Examples
        --------
        S, pS = signal_collection.generate_mixtures(
        ...     n_mixtures=30,
        ...     max_peaks=12,
        ...     peaks_per_mixture=(4, 8),
        ...     amplitude_range=(0.2, 1.5),
        ...     n_signals=12,
        ...     kinds=(&#34;gauss&#34;,),
        ...     width_range=(0.5, 3),
        ...     height_range=(1.0, 5.0),
        ...     x_range=(0, 500),
        ...     n_points=2048,
        ...     normalize=False,
        ...     seed=123
        ... )
        &gt;&gt;&gt; S.plot()
        &#34;&#34;&#34;

        # Step 1: Set defaults and validate
        if not (0 &lt; peaks_per_mixture[0] &lt;= peaks_per_mixture[1] &lt;= max_peaks):
            raise ValueError(&#34;Invalid peaks_per_mixture range.&#34;)

        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)

        # Step 2: Generate base signals and flatten peaks
        S, peak_list = cls.generate_synthetic(
            n_signals=max_peaks,
            n_peaks=n_peaks,
            kinds=(&#34;gauss&#34;,),
            width_range=width_range,
            height_range=height_range,
            x_range=x_range,
            n_points=n_points,
            normalize=normalize,
            seed=seed,
            **kwargs
            )
        peak_objs = peaks(peak_list)  # Flatten into a peak collection

        all_peaks = list(peak_objs)
        peak_id_map = {p[&#39;name&#39;]: p for p in all_peaks}

        mixtures = []
        used_peak_ids = []

        for i in range(n_mixtures):
            n_peaks_in_mix = random.randint(*peaks_per_mixture)
            selected_peaks = random.sample(all_peaks, n_peaks_in_mix)
            mixture_signal = np.zeros_like(S[0].y)

            current_ids = []
            for p in selected_peaks:
                scale = random.uniform(*amplitude_range)
                yvals = generator(p[&#39;type&#39;])(S[0].x, p[&#39;x&#39;], p[&#39;w&#39;], p[&#39;h&#39;] * scale)
                mixture_signal += yvals
                current_ids.append(p[&#39;name&#39;])

            if flatten == &#39;mean&#39;:
                mixture_signal /= len(selected_peaks)

            sig = signal(x=S[0].x, y=mixture_signal, name=f&#34;mixture {i} of {n_mixtures}&#34;)
            mixtures.append(sig)
            used_peak_ids.append(current_ids)

        result_collection = cls(*mixtures,n=n_points, mode=&#39;union&#39;, force=True)

        return result_collection, all_peaks, used_peak_ids


    def _toDNA(self,encode=True,scales=[1,3,4,8,16,32]):
        &#34;&#34;&#34;
        Return a DNA encoded signal

        Parameters
            encode : bool (default=True)
            scales : list (default=[1,3,4,8,16,32])
        &#34;&#34;&#34;
        return [DNAsignal(s,scales=scales,encode=encode) for s in self]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.list</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="signomics.signal_collection.generate_mixtures"><code class="name flex">
<span>def <span class="ident">generate_mixtures</span></span>(<span>n_mixtures=10, max_peaks=16, peaks_per_mixture=(3, 8), amplitude_range=(0.5, 2), flatten='mean', n_signals=1, n_peaks=1, kinds=('gauss',), width_range=(0.5, 3), height_range=(1.0, 5.0), x_range=(0, 500), n_points=1024, normalize=False, seed=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate synthetic mixtures of signals by combining a subset of base peaks.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n_mixtures</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of synthetic mixtures to generate.</dd>
<dt><strong><code>max_peaks</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum number of base signals (from which peaks are taken).</dd>
<dt><strong><code>peaks_per_mixture</code></strong> :&ensp;<code>tuple</code> of <code>(int, int)</code></dt>
<dd>Range (min, max) for the number of peaks to combine in each mixture.
Cannot exceed <code>max_peaks</code>.</dd>
<dt><strong><code>amplitude_range</code></strong> :&ensp;<code>tuple</code> of <code>(float, float)</code></dt>
<dd>Random scaling range applied to peak amplitudes in each mixture.</dd>
<dt><strong><code>flatten</code></strong> :&ensp;<code>{'sum', 'mean'}</code>, default=<code>'mean'</code></dt>
<dd>How to combine the signals for each mixture.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>All other keyword arguments passed to <code>generate_synthetic</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result_collection</code></strong> :&ensp;<code><a title="signomics.signal_collection" href="#signomics.signal_collection">signal_collection</a></code></dt>
<dd>A collection of synthetic mixed signals.</dd>
<dt><strong><code>all_peaks</code></strong> :&ensp;<code>list</code> of <code>dict</code></dt>
<dd>All individual peaks originally generated.</dd>
<dt><strong><code>used_peak_ids</code></strong> :&ensp;<code>list</code> of <code>list</code> of <code>str</code></dt>
<dd>For each mixture, the list of peak names used.</dd>
</dl>
<h2 id="examples">Examples</h2>
<p>S, pS = signal_collection.generate_mixtures(
&hellip;
n_mixtures=30,
&hellip;
max_peaks=12,
&hellip;
peaks_per_mixture=(4, 8),
&hellip;
amplitude_range=(0.2, 1.5),
&hellip;
n_signals=12,
&hellip;
kinds=("gauss",),
&hellip;
width_range=(0.5, 3),
&hellip;
height_range=(1.0, 5.0),
&hellip;
x_range=(0, 500),
&hellip;
n_points=2048,
&hellip;
normalize=False,
&hellip;
seed=123
&hellip; )</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; S.plot()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def generate_mixtures(cls,
                      n_mixtures=10,             # int
                      max_peaks = 16,            # int,
                      peaks_per_mixture = (3,8), # tuple[int, int],
                      amplitude_range = (0.5,2), # tuple[float, float],
                      flatten = &#39;mean&#39;,          # literal[&#39;sum&#39;, &#39;mean&#39;]
                      # parameters
                      n_signals=1,
                      n_peaks=1,
                      kinds=(&#34;gauss&#34;,),
                      width_range=(0.5, 3),
                      height_range=(1.0, 5.0),
                      x_range=(0, 500),
                      n_points=1024,
                      normalize=False,
                      seed=None,
                      **kwargs):
    &#34;&#34;&#34;
    Generate synthetic mixtures of signals by combining a subset of base peaks.

    Parameters
    ----------
    n_mixtures : int
        Number of synthetic mixtures to generate.

    max_peaks : int
        Maximum number of base signals (from which peaks are taken).

    peaks_per_mixture : tuple of (int, int)
        Range (min, max) for the number of peaks to combine in each mixture.
        Cannot exceed `max_peaks`.

    amplitude_range : tuple of (float, float)
        Random scaling range applied to peak amplitudes in each mixture.

    flatten : {&#39;sum&#39;, &#39;mean&#39;}, default=&#39;mean&#39;
        How to combine the signals for each mixture.

    **kwargs : dict
        All other keyword arguments passed to `generate_synthetic`.

    Returns
    -------
    result_collection : signal_collection
        A collection of synthetic mixed signals.

    all_peaks : list of dict
        All individual peaks originally generated.

    used_peak_ids : list of list of str
        For each mixture, the list of peak names used.

    Examples
    --------
    S, pS = signal_collection.generate_mixtures(
    ...     n_mixtures=30,
    ...     max_peaks=12,
    ...     peaks_per_mixture=(4, 8),
    ...     amplitude_range=(0.2, 1.5),
    ...     n_signals=12,
    ...     kinds=(&#34;gauss&#34;,),
    ...     width_range=(0.5, 3),
    ...     height_range=(1.0, 5.0),
    ...     x_range=(0, 500),
    ...     n_points=2048,
    ...     normalize=False,
    ...     seed=123
    ... )
    &gt;&gt;&gt; S.plot()
    &#34;&#34;&#34;

    # Step 1: Set defaults and validate
    if not (0 &lt; peaks_per_mixture[0] &lt;= peaks_per_mixture[1] &lt;= max_peaks):
        raise ValueError(&#34;Invalid peaks_per_mixture range.&#34;)

    if seed is not None:
        random.seed(seed)
        np.random.seed(seed)

    # Step 2: Generate base signals and flatten peaks
    S, peak_list = cls.generate_synthetic(
        n_signals=max_peaks,
        n_peaks=n_peaks,
        kinds=(&#34;gauss&#34;,),
        width_range=width_range,
        height_range=height_range,
        x_range=x_range,
        n_points=n_points,
        normalize=normalize,
        seed=seed,
        **kwargs
        )
    peak_objs = peaks(peak_list)  # Flatten into a peak collection

    all_peaks = list(peak_objs)
    peak_id_map = {p[&#39;name&#39;]: p for p in all_peaks}

    mixtures = []
    used_peak_ids = []

    for i in range(n_mixtures):
        n_peaks_in_mix = random.randint(*peaks_per_mixture)
        selected_peaks = random.sample(all_peaks, n_peaks_in_mix)
        mixture_signal = np.zeros_like(S[0].y)

        current_ids = []
        for p in selected_peaks:
            scale = random.uniform(*amplitude_range)
            yvals = generator(p[&#39;type&#39;])(S[0].x, p[&#39;x&#39;], p[&#39;w&#39;], p[&#39;h&#39;] * scale)
            mixture_signal += yvals
            current_ids.append(p[&#39;name&#39;])

        if flatten == &#39;mean&#39;:
            mixture_signal /= len(selected_peaks)

        sig = signal(x=S[0].x, y=mixture_signal, name=f&#34;mixture {i} of {n_mixtures}&#34;)
        mixtures.append(sig)
        used_peak_ids.append(current_ids)

    result_collection = cls(*mixtures,n=n_points, mode=&#39;union&#39;, force=True)

    return result_collection, all_peaks, used_peak_ids</code></pre>
</details>
</dd>
<dt id="signomics.signal_collection.generate_synthetic"><code class="name flex">
<span>def <span class="ident">generate_synthetic</span></span>(<span>n_signals=5, n_peaks=5, kind_distribution='uniform', kinds=('gauss', 'lorentz', 'triangle'), x_range=(0, 1000), n_points=1024, avoid_overlap=True, width_range=(20, 60), height_range=(0.5, 1.0), normalize=True, noise=None, bias=None, name_prefix='synthetic', seed=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a synthetic signal collection composed of random peaks.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n_signals</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of synthetic signals to generate.</dd>
<dt><strong><code>n_peaks</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of peaks per signal.</dd>
<dt><strong><code>kind_distribution</code></strong> :&ensp;<code>str</code></dt>
<dd>'uniform' → use all peak kinds equally; 'random' → random draw from kinds.</dd>
<dt><strong><code>kinds</code></strong> :&ensp;<code>tuple[str]</code></dt>
<dd>Generator types to choose from ('gauss', 'lorentz', 'triangle').</dd>
<dt><strong><code>x_range</code></strong> :&ensp;<code>tuple[float, float]</code></dt>
<dd>Start and end of x-domain.</dd>
<dt><strong><code>n_points</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of sampling points for each signal (default: 1024).</dd>
<dt><strong><code>avoid_overlap</code></strong> :&ensp;<code>bool</code></dt>
<dd>Prevent peaks from overlapping by checking spacing vs. width.</dd>
<dt><strong><code>width_range</code></strong> :&ensp;<code>tuple[float, float]</code></dt>
<dd>Range of widths for the peaks.</dd>
<dt><strong><code>height_range</code></strong> :&ensp;<code>tuple[float, float]</code></dt>
<dd>Range of peak heights.</dd>
<dt><strong><code>normalize</code></strong> :&ensp;<code>bool</code></dt>
<dd>Normalize each signal so the highest peak has intensity 1.</dd>
<dt><strong><code>noise</code></strong> :&ensp;<code>dict</code> or <code>None</code></dt>
<dd>Optional noise model, e.g. {"kind": "gaussian", "scale": 0.01}.</dd>
<dt><strong><code>bias</code></strong> :&ensp;<code>float, str, np.ndarray,</code> or <code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>Optional signal bias: can be a constant, 'ramp', or signal.</dd>
<dt><strong><code>name_prefix</code></strong> :&ensp;<code>str</code></dt>
<dd>Base name for each generated signal.</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>Random seed for reproducibility.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="signomics.signal_collection" href="#signomics.signal_collection">signal_collection</a></code></dt>
<dd>A collection of generated signals.</dd>
</dl>
<h2 id="examples">Examples</h2>
<h1 id="1-default-random-peaks-gaussian-ramp-bias">1. Default random peaks, Gaussian + ramp bias</h1>
<p>sc = signal_collection.generate_synthetic(
n_signals=5,
n_peaks=6,
kinds=("gauss", "lorentz", "triangle"),
noise={"kind": "gaussian", "scale": 0.02},
bias="ramp",
name_prefix="test"
)
sc.plot(show_mean=True, fontsize="large")</p>
<h1 id="2-high-res-signal-fixed-width-and-height">2. High-res signal, fixed width and height</h1>
<p>sc2 = signal_collection.generate_synthetic(
n_signals=3,
n_peaks=8,
kinds=("gauss",),
width_range=(30, 30),
height_range=(1.0, 1.0),
x_range=(0, 500),
n_points=2048,
normalize=False,
seed=123
)
sc2.plot(fontsize=14)</p>
<h1 id="3-poisson-noise-no-overlap-save-output">3. Poisson noise, no overlap, save output</h1>
<p>sc3 = signal_collection.generate_synthetic(
n_signals=2,
n_peaks=5,
noise={"kind": "poisson", "scale": 2.0},
name_prefix="poisson_example"
)
for s in sc3:
s.save(export_csv=True)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def generate_synthetic(cls,
                       n_signals=5,
                       n_peaks=5,
                       kind_distribution=&#34;uniform&#34;,  # or &#34;random&#34;
                       kinds=(&#34;gauss&#34;, &#34;lorentz&#34;, &#34;triangle&#34;),
                       x_range=(0, 1000),
                       n_points=1024,
                       avoid_overlap=True,
                       width_range=(20, 60),
                       height_range=(0.5, 1.0),
                       normalize=True,
                       noise=None,    # e.g. {&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.05}
                       bias=None,     # can be scalar, &#34;ramp&#34;, or signal instance
                       name_prefix=&#34;synthetic&#34;,
                       seed=None):
    &#34;&#34;&#34;
    Generate a synthetic signal collection composed of random peaks.

    Parameters
    ----------
    n_signals : int
        Number of synthetic signals to generate.
    n_peaks : int
        Number of peaks per signal.
    kind_distribution : str
        &#39;uniform&#39; → use all peak kinds equally; &#39;random&#39; → random draw from kinds.
    kinds : tuple[str]
        Generator types to choose from (&#39;gauss&#39;, &#39;lorentz&#39;, &#39;triangle&#39;).
    x_range : tuple[float, float]
        Start and end of x-domain.
    n_points : int
        Number of sampling points for each signal (default: 1024).
    avoid_overlap : bool
        Prevent peaks from overlapping by checking spacing vs. width.
    width_range : tuple[float, float]
        Range of widths for the peaks.
    height_range : tuple[float, float]
        Range of peak heights.
    normalize : bool
        Normalize each signal so the highest peak has intensity 1.
    noise : dict or None
        Optional noise model, e.g. {&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.01}.
    bias : float, str, np.ndarray, or signal
        Optional signal bias: can be a constant, &#39;ramp&#39;, or signal.
    name_prefix : str
        Base name for each generated signal.
    seed : int or None
        Random seed for reproducibility.

    Returns
    -------
    signal_collection
        A collection of generated signals.

    Examples
    ---------
    # 1. Default random peaks, Gaussian + ramp bias
    sc = signal_collection.generate_synthetic(
        n_signals=5,
        n_peaks=6,
        kinds=(&#34;gauss&#34;, &#34;lorentz&#34;, &#34;triangle&#34;),
        noise={&#34;kind&#34;: &#34;gaussian&#34;, &#34;scale&#34;: 0.02},
        bias=&#34;ramp&#34;,
        name_prefix=&#34;test&#34;
    )
    sc.plot(show_mean=True, fontsize=&#34;large&#34;)

    # 2. High-res signal, fixed width and height
    sc2 = signal_collection.generate_synthetic(
        n_signals=3,
        n_peaks=8,
        kinds=(&#34;gauss&#34;,),
        width_range=(30, 30),
        height_range=(1.0, 1.0),
        x_range=(0, 500),
        n_points=2048,
        normalize=False,
        seed=123
    )
    sc2.plot(fontsize=14)

    # 3. Poisson noise, no overlap, save output
    sc3 = signal_collection.generate_synthetic(
        n_signals=2,
        n_peaks=5,
        noise={&#34;kind&#34;: &#34;poisson&#34;, &#34;scale&#34;: 2.0},
        name_prefix=&#34;poisson_example&#34;
    )
    for s in sc3:
        s.save(export_csv=True)
    &#34;&#34;&#34;
    rng = np.random.default_rng(seed)
    xmin, xmax = x_range
    x = np.linspace(xmin, xmax, n_points)
    all_peak_centers = []
    all_peak_widths = []
    signals = []

    for i in range(n_signals):
        p = peaks()
        attempts = 0
        while len(p) &lt; n_peaks and attempts &lt; 100 * n_peaks:
            w = rng.uniform(*width_range)
            h = rng.uniform(*height_range)
            x0 = rng.uniform(xmin + 3 * w, xmax - 3 * w)

            # Check for global overlap
            if avoid_overlap:
                if any(abs(x0 - xj) &lt; 3 * max(w, wj) for xj, wj in zip(all_peak_centers, all_peak_widths)):
                    attempts += 1
                    continue

            if kind_distribution == &#34;uniform&#34;:
                kind = kinds[len(p) % len(kinds)]
            else:
                kind = rng.choice(kinds)

            p.add(x=x0, w=w, h=h, type=kind)
            all_peak_centers.append(x0)
            all_peak_widths.append(w)
            attempts += 1

        # warning if the number of peaks is lower than expected
        if len(p) &lt; n_peaks:
            warnings.warn(f&#34;Signal {i+1}: only placed {len(p)} of {n_peaks} peaks due to overlap constraints.&#34;)

        # Generate signal
        generator_map = {k: generator(k) for k in kinds}
        s = signal.from_peaks(p, x=x, generator_map=generator_map, name=f&#34;{name_prefix}_{i+1}&#34;)
        s.y_label = &#34;intensity&#34;
        s.y_unit = &#34;a.u.&#34;

        # Normalize
        if normalize:
            ymax = np.max(np.abs(s.y))
            if ymax &gt; 0:
                s.y /= ymax

        # Add noise or bias
        if noise:
            s = s.add_noise(**noise, bias=bias)
        elif bias is not None:
            s = s.add_noise(kind=&#34;gaussian&#34;, scale=0.0, bias=bias)  # bias only

        s._source_peaks = p
        signals.append(s)

    return cls(*signals, n=n_points, mode=&#39;union&#39;, force=True), [s._source_peaks for s in signals]</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="signomics.signal_collection.append"><code class="name flex">
<span>def <span class="ident">append</span></span>(<span>self, new_signal)</span>
</code></dt>
<dd>
<div class="desc"><p>Append and align the new signal to the existing collection.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append(self, new_signal):
    &#34;&#34;&#34;Append and align the new signal to the existing collection.&#34;&#34;&#34;
    aligned = self._align_all(self + [new_signal.copy()])
    self.clear()
    self.extend(aligned)</code></pre>
</details>
</dd>
<dt id="signomics.signal_collection.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self, indices_or_names=None, coeffs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Mean of selected signals, optionally weighted.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>indices_or_names</code></strong> :&ensp;<code>list[int</code> or <code>str]</code>, optional</dt>
<dd>Signal names or indices to include.</dd>
<dt><strong><code>coeffs</code></strong> :&ensp;<code>list[float]</code>, optional</dt>
<dd>Weights for selected signals.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>Averaged signal.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean(self, indices_or_names=None, coeffs=None):
    &#34;&#34;&#34;
    Mean of selected signals, optionally weighted.

    Parameters
    ----------
    indices_or_names : list[int or str], optional
        Signal names or indices to include.
    coeffs : list[float], optional
        Weights for selected signals.

    Returns
    -------
    signal
        Averaged signal.
    &#34;&#34;&#34;
    if coeffs is not None:
        total_weight = np.sum(coeffs)
    else:
        total_weight = len(indices_or_names) if indices_or_names else len(self)

    s = self.sum(indices_or_names=indices_or_names, coeffs=coeffs)
    return signal(s.x.copy(), s.y / total_weight, name=&#34;mean&#34;, source=&#34;signal_collection&#34;)</code></pre>
</details>
</dd>
<dt id="signomics.signal_collection.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, indices=None, labels=True, title=None, newfig=None, ax=None, show_mean=False, show_sum=False, coeffs=None, fontsize=12, colormap=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot selected signals with style attributes and optional overlays.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>indices</code></strong> :&ensp;<code>list[int]</code> or <code>list[str]</code>, optional</dt>
<dd>Signals to plot by index or name.</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to show signal labels.</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code></dt>
<dd>Plot title.</dd>
<dt><strong><code>newfig</code></strong> :&ensp;<code>bool</code> or <code>None</code></dt>
<dd>If True, always open a new figure.
If False, use current axes.
If None, open new figure only the first time this collection is plotted.</dd>
<dt><strong><code>ax</code></strong> :&ensp;<code>matplotlib axis</code>, optional</dt>
<dd>Axis to draw on.</dd>
<dt><strong><code>show_mean</code></strong> :&ensp;<code>bool</code></dt>
<dd>Overlay mean curve.</dd>
<dt><strong><code>show_sum</code></strong> :&ensp;<code>bool</code></dt>
<dd>Overlay sum curve.</dd>
<dt><strong><code>coeffs</code></strong> :&ensp;<code>list[float]</code>, optional</dt>
<dd>Optional weights for mean/sum.</dd>
<dt><strong><code>fontsize</code></strong> :&ensp;<code>int</code> or <code>str</code></dt>
<dd>Font size for labels and legend.</dd>
<dt><strong><code>colormap</code></strong> :&ensp;<code>list[str]</code>, optional</dt>
<dd>List of colors to cycle through when signal.color is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>matplotlib.figure.Figure</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, indices=None, labels=True, title=None, newfig=None, ax=None,
         show_mean=False, show_sum=False, coeffs=None, fontsize=12, colormap=None):
    &#34;&#34;&#34;
    Plot selected signals with style attributes and optional overlays.

    Parameters
    ----------
    indices : list[int] or list[str], optional
        Signals to plot by index or name.
    labels : bool
        Whether to show signal labels.
    title : str
        Plot title.
    newfig : bool or None
        If True, always open a new figure.
        If False, use current axes.
        If None, open new figure only the first time this collection is plotted.
    ax : matplotlib axis, optional
        Axis to draw on.
    show_mean : bool
        Overlay mean curve.
    show_sum : bool
        Overlay sum curve.
    coeffs : list[float], optional
        Optional weights for mean/sum.
    fontsize : int or str
        Font size for labels and legend.
    colormap : list[str], optional
        List of colors to cycle through when signal.color is None.

    Returns
    -------
    matplotlib.figure.Figure
    &#34;&#34;&#34;
    if not self:
        return
    # Select signals to plot
    if indices is None:
        selected = self
    else:
        if isinstance(indices[0], str):
            selected = [s for s in self if s.name in indices]
        else:
            selected = [self[i] for i in indices]
    # Circular color iterator
    if colormap is None:
        colormap = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key().get(&#39;color&#39;, [])
    color_cycle = (colormap * ((len(selected) // len(colormap)) + 1)) if colormap else [None] * len(selected)
    # Determine whether to create new figure
    if newfig is None:
        newfig = not self._plotted_once
    if newfig:
        fig = plt.figure()
    else:
        fig = plt.gcf()
    self._plotted_once = True
    ax = ax or plt.gca()
    for i, s in enumerate(selected):
        c = s.color if s.color is not None else color_cycle[i]
        s.plot(ax=ax, label=s.name if labels else None,
               color=c, linestyle=s.linestyle, linewidth=s.linewidth, fontsize=fontsize)
    # Overlay mean and sum
    if show_mean:
        self.mean(coeffs).plot(ax=ax, label=&#34;mean&#34;, color=&#34;black&#34;, linewidth=2, fontsize=fontsize)
    if show_sum:
        self.sum(coeffs).plot(ax=ax, label=&#34;sum&#34;, color=&#34;red&#34;, linestyle=&#34;--&#34;, linewidth=2, fontsize=fontsize)

    title = self.name if title is None else title
    title = &#34;Signal Collection&#34; if title is None else title
    ax.set_title(title, fontsize=fontsize)
    ax.tick_params(labelsize=fontsize)
    if labels:
        ax.legend(fontsize=fontsize)
    plt.show()
    return fig</code></pre>
</details>
</dd>
<dt id="signomics.signal_collection.sum"><code class="name flex">
<span>def <span class="ident">sum</span></span>(<span>self, indices_or_names=None, coeffs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Sum selected signals, optionally weighted by coeffs.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>indices_or_names</code></strong> :&ensp;<code>list[int</code> or <code>str]</code>, optional</dt>
<dd>If provided, selects a subset by index or name.</dd>
<dt><strong><code>coeffs</code></strong> :&ensp;<code>list[float]</code>, optional</dt>
<dd>Weights matching the number of selected signals.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="signomics.signal" href="#signomics.signal">signal</a></code></dt>
<dd>Summed signal.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sum(self, indices_or_names=None, coeffs=None):
    &#34;&#34;&#34;
    Sum selected signals, optionally weighted by coeffs.

    Parameters
    ----------
    indices_or_names : list[int or str], optional
        If provided, selects a subset by index or name.
    coeffs : list[float], optional
        Weights matching the number of selected signals.

    Returns
    -------
    signal
        Summed signal.
    &#34;&#34;&#34;
    if indices_or_names is None:
        selected = self
    else:
        selected = []
        for k in indices_or_names:
            if isinstance(k, int):
                selected.append(self[k])
            elif isinstance(k, str):
                found = next((s for s in self if s.name == k), None)
                if found is None:
                    raise KeyError(f&#34;Signal name &#39;{k}&#39; not found.&#34;)
                selected.append(found)
            else:
                raise TypeError(&#34;indices_or_names must contain ints or strs.&#34;)

    matrix = np.vstack([s.y for s in selected])
    if coeffs is not None:
        coeffs = np.asarray(coeffs)
        if coeffs.shape[0] != len(selected):
            raise ValueError(&#34;Length of coeffs must match number of selected signals.&#34;)
        result = np.dot(coeffs, matrix)
    else:
        result = np.sum(matrix, axis=0)

    return signal(selected[0].x.copy(), result, name=&#34;sum&#34;, source=&#34;signal_collection&#34;)</code></pre>
</details>
</dd>
<dt id="signomics.signal_collection.to_matrix"><code class="name flex">
<span>def <span class="ident">to_matrix</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a 2D array (n_signals x n_points) of aligned signal values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_matrix(self):
    &#34;&#34;&#34;Return a 2D array (n_signals x n_points) of aligned signal values.&#34;&#34;&#34;
    return np.vstack([s.y for s in self])</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#module-sig2dna_coresignomicspy-from-the-generative-simulation-initiative">Module: sig2dna_core.signomics.py (from the Generative Simulation Initiative)</a><ul>
<li><a href="#main-components">Main Components</a></li>
<li><a href="#key-features">Key Features</a></li>
<li><a href="#core-concept">Core Concept</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#examples">Examples</a></li>
</ul>
</li>
<li><a href="#load-a-sampled-signal-eg-from-gc-ms-raman">Load a sampled signal (e.g., from GC-MS, Raman)</a></li>
<li><a href="#encode-into-dna-like-format">Encode into DNA-like format</a></li>
<li><a href="#compare-samples-and-cluster">Compare samples and cluster</a><ul>
<li><a href="#notes">Notes</a></li>
<li><a href="#maintenance-forking">Maintenance &amp; forking</a></li>
</ul>
</li>
<li><a href="#git-init-b-main">git init -b main</a></li>
<li><a href="#gh-repo-create-sig2dna-public-source-remoteorigin-push">gh repo create sig2dna &ndash;public &ndash;source=. &ndash;remote=origin &ndash;push</a></li>
<li><a href="#alternatively">alternatively</a></li>
<li><a href="#git-remote-add-origin-gitgithubcomovitracsig2dnagit">git remote add origin git@github.com:ovitrac/sig2dna.git</a></li>
<li><a href="#git-branch-m-main-ensure-current-branch-is-named-main">git branch -M main # Ensure current branch is named 'main'</a></li>
<li><a href="#git-push-u-origin-main-push-and-set-upstream-tracking">git push -u origin main # Push and set upstream tracking</a></li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="signomics.DNApairwiseAnalysis" href="#signomics.DNApairwiseAnalysis">DNApairwiseAnalysis</a></code></h4>
<ul class="">
<li><code><a title="signomics.DNApairwiseAnalysis.best_dimension" href="#signomics.DNApairwiseAnalysis.best_dimension">best_dimension</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.cluster" href="#signomics.DNApairwiseAnalysis.cluster">cluster</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.compute_linkage" href="#signomics.DNApairwiseAnalysis.compute_linkage">compute_linkage</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.dimension_variance_curve" href="#signomics.DNApairwiseAnalysis.dimension_variance_curve">dimension_variance_curve</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.get_cluster_labels" href="#signomics.DNApairwiseAnalysis.get_cluster_labels">get_cluster_labels</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.heatmap" href="#signomics.DNApairwiseAnalysis.heatmap">heatmap</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.load" href="#signomics.DNApairwiseAnalysis.load">load</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.pcoa" href="#signomics.DNApairwiseAnalysis.pcoa">pcoa</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.plot_dendrogram" href="#signomics.DNApairwiseAnalysis.plot_dendrogram">plot_dendrogram</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.reduced_distances" href="#signomics.DNApairwiseAnalysis.reduced_distances">reduced_distances</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.save" href="#signomics.DNApairwiseAnalysis.save">save</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.scatter" href="#signomics.DNApairwiseAnalysis.scatter">scatter</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.scatter3d" href="#signomics.DNApairwiseAnalysis.scatter3d">scatter3d</a></code></li>
<li><code><a title="signomics.DNApairwiseAnalysis.select_dimensions" href="#signomics.DNApairwiseAnalysis.select_dimensions">select_dimensions</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="signomics.DNAsignal" href="#signomics.DNAsignal">DNAsignal</a></code></h4>
<ul class="">
<li><code><a title="signomics.DNAsignal.align_with" href="#signomics.DNAsignal.align_with">align_with</a></code></li>
<li><code><a title="signomics.DNAsignal.apply_baseline_filter" href="#signomics.DNAsignal.apply_baseline_filter">apply_baseline_filter</a></code></li>
<li><code><a title="signomics.DNAsignal.compute_cwt" href="#signomics.DNAsignal.compute_cwt">compute_cwt</a></code></li>
<li><code><a title="signomics.DNAsignal.encode_dna" href="#signomics.DNAsignal.encode_dna">encode_dna</a></code></li>
<li><code><a title="signomics.DNAsignal.encode_dna_full" href="#signomics.DNAsignal.encode_dna_full">encode_dna_full</a></code></li>
<li><code><a title="signomics.DNAsignal.entropy_from_string" href="#signomics.DNAsignal.entropy_from_string">entropy_from_string</a></code></li>
<li><code><a title="signomics.DNAsignal.find_sequence" href="#signomics.DNAsignal.find_sequence">find_sequence</a></code></li>
<li><code><a title="signomics.DNAsignal.get_code" href="#signomics.DNAsignal.get_code">get_code</a></code></li>
<li><code><a title="signomics.DNAsignal.get_entropy" href="#signomics.DNAsignal.get_entropy">get_entropy</a></code></li>
<li><code><a title="signomics.DNAsignal.has" href="#signomics.DNAsignal.has">has</a></code></li>
<li><code><a title="signomics.DNAsignal.plot_codes" href="#signomics.DNAsignal.plot_codes">plot_codes</a></code></li>
<li><code><a title="signomics.DNAsignal.plot_signals" href="#signomics.DNAsignal.plot_signals">plot_signals</a></code></li>
<li><code><a title="signomics.DNAsignal.plot_transforms" href="#signomics.DNAsignal.plot_transforms">plot_transforms</a></code></li>
<li><code><a title="signomics.DNAsignal.print_alignment" href="#signomics.DNAsignal.print_alignment">print_alignment</a></code></li>
<li><code><a title="signomics.DNAsignal.reconstruct_aligned_string" href="#signomics.DNAsignal.reconstruct_aligned_string">reconstruct_aligned_string</a></code></li>
<li><code><a title="signomics.DNAsignal.reconstruct_signal" href="#signomics.DNAsignal.reconstruct_signal">reconstruct_signal</a></code></li>
<li><code><a title="signomics.DNAsignal.synthetic_signal" href="#signomics.DNAsignal.synthetic_signal">synthetic_signal</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="signomics.DNAstr" href="#signomics.DNAstr">DNAstr</a></code></h4>
<ul class="two-column">
<li><code><a title="signomics.DNAstr.align" href="#signomics.DNAstr.align">align</a></code></li>
<li><code><a title="signomics.DNAstr.aligned_code" href="#signomics.DNAstr.aligned_code">aligned_code</a></code></li>
<li><code><a title="signomics.DNAstr.alignment_stats" href="#signomics.DNAstr.alignment_stats">alignment_stats</a></code></li>
<li><code><a title="signomics.DNAstr.entropy" href="#signomics.DNAstr.entropy">entropy</a></code></li>
<li><code><a title="signomics.DNAstr.excess_entropy" href="#signomics.DNAstr.excess_entropy">excess_entropy</a></code></li>
<li><code><a title="signomics.DNAstr.extract_motifs" href="#signomics.DNAstr.extract_motifs">extract_motifs</a></code></li>
<li><code><a title="signomics.DNAstr.find" href="#signomics.DNAstr.find">find</a></code></li>
<li><code><a title="signomics.DNAstr.html_alignment" href="#signomics.DNAstr.html_alignment">html_alignment</a></code></li>
<li><code><a title="signomics.DNAstr.jaccard" href="#signomics.DNAstr.jaccard">jaccard</a></code></li>
<li><code><a title="signomics.DNAstr.jensen_shannon" href="#signomics.DNAstr.jensen_shannon">jensen_shannon</a></code></li>
<li><code><a title="signomics.DNAstr.levenshtein" href="#signomics.DNAstr.levenshtein">levenshtein</a></code></li>
<li><code><a title="signomics.DNAstr.mutation_counts" href="#signomics.DNAstr.mutation_counts">mutation_counts</a></code></li>
<li><code><a title="signomics.DNAstr.mutual_entropy" href="#signomics.DNAstr.mutual_entropy">mutual_entropy</a></code></li>
<li><code><a title="signomics.DNAstr.plot_alignment" href="#signomics.DNAstr.plot_alignment">plot_alignment</a></code></li>
<li><code><a title="signomics.DNAstr.plot_mask" href="#signomics.DNAstr.plot_mask">plot_mask</a></code></li>
<li><code><a title="signomics.DNAstr.score" href="#signomics.DNAstr.score">score</a></code></li>
<li><code><a title="signomics.DNAstr.summary" href="#signomics.DNAstr.summary">summary</a></code></li>
<li><code><a title="signomics.DNAstr.to_signal" href="#signomics.DNAstr.to_signal">to_signal</a></code></li>
<li><code><a title="signomics.DNAstr.vectorized" href="#signomics.DNAstr.vectorized">vectorized</a></code></li>
<li><code><a title="signomics.DNAstr.wrapped_alignment" href="#signomics.DNAstr.wrapped_alignment">wrapped_alignment</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="signomics.generator" href="#signomics.generator">generator</a></code></h4>
</li>
<li>
<h4><code><a title="signomics.peaks" href="#signomics.peaks">peaks</a></code></h4>
<ul class="two-column">
<li><code><a title="signomics.peaks.add" href="#signomics.peaks.add">add</a></code></li>
<li><code><a title="signomics.peaks.as_dict" href="#signomics.peaks.as_dict">as_dict</a></code></li>
<li><code><a title="signomics.peaks.copy" href="#signomics.peaks.copy">copy</a></code></li>
<li><code><a title="signomics.peaks.names" href="#signomics.peaks.names">names</a></code></li>
<li><code><a title="signomics.peaks.remove_duplicates" href="#signomics.peaks.remove_duplicates">remove_duplicates</a></code></li>
<li><code><a title="signomics.peaks.rename" href="#signomics.peaks.rename">rename</a></code></li>
<li><code><a title="signomics.peaks.sort" href="#signomics.peaks.sort">sort</a></code></li>
<li><code><a title="signomics.peaks.to_signal" href="#signomics.peaks.to_signal">to_signal</a></code></li>
<li><code><a title="signomics.peaks.update" href="#signomics.peaks.update">update</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="signomics.signal" href="#signomics.signal">signal</a></code></h4>
<ul class="">
<li><code><a title="signomics.signal.add_noise" href="#signomics.signal.add_noise">add_noise</a></code></li>
<li><code><a title="signomics.signal.align_with" href="#signomics.signal.align_with">align_with</a></code></li>
<li><code><a title="signomics.signal.apply_poisson_baseline_filter" href="#signomics.signal.apply_poisson_baseline_filter">apply_poisson_baseline_filter</a></code></li>
<li><code><a title="signomics.signal.backup" href="#signomics.signal.backup">backup</a></code></li>
<li><code><a title="signomics.signal.copy" href="#signomics.signal.copy">copy</a></code></li>
<li><code><a title="signomics.signal.disable_fullhistory" href="#signomics.signal.disable_fullhistory">disable_fullhistory</a></code></li>
<li><code><a title="signomics.signal.enable_fullhistory" href="#signomics.signal.enable_fullhistory">enable_fullhistory</a></code></li>
<li><code><a title="signomics.signal.from_peaks" href="#signomics.signal.from_peaks">from_peaks</a></code></li>
<li><code><a title="signomics.signal.load" href="#signomics.signal.load">load</a></code></li>
<li><code><a title="signomics.signal.n" href="#signomics.signal.n">n</a></code></li>
<li><code><a title="signomics.signal.plot" href="#signomics.signal.plot">plot</a></code></li>
<li><code><a title="signomics.signal.restore" href="#signomics.signal.restore">restore</a></code></li>
<li><code><a title="signomics.signal.sample" href="#signomics.signal.sample">sample</a></code></li>
<li><code><a title="signomics.signal.save" href="#signomics.signal.save">save</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="signomics.signal_collection" href="#signomics.signal_collection">signal_collection</a></code></h4>
<ul class="two-column">
<li><code><a title="signomics.signal_collection.append" href="#signomics.signal_collection.append">append</a></code></li>
<li><code><a title="signomics.signal_collection.generate_mixtures" href="#signomics.signal_collection.generate_mixtures">generate_mixtures</a></code></li>
<li><code><a title="signomics.signal_collection.generate_synthetic" href="#signomics.signal_collection.generate_synthetic">generate_synthetic</a></code></li>
<li><code><a title="signomics.signal_collection.mean" href="#signomics.signal_collection.mean">mean</a></code></li>
<li><code><a title="signomics.signal_collection.plot" href="#signomics.signal_collection.plot">plot</a></code></li>
<li><code><a title="signomics.signal_collection.sum" href="#signomics.signal_collection.sum">sum</a></code></li>
<li><code><a title="signomics.signal_collection.to_matrix" href="#signomics.signal_collection.to_matrix">to_matrix</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>